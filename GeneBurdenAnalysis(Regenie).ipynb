{
 "cells": [
  {
   "metadata": {},
   "cell_type": "raw",
   "source": [
    "# ADNI Gene Burden Analysis with REGENIE\n",
    "\n",
    "Notebook for rare variant burden testing in Alzheimer‚Äôs Disease using ADNI data, following UK Biobank/DNAnexus gene burden analysis WES protocols.\n",
    "\n",
    "**Key Steps**\n",
    "\n",
    "0. Environment setup (Conda, REGENIE, PLINK, ANNOVAR)\n",
    "1. Data QC & PCA\n",
    "2. Functional annotation (Ensembl via ANNOVAR ‚Üí REGENIE formats: `.annotations.txt`, `.sets.txt`, `.masks`)\n",
    "3. REGENIE two-step analysis:\n",
    "   - Step 1: Null model fitting (common variants, MAF > 1%, 10 PCs)\n",
    "   - Step 2: Gene-based burden tests (rare variants, MAF 0.005‚Äì0.01) across masks:\n",
    "     - M1: Loss-of-function\n",
    "     - M2: Missense\n",
    "     - M3: LoF + missense\n",
    "     - M4: All coding\n",
    "4. LOVO gene selection (top 10 genes, SKAT-O)\n",
    "\n",
    "**Dataset**: ADNI2 (2/Go merged)\n",
    "**Genome Build**: GRCh37/hg19\n",
    "**Software**: REGENIE v4,1, PLINK v1.9, ANNOVAR, Python\n",
    "**References**:\n",
    "- UK Biobank RAP ‚ÄúBurden testing with WES‚Äù tutorial  https://dnanexus.gitbook.io/uk-biobank-rap/science-corner/burden-testing-with-wes\n",
    "- REGENIE documentation https://rgcgithub.github.io/regenie/options/\n"
   ],
   "id": "1259b0fa3b6e7f23"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 0. Environment setup (kelvin2)",
   "id": "98c43f6898dd7f42"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 00_environment\n",
    "# i. create conda environment in NI-HPC kelvin2\n",
    "\n",
    "conda env create -f regenie-env.yml\n",
    "\n",
    "conda activate regenie-env"
   ],
   "id": "ad3fab68ef4f2230"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 1. Data prep & qc",
   "id": "a0adc64fc8c65c26"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 01_data_prep_qc\n",
    "# i. PLINK QC for Rare Variants\n",
    "\n",
    "##############################################################\n",
    "# USER-DEFINED INPUTS (EDIT HERE) #\n",
    "##############################################################\n",
    "\n",
    "BFILE=\"/mnt/c/Users/B00731414/OneDrive - Ulster University/6. Code/ADNI/4. Gene Burden/01_Data_Prep_QC/inputs/ADNI_merged\"\n",
    "OUTPUT=\"/mnt/c/Users/B00731414/OneDrive - Ulster University/6. Code/ADNI/4. Gene Burden/01_Data_Prep_QC/outputs/ADNI2_preQC\"\n",
    "\n",
    "##############################################################\n",
    "# DO NOT EDIT BELOW THIS LINE #\n",
    "##############################################################\n",
    "\n",
    "\n",
    "# ‚îÄ‚îÄ QC rare variants ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "plink --bfile \"$BFILE\" \\\n",
    "      --maf 0.005 \\\n",
    "      --max-maf 0.01 \\\n",
    "      --geno 0.05 \\\n",
    "      --mind 0.05 \\\n",
    "      --hwe 1e-6 \\\n",
    "      --mac 1 \\\n",
    "      --not-chr 0 \\\n",
    "      --output-chr MT \\\n",
    "      --make-bed \\\n",
    "      --out \"$OUTPUT\"\n",
    "STATUS=$?\n",
    "\n",
    "if [ $STATUS -ne 0 ]; then\n",
    "  echo \"‚ùå ERROR: PLINK QC failed with exit code $STATUS\"\n",
    "  exit $STATUS\n",
    "fi\n",
    "\n",
    "echo \"‚úÖ Files saved: ${OUTPUT}.[bed|bim|fam]\"\n",
    "echo \"üèÅ QC (rare) complete.\""
   ],
   "id": "initial_id",
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 01_data_prep_qc\n",
    "# ii. PLINK QC for Common Variants (to create null model for regenie step 1)\n",
    "\n",
    "##############################################################\n",
    "# USER-DEFINED INPUTS (EDIT HERE) #\n",
    "##############################################################\n",
    "\n",
    "BFILE=\"/mnt/c/Users/B00731414/OneDrive - Ulster University/6. Code/ADNI/4. Gene Burden/01_Data_Prep_QC/inputs/ADNI_merged\"\n",
    "\n",
    "OUTPUT=\"/mnt/c/Users/B00731414/OneDrive - Ulster University/6. Code/ADNI/4. Gene Burden/01_Data_Prep_QC/outputs/ADNI2_preQC_common\"\n",
    "\n",
    "##############################################################\n",
    "# DO NOT EDIT BELOW THIS LINE #\n",
    "##############################################################\n",
    "\n",
    "# ‚îÄ‚îÄ QC common variants ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "plink --bfile \"$BFILE\" \\\n",
    "      --maf 0.01 \\\n",
    "      --geno 0.05 \\\n",
    "      --mind 0.05 \\\n",
    "      --hwe 1e-6 \\\n",
    "      --mac 1 \\\n",
    "      --not-chr 0 \\\n",
    "      --output-chr MT \\\n",
    "      --make-bed \\\n",
    "      --out \"$OUTPUT\"\n",
    "STATUS=$?\n",
    "\n",
    "if [ $STATUS -ne 0 ]; then\n",
    "  echo \"‚ùå ERROR: PLINK QC failed with exit code $STATUS\"\n",
    "  exit $STATUS\n",
    "fi\n",
    "\n",
    "echo \"‚úÖ Files saved: ${OUTPUT}.[bed|bim|fam]\"\n",
    "echo \"üèÅ QC (common) complete.\""
   ],
   "id": "9ac1df6bacbdad23"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 01_data_prep_qc\n",
    "# iii. PLINK LD pruning common variants set\n",
    "\n",
    "##############################################################\n",
    "# USER-DEFINED INPUTS (EDIT HERE) #\n",
    "##############################################################\n",
    "\n",
    "BFILE=\"/mnt/c/Users/B00731414/OneDrive - Ulster University/6. Code/ADNI/4. Gene Burden/01_Data_Prep_QC/outputs/ADNI2_preQC\"\n",
    "\n",
    "OUTPUT=\"/mnt/c/Users/B00731414/OneDrive - Ulster University/6. Code/ADNI/4. Gene Burden/01_Data_Prep_QC/outputs/ADNI_pruned\"\n",
    "\n",
    "##############################################################\n",
    "# DO NOT EDIT BELOW THIS LINE #\n",
    "##############################################################\n",
    "\n",
    "plink \\\n",
    "  --bfile \"$BFILE\" \\\n",
    "  --indep-pairwise 200 50 0.3 \\\n",
    "  --out \"$OUTPUT\"\n",
    "STATUS=$?\n",
    "\n",
    "if [ $STATUS -ne 0 ]; then\n",
    "  echo \"‚ùå ERROR: PLINK QC failed with exit code $STATUS\"\n",
    "  exit $STATUS\n",
    "fi\n",
    "\n",
    "echo \"‚úÖ Files saved: ${OUTPUT}\"\n",
    "echo \"üèÅ LD pruning complete."
   ],
   "id": "6c16fc293296172a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 01_data_prep_qc\n",
    "# iv. PLINK PCA generation on common variants set\n",
    "\n",
    "##############################################################\n",
    "# USER-DEFINED INPUTS (EDIT HERE) #\n",
    "##############################################################\n",
    "\n",
    "BFILE=\"/mnt/c/Users/B00731414/OneDrive - Ulster University/6. Code/ADNI/4. Gene Burden/01_Data_Prep_QC/outputs/ADNI2_preQC\"\n",
    "\n",
    "PRUNED=\"/mnt/c/Users/B00731414/OneDrive - Ulster University/6. Code/ADNI/4. Gene Burden/01_Data_Prep_QC/outputs/ADNI_pruned.prune.in\"\n",
    "\n",
    "OUTPUT=\"/mnt/c/Users/B00731414/OneDrive - Ulster University/6. Code/ADNI/4. Gene Burden/01_Data_Prep_QC/outputs/ADNI_PCA\"\n",
    "\n",
    "##############################################################\n",
    "# DO NOT EDIT BELOW THIS LINE #\n",
    "##############################################################\n",
    "\n",
    "plink \\\n",
    "  --bfile \"$BFILE\" \\\n",
    "  --extract \"$PRUNED\" \\\n",
    "  --pca 10 header \\\n",
    "  --out \"$OUTPUT\"\n",
    "STATUS=$?\n",
    "\n",
    "if [ $STATUS -ne 0 ]; then\n",
    "  echo \"‚ùå ERROR: PLINK QC failed with exit code $STATUS\"\n",
    "  exit $STATUS\n",
    "fi\n",
    "\n",
    "echo \"‚úÖ Files saved: ${OUTPUT}\"\n",
    "echo \"üèÅ PCA complete.\""
   ],
   "id": "a459d39a1389da24"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-16T22:56:05.667525Z",
     "start_time": "2025-08-16T22:56:05.176647Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 01_Data_Prep_QC\n",
    "# v. Generate Phenotype and Covariate Files\n",
    "# Python script\n",
    "\n",
    "##############################################################\n",
    "# USER-DEFINED INPUTS (EDIT HERE) #\n",
    "##############################################################\n",
    "\n",
    "# Paths to input files\n",
    "ADNI_MERGE_PATH = r\"C:\\Users\\B00731414\\OneDrive - Ulster University\\6. Code\\ADNI\\4. Gene Burden\\01_Data_Prep_QC\\inputs\\ADNIMERGE_15May2025.csv\"\n",
    "\n",
    "PLINK_FAM_PATH  = r\"C:\\Users\\B00731414\\OneDrive - Ulster University\\6. Code\\ADNI\\4. Gene Burden\\01_Data_Prep_QC\\outputs\\ADNI2_preQC.fam\"\n",
    "\n",
    "# Path to output directory\n",
    "OUTPUT_DIR = Path(r\"C:\\Users\\B00731414\\OneDrive - Ulster University\\6. Code\\ADNI\\4. Gene Burden\\01_Data_Prep_QC\\outputs\")\n",
    "\n",
    "##############################################################\n",
    "# DO NOT EDIT BELOW THIS LINE #\n",
    "##############################################################\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "def main():\n",
    "    print(\"üì• Loading ADNI phenotype and PLINK sample data...\")\n",
    "    # Load ADNI phenotype data\n",
    "    adni_data = pd.read_csv(ADNI_MERGE_PATH, low_memory=False)\n",
    "    # Load PLINK .fam file\n",
    "    plink_fam = pd.read_csv(\n",
    "        PLINK_FAM_PATH, sep=r'\\s+', header=None,\n",
    "        names=['FID', 'IID', 'PAT', 'MAT', 'SEX', 'PHENOTYPE']\n",
    "    )\n",
    "\n",
    "# ‚îÄ‚îÄ Filter to baseline AD vs CN ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "    ad_cn_data = adni_data[\n",
    "        (adni_data['VISCODE'] == 'bl') &\n",
    "        (adni_data['DX_bl'].isin(['AD', 'CN']))\n",
    "    ].copy()\n",
    "    print(f\"üîç Baseline AD vs CN: {len(ad_cn_data)} samples (before matching)\")\n",
    "\n",
    "# ‚îÄ‚îÄ Match PTID to IID and create FID mapping ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "    ad_cn_data['IID'] = ad_cn_data['PTID'].astype(str)\n",
    "    ad_cn_data = ad_cn_data[ad_cn_data['IID'].isin(plink_fam['IID'].astype(str))]\n",
    "    iid_to_fid = dict(zip(plink_fam['IID'].astype(str), plink_fam['FID']))\n",
    "    ad_cn_data['FID'] = ad_cn_data['IID'].map(iid_to_fid)\n",
    "\n",
    "    if ad_cn_data['FID'].isnull().any():\n",
    "        missing = ad_cn_data[ad_cn_data['FID'].isnull()]['IID'].tolist()\n",
    "        print(\"‚ö†Ô∏è WARNING: Some samples could not be mapped to FIDs\")\n",
    "        print(f\"Missing FID for: {missing}\")\n",
    "\n",
    "    print(f\"‚úÖ After genetic match: {len(ad_cn_data)} samples => \"\n",
    "          f\"{(ad_cn_data['DX_bl']=='AD').sum()} AD, {(ad_cn_data['DX_bl']=='CN').sum()} CN\")\n",
    "\n",
    "# ‚îÄ‚îÄ Create phenotype & covars ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "    ad_cn_data['AD_vs_CN'] = ad_cn_data['DX_bl'].map({'AD':1, 'CN':0})\n",
    "    ad_cn_data['sex']       = ad_cn_data['PTGENDER'].map({'Male':1, 'Female':0})\n",
    "    ad_cn_data['age']       = ad_cn_data['AGE']\n",
    "    ad_cn_data['education'] = ad_cn_data['PTEDUCAT']\n",
    "    ad_cn_data['apoe4_count']=ad_cn_data['APOE4']\n",
    "\n",
    "    phenotype_cols = ['FID','IID','AD_vs_CN','age','sex','education','apoe4_count','PTID','DX_bl']\n",
    "    pheno_df = ad_cn_data[phenotype_cols].dropna(\n",
    "        subset=['AD_vs_CN','age','sex','education','apoe4_count']\n",
    "    )\n",
    "    print(f\"üîç Final sample size: {len(pheno_df)} \"\n",
    "          f\"({(pheno_df['AD_vs_CN']==1).sum()} AD, {(pheno_df['AD_vs_CN']==0).sum()} CN)\")\n",
    "\n",
    "# ‚îÄ‚îÄ Check FID alignment with FAM file ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "    print(\"\\nüîß Verifying FID alignment with FAM file...\")\n",
    "    fam_sample  = plink_fam[plink_fam['IID'].isin(pheno_df['IID'])][['FID','IID']].head()\n",
    "    pheno_sample= pheno_df[['FID','IID']].head()\n",
    "    print(\"FAM file FID/IID mapping (sample):\"); print(fam_sample)\n",
    "    print(\"\\nPhenotype file FID/IID mapping (sample):\"); print(pheno_sample)\n",
    "\n",
    "    merged = pheno_df.merge(\n",
    "        plink_fam[['FID','IID']], on='IID', suffixes=('_pheno','_fam')\n",
    "    )\n",
    "    if (merged['FID_pheno']==merged['FID_fam']).all():\n",
    "        print(\"‚úÖ FID alignment check: PASS\")\n",
    "    else:\n",
    "        mismatches = merged[merged['FID_pheno']!=merged['FID_fam']]\n",
    "        print(\"‚ùå FID alignment check: FAIL\")\n",
    "        print(f\"Number of mismatches: {len(mismatches)}\")\n",
    "\n",
    "# ‚îÄ‚îÄ Save outputs ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    pheno_df[['FID','IID','AD_vs_CN']].to_csv(\n",
    "        OUTPUT_DIR/\"ADNI_AD_vs_CN_phenotypes.txt\", sep='\\t',\n",
    "        index=False, na_rep='NA'\n",
    "    )\n",
    "    pheno_df[['FID','IID','age','sex','education','apoe4_count']].to_csv(\n",
    "        OUTPUT_DIR/\"ADNI_AD_vs_CN_covariates.txt\", sep='\\t',\n",
    "        index=False, na_rep='NA'\n",
    "    )\n",
    "    pheno_df.to_csv(\n",
    "        OUTPUT_DIR/\"ADNI_AD_vs_CN_summary.txt\", sep='\\t',\n",
    "        index=False, na_rep='NA'\n",
    "    )\n",
    "    summary_stats = pheno_df.groupby('DX_bl').agg({\n",
    "        'age':['count','mean','std'],\n",
    "        'sex':'mean',\n",
    "        'education':['mean','std'],\n",
    "        'apoe4_count':['mean','std']\n",
    "    }).round(2)\n",
    "    summary_stats.to_csv(\n",
    "        OUTPUT_DIR/\"ADNI_AD_vs_CN_summary_stats.txt\", sep='\\t'\n",
    "    )\n",
    "\n",
    "    print(f\"\\n‚úÖ Files saved to: {OUTPUT_DIR}\")\n",
    "    print \"üèÅ Pheno & covar creation complete.\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ],
   "id": "4146c6a5b511e3ba",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ADNI phenotype and PLINK sample data...\n",
      "Baseline AD vs CN: 953 samples (before matching)\n",
      "After genetic match: 282 samples => 127 AD, 155 CN\n",
      "Final sample size: 282 (127 AD, 155 CN)\n",
      "\n",
      "Verifying FID alignment with FAM file...\n",
      "FAM file FID/IID mapping (sample):\n",
      "    FID         IID\n",
      "3     2  002_S_5018\n",
      "7     2  003_S_4644\n",
      "8     2  003_S_4872\n",
      "9     2  003_S_4892\n",
      "10    2  003_S_4900\n",
      "\n",
      "Phenotype file FID/IID mapping (sample):\n",
      "      FID         IID\n",
      "217     2  135_S_5275\n",
      "1138    2  009_S_5252\n",
      "1202    2  016_S_5251\n",
      "1454    2  023_S_5241\n",
      "1455    2  018_S_5240\n",
      "\n",
      "FID alignment check: PASS\n",
      "\n",
      "Files saved to: C:\\Users\\B00731414\\OneDrive - Ulster University\\6. Code\\ADNI\\4. Gene Burden\\01_Data_Prep_QC\\outputs\n",
      "\n",
      "REGENIE command should now work with aligned FIDs!\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-16T22:57:59.716288Z",
     "start_time": "2025-08-16T22:57:59.663317Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 01_Data_Prep_QC\n",
    "# vi. Merge covars with PCA data\n",
    "# Python script\n",
    "\n",
    "\n",
    "##############################################################\n",
    "# USER-DEFINED INPUTS (EDIT HERE) #\n",
    "##############################################################\n",
    "\n",
    "covar_file = r\"C:\\Users\\B00731414\\OneDrive - Ulster University\\6. Code\\ADNI\\4. Gene Burden\\01_Data_Prep_QC\\outputs\\ADNI_AD_vs_CN_covariates.txt\"\n",
    "\n",
    "pca_file = r\"C:\\Users\\B00731414\\OneDrive - Ulster University\\6. Code\\ADNI\\4. Gene Burden\\01_Data_Prep_QC\\outputs\\ADNI_PCA.eigenvec\"\n",
    "\n",
    "output_file = r\"C:\\Users\\B00731414\\OneDrive - Ulster University\\6. Code\\ADNI\\4. Gene Burden\\01_Data_Prep_QC\\outputs\\ADNI_PCA_merged_covariates.txt\"\n",
    "\n",
    "# Number of PCs to include\n",
    "num_pcs = 10\n",
    "\n",
    "##############################################################\n",
    "# DO NOT EDIT BELOW THIS LINE #\n",
    "##############################################################\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import List, Optional\n",
    "\n",
    "# ‚îÄ‚îÄ Check input files ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "def validate_input_files(covar_path: str, pca_path: str) -> None:\n",
    "    print(\"üîç Checking input files...\")\n",
    "\n",
    "    if not os.path.exists(covar_path):\n",
    "        raise FileNotFoundError(f\"‚ùå Covariates file not found: {covar_path}\")\n",
    "\n",
    "    if not os.path.exists(pca_path):\n",
    "        raise FileNotFoundError(f\"‚ùå PCA file not found: {pca_path}\")\n",
    "\n",
    "    print(f\"‚úÖ Covariates file found: {Path(covar_path).name}\")\n",
    "    print(f\"‚úÖ PCA file found: {Path(pca_path).name}\")\n",
    "\n",
    "# ‚îÄ‚îÄ Load PCA scores  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "def load_pca_data(pca_path: str, num_pcs: int) -> pd.DataFrame:\n",
    "    print(f\"üìñ Loading PCA data with {num_pcs} components...\")\n",
    "\n",
    "    try:\n",
    "        # Define column names for PCA file\n",
    "        pca_columns = [\"FID\", \"IID\"] + [f\"PC{i}\" for i in range(1, num_pcs + 1)]\n",
    "\n",
    "        pca = pd.read_csv(\n",
    "            pca_path,\n",
    "            sep=r'\\s+',\n",
    "            header=0,\n",
    "            names=pca_columns,\n",
    "            dtype={\"FID\": str, \"IID\": str}\n",
    "        )\n",
    "\n",
    "        print(f\"‚úÖ Loaded {len(pca)} samples with {num_pcs} PCs\")\n",
    "        return pca\n",
    "\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"‚ùå Error loading PCA data: {e}\")\n",
    "\n",
    "# ‚îÄ‚îÄ Load covar data w/ str IDs ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "def load_covariate_data(covar_path: str) -> pd.DataFrame:\n",
    "    print(\"üìñ Loading covariate data...\")\n",
    "\n",
    "    try:\n",
    "        cov = pd.read_csv(covar_path, sep='\\t', dtype=str)\n",
    "\n",
    "        # Validate required columns\n",
    "        if 'FID' not in cov.columns or 'IID' not in cov.columns:\n",
    "            raise ValueError(\"Covariate file must contain 'FID' and 'IID' columns\")\n",
    "\n",
    "        print(f\"‚úÖ Loaded {len(cov)} samples with {len(cov.columns)} covariates\")\n",
    "        print(f\"   Covariate columns: {', '.join(cov.columns.tolist())}\")\n",
    "        return cov\n",
    "\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"‚ùå Error loading covariate data: {e}\")\n",
    "\n",
    "# ‚îÄ‚îÄ Merge covar and PCA ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "def merge_data(cov: pd.DataFrame, pca: pd.DataFrame, num_pcs: int) -> pd.DataFrame:\n",
    "    print(\"üîó Merging covariate and PCA data...\")\n",
    "\n",
    "    # Check for sample overlap\n",
    "    common_samples = set(cov['IID']) & set(pca['IID'])\n",
    "    cov_only = set(cov['IID']) - set(pca['IID'])\n",
    "    pca_only = set(pca['IID']) - set(cov['IID'])\n",
    "\n",
    "    print(f\"   Common samples: {len(common_samples)}\")\n",
    "    if cov_only:\n",
    "        print(f\"   ‚ö†Ô∏è  Samples in covariates only: {len(cov_only)}\")\n",
    "    if pca_only:\n",
    "        print(f\"   ‚ö†Ô∏è  Samples in PCA only: {len(pca_only)}\")\n",
    "\n",
    "    # Merge on IID, keeping covariate FID and dropping PCA FID\n",
    "    try:\n",
    "        df = pd.merge(cov, pca.drop(columns=\"FID\"), on=\"IID\", how=\"inner\")\n",
    "\n",
    "        # Reorder columns: covariate columns first, then PCs\n",
    "        cov_cols = cov.columns.tolist()\n",
    "        pc_cols = [f\"PC{i}\" for i in range(1, num_pcs + 1)]\n",
    "        df = df[cov_cols + pc_cols]\n",
    "\n",
    "        print(f\"‚úÖ Successfully merged data: {len(df)} samples\")\n",
    "        return df\n",
    "\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"‚ùå Error merging data: {e}\")\n",
    "\n",
    "# ‚îÄ‚îÄ Save merged data ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "def save_merged_data(df: pd.DataFrame, output_path: str) -> None:\n",
    "    print(\"üíæ Saving merged covariate-PCA file...\")\n",
    "\n",
    "    try:\n",
    "        # Create output directory if it doesn't exist\n",
    "        output_dir = Path(output_path).parent\n",
    "        output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        # Save with tab delimiter\n",
    "        df.to_csv(output_path, sep='\\t', index=False)\n",
    "\n",
    "        print(f\"‚úÖ Merged file saved: {Path(output_path).name}\")\n",
    "        print(f\"   Location: {output_path}\")\n",
    "        print(f\"   Dimensions: {df.shape[0]} rows √ó {df.shape[1]} columns\")\n",
    "\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"‚ùå Error saving merged data: {e}\")\n",
    "\n",
    "# ‚îÄ‚îÄ Check data ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "def validate_output(df: pd.DataFrame, num_pcs: int) -> None:\n",
    "\n",
    "    print(\"üîç Checking merged data...\")\n",
    "\n",
    "    # Check for required columns\n",
    "    required_cols = ['FID', 'IID'] + [f\"PC{i}\" for i in range(1, num_pcs + 1)]\n",
    "    missing_cols = [col for col in required_cols if col not in df.columns]\n",
    "\n",
    "    if missing_cols:\n",
    "        print(f\"‚ö†Ô∏è  Warning: Missing expected columns: {missing_cols}\")\n",
    "\n",
    "    # Check for missing values in key columns\n",
    "    na_counts = df[['FID', 'IID']].isna().sum()\n",
    "    if na_counts.any():\n",
    "        print(f\"‚ö†Ô∏è  Warning: Missing values in ID columns: {na_counts.to_dict()}\")\n",
    "\n",
    "    # Display sample of merged data\n",
    "    print(\"\\nüìã Sample of merged data:\")\n",
    "    print(df.head(3).to_string(index=False))\n",
    "\n",
    "    print(\"‚úÖ Data check complete\")\n",
    "\n",
    "# ‚îÄ‚îÄ Main function ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "def main():\n",
    "    print(\"=\" * 60)\n",
    "    print(\"COVARIATE-PCA DATA MERGER\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    try:\n",
    "        # Validate input files\n",
    "        validate_input_files(covar_file, pca_file)\n",
    "\n",
    "        # Load data\n",
    "        pca_data = load_pca_data(pca_file, num_pcs)\n",
    "        covar_data = load_covariate_data(covar_file)\n",
    "\n",
    "        # Merge data\n",
    "        merged_data = merge_data(covar_data, pca_data, num_pcs)\n",
    "\n",
    "        # Save merged data\n",
    "        save_merged_data(merged_data, output_file)\n",
    "\n",
    "        # Validate output\n",
    "        validate_output(merged_data, num_pcs)\n",
    "\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"üèÅ MERGE COMPLETE\")\n",
    "        print(\"=\" * 60)\n",
    "        print(f\"‚úÖ Successfully created merged covariate-PCA file\")\n",
    "        print(f\"‚úÖ Ready for REGENIE analysis\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå ERROR: {e}\")\n",
    "        print(\"Please check your input files and try again.\")\n",
    "        exit(1)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "id": "b50b2df6ca549e3a",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-16T11:58:54.631236Z",
     "start_time": "2025-08-16T11:58:54.586956Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 01_Data_Prep_QC\n",
    "# vii. Convert to vcf\n",
    "\n",
    "#!/bin/bash\n",
    "\n",
    "##############################################################\n",
    "# USER-DEFINED INPUTS (EDIT HERE) #\n",
    "##############################################################\n",
    "\n",
    "INPUT=\"/mnt/c/Users/B00731414/OneDrive - Ulster University/6. Code/ADNI/4. Gene Burden/01_Data_Prep_QC/outputs/ADNI2_preQC\"\n",
    "\n",
    "OUTPUT=\"/mnt/c/Users/B00731414/OneDrive - Ulster University/6. Code/ADNI/4. Gene Burden/02_Annotations/inputs/vcf/ADNI2_preQC_converted\"\n",
    "\n",
    "##############################################################\n",
    "# DO NOT EDIT BELOW THIS LINE #\n",
    "##############################################################\n",
    "\n",
    "plink \\\n",
    "    --bfile \"$INPUT\" \\\n",
    "    --recode vcf \\\n",
    "    --out \"$OUTPUT\" \\\n",
    "STATUS=$?\n",
    "\n",
    "if [ $STATUS -ne 0 ]; then\n",
    "  echo \"‚ùå ERROR: vcf recode failed with exit code $STATUS\"\n",
    "  exit $STATUS\n",
    "fi\n",
    "\n",
    "echo \"‚úÖ Files saved: ${OUTPUT}\"\n",
    "echo \"üèÅ VCF conversion complete\"\n"
   ],
   "id": "7dd2ca178be9a181",
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (651447432.py, line 9)",
     "output_type": "error",
     "traceback": [
      "  \u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[5]\u001B[39m\u001B[32m, line 9\u001B[39m\n\u001B[31m    \u001B[39m\u001B[31mplink --bfile \"$INPUT\" --recode vcf --out \"$OUTPUT\"\u001B[39m\n                  ^\n\u001B[31mSyntaxError\u001B[39m\u001B[31m:\u001B[39m invalid syntax\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2. Annotation",
   "id": "db812af91481d018"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 02_annotation\n",
    "# i. Ensembl Gene Annotation with ANNOVAR\n",
    "\n",
    "##############################################################\n",
    "# USER-DEFINED INPUTS (EDIT HERE) #\n",
    "##############################################################\n",
    "\n",
    "BASE_DIR=\"/mnt/c/Users/B00731414/OneDrive - Ulster University/6. Code/ADNI/4. Gene Burden/02_Annotations\"\n",
    "\n",
    "INPUT_VCF=\"./inputs/vcf/ADNI2_preQC_converted.vcf\"\n",
    "\n",
    "BUILD= \"hg19\"\n",
    "\n",
    "OUTPUT_DIR=\"./outputs\"\n",
    "\n",
    "ANNOVAR_DB_DIR=\"./inputs/annovar_db\"\n",
    "\n",
    "ANNOVAR_SCRIPTS_DIR=\"./inputs/annovar_db/annovar\"\n",
    "ANNOVAR_PATH=\"${ANNOVAR_SCRIPTS_DIR}/table_annovar.pl\"\n",
    "ANNOTATE_VAR_PATH=\"${ANNOVAR_SCRIPTS_DIR}/annotate_variation.pl\"\n",
    "\n",
    "##############################################################\n",
    "# DO NOT EDIT BELOW THIS LINE #\n",
    "##############################################################\n",
    "\n",
    "set -euo pipefail\n",
    "\n",
    "# ‚îÄ‚îÄ Change to base directory ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "cd \"$BASE_DIR\" || {\n",
    "    echo \"‚ùå ERROR: Failed to change directory to $BASE_DIR\"\n",
    "    exit 1\n",
    "}\n",
    "\n",
    "echo \"üîß Checking ANNOVAR setup...\"\n",
    "\n",
    "# ‚îÄ‚îÄ Verify required scripts exist ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "if [ ! -f \"$ANNOTATE_VAR_PATH\" ]; then\n",
    "    echo \"‚ùå ERROR: annotate_variation.pl not found at $ANNOTATE_VAR_PATH\"\n",
    "    echo \"Please ensure ANNOVAR scripts are in the correct location\"\n",
    "    exit 1\n",
    "fi\n",
    "\n",
    "if [ ! -f \"$ANNOVAR_PATH\" ]; then\n",
    "    echo \"‚ùå ERROR: table_annovar.pl not found at $ANNOVAR_PATH\"\n",
    "    exit 1\n",
    "fi\n",
    "\n",
    "# ‚îÄ‚îÄ Check and download ensGene database if needed ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "if [ ! -f \"$ANNOVAR_DB_DIR/hg19_ensGene.txt\" ]; then\n",
    "    echo \"‚ùå ERROR: hg19_ensGene.txt database not found\"\n",
    "    echo \"üîÑ Attempting to download ensGene database...\"\n",
    "\n",
    "    # Download ensGene database using script paths\n",
    "    perl \"$ANNOTATE_VAR_PATH\" \\\n",
    "        -buildver \"$BUILD\" \\\n",
    "        -downdb -webfrom annovar ensGene \\\n",
    "        \"$ANNOVAR_DB_DIR/\"\n",
    "\n",
    "    if [ ! -f \"$ANNOVAR_DB_DIR/hg19_ensGene.txt\" ]; then\n",
    "        echo \"‚ùå ERROR: Failed to download ensGene database\"\n",
    "        exit 1\n",
    "    fi\n",
    "    echo \"‚úÖ ensGene database downloaded successfully\"\n",
    "else\n",
    "    echo \"‚úÖ ensGene database found\"\n",
    "fi\n",
    "\n",
    "# ‚îÄ‚îÄ Make scripts executable ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "chmod +x \"$ANNOVAR_SCRIPTS_DIR\"/*.pl\n",
    "\n",
    "# ‚îÄ‚îÄ Create output directory ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "mkdir -p \"$OUTPUT_DIR\"\n",
    "\n",
    "echo \"üîÑ Setting up Ensembl gene annotations...\"\n",
    "echo \"‚è≥ Annotating VCF: $INPUT_VCF with Ensembl genes...\"\n",
    "\n",
    "# ‚îÄ‚îÄ Run annotation ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "perl \"$ANNOVAR_PATH\" \\\n",
    "    \"$INPUT_VCF\" \\\n",
    "    \"$ANNOVAR_DB_DIR/\" \\\n",
    "    -buildver \"$BUILD\" \\\n",
    "    -out \"$OUTPUT_DIR/ADNI2_preQC_annotated_ensembl\" \\\n",
    "    -protocol ensGene \\\n",
    "    -operation g \\\n",
    "    -remove \\\n",
    "    -vcfinput \\\n",
    "    -nastring .\n",
    "\n",
    "# ‚îÄ‚îÄ Verify annotation success ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "if [ $? -eq 0 ]; then\n",
    "    echo \"üèÅ Annotation finished successfully!\"\n",
    "    echo \"üìÑ Output files:\"\n",
    "    echo \"   - ${OUTPUT_DIR}/ADNI2_preQC_annotated_ensembl.hg19_multianno.txt\"\n",
    "    echo \"   - ${OUTPUT_DIR}/ADNI2_preQC_annotated_ensembl.hg19_multianno.vcf\"\n",
    "else\n",
    "    echo \"‚ùå ERROR: Annotation failed\"\n",
    "    exit 1\n",
    "fi"
   ],
   "id": "dab13721e5864f63"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T11:46:39.979933Z",
     "start_time": "2025-08-20T11:40:20.724102Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 02_annotation\n",
    "# ii. convert ANNOVAR ensGene output to regenie inputs:\n",
    "# 1. Variant annotations file (.annotations.txt)\n",
    "# 2. Gene sets file (.sets.txt)\n",
    "# 3. Mask definitions file (.masks)\n",
    "# makes file in format  1:69134:A:G\tOR4F5(ENSG00000186092) missense(0/5)\n",
    "\n",
    "##############################################################\n",
    "#               USER-DEFINED INPUTS (EDIT HERE)              #\n",
    "##############################################################\n",
    "\n",
    "# Path to ANNOVAR ensGene multianno.txt output file\n",
    "ANNOVAR_FILE = r\"C:\\Users\\B00731414\\OneDrive - Ulster University\\6. Code\\ADNI\\4. Gene Burden\\02_Annotations\\outputs\\ADNI2_preQC_annotated_ensembl.hg19_multianno.txt\"\n",
    "\n",
    "# Output file prefix for regenie files\n",
    "OUTPUT_PREFIX = r\"C:\\Users\\B00731414\\OneDrive - Ulster University\\6. Code\\ADNI\\4. Gene Burden\\02_Annotations\\outputs\\regenie\\regenie_ukb\"\n",
    "\n",
    "# Genome build version\n",
    "GENOME_BUILD = \"hg19\"\n",
    "\n",
    "##############################################################\n",
    "#            DO NOT EDIT BELOW THIS LINE                     #\n",
    "##############################################################\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "import re\n",
    "\n",
    "# ‚îÄ‚îÄ Parse annotation to extract gene ENSGID ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "def parse_ensembl_gene_name(gene_string):\n",
    "\n",
    "    if pd.isna(gene_string) or gene_string == '.' or gene_string == '':\n",
    "        return None\n",
    "\n",
    "    gene_string = str(gene_string).strip()\n",
    "\n",
    "    # Split by comma to handle \"ENSG00000ID,GENENAME\" format\n",
    "    parts = gene_string.split(',')\n",
    "\n",
    "    ensg_id = None\n",
    "    gene_name = None\n",
    "\n",
    "    # Extract ENSG ID and gene name from parts\n",
    "    for part in parts:\n",
    "        part = part.strip()\n",
    "        if part.startswith('ENSG'):\n",
    "            ensg_id = part\n",
    "        elif part and not part.startswith('ENSG'):\n",
    "            gene_name = part\n",
    "\n",
    "    # Format like UKB\n",
    "    if gene_name and ensg_id:\n",
    "        return f\"{gene_name}({ensg_id})\"\n",
    "    elif gene_name:\n",
    "        return gene_name  # Return gene name even without ENSG\n",
    "    elif ensg_id:\n",
    "        return f\"Unknown({ensg_id})\"  # Fallback if only ENSG available\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# ‚îÄ‚îÄ Map ANNOVAR functional annotations to UKB regenie categories ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "def map_annovar_consequence_ukb(func_ensgene, exonic_func_ensgene):\n",
    "\n",
    "    func = str(func_ensgene).lower()\n",
    "    exonic_func = str(exonic_func_ensgene).lower()\n",
    "\n",
    "    # Loss-of-function variants (highest priority)\n",
    "    if ((func == 'exonic' and any(x in exonic_func for x in\n",
    "         ['nonsense', 'frameshift', 'stopgain', 'stoploss'])) or\n",
    "        'splicing' in func):\n",
    "        return 'LoF'\n",
    "\n",
    "    # Missense variants\n",
    "    if func == 'exonic' and any(x in exonic_func for x in\n",
    "        ['nonsynonymous', 'missense']):\n",
    "        return 'missense'\n",
    "\n",
    "    # Synonymous variants\n",
    "    if func == 'exonic' and 'synonymous' in exonic_func:\n",
    "        return 'synonymous'\n",
    "\n",
    "    # Other coding variants\n",
    "    if func == 'exonic':\n",
    "        return 'other_coding'\n",
    "\n",
    "    # Non-coding variants (default)\n",
    "    return 'non_coding'\n",
    "\n",
    "# ‚îÄ‚îÄ check inputs exist ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "def validate_input_file(file_path):\n",
    "\n",
    "    if not Path(file_path).exists():\n",
    "        raise FileNotFoundError(f\"Input file not found: {file_path}\")\n",
    "\n",
    "    # Test read first few lines to check format\n",
    "    try:\n",
    "        df_test = pd.read_csv(file_path, sep='\\t', nrows=5, low_memory=False)\n",
    "        required_cols = ['Gene.ensGene', 'Func.ensGene', 'Chr', 'Start', 'Ref', 'Alt']\n",
    "        missing_cols = [col for col in required_cols if col not in df_test.columns]\n",
    "\n",
    "        if missing_cols:\n",
    "            raise ValueError(f\"Missing required columns: {missing_cols}\")\n",
    "\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Error reading input file: {e}\")\n",
    "\n",
    "# ‚îÄ‚îÄ create variant-gene pairs ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "def create_variant_annotations(df):\n",
    "\n",
    "    annotations = []\n",
    "    stats = {'genes_with_ensg': 0, 'genes_without_ensg': 0}\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        # Create variant ID in regenie format: CHR:POS:REF:ALT\n",
    "        var_id = f\"{row['Chr']}:{row['Start']}:{row['Ref']}:{row['Alt']}\"\n",
    "\n",
    "        # Get gene names from ensGene (may be semicolon-separated)\n",
    "        genes = str(row['Gene.ensGene'])\n",
    "        if genes == '.' or pd.isna(genes):\n",
    "            continue\n",
    "\n",
    "        # Get functional consequence\n",
    "        consequence = map_annovar_consequence_ukb(\n",
    "            row['Func.ensGene'],\n",
    "            row.get('ExonicFunc.ensGene', '.')\n",
    "        )\n",
    "\n",
    "        # Handle multiple genes (separated by semicolons)\n",
    "        for gene_entry in genes.split(';'):\n",
    "            gene_entry = gene_entry.strip()\n",
    "            if gene_entry and gene_entry != '.':\n",
    "                # Parse and format gene name properly\n",
    "                formatted_gene = parse_ensembl_gene_name(gene_entry)\n",
    "\n",
    "                if formatted_gene:\n",
    "                    annotations.append({\n",
    "                        'variant_id': var_id,\n",
    "                        'gene': formatted_gene,\n",
    "                        'consequence': consequence,\n",
    "                        'chr': row['Chr'],\n",
    "                        'pos': row['Start']\n",
    "                    })\n",
    "\n",
    "                    # Track ENSG coverage\n",
    "                    if 'ENSG' in formatted_gene:\n",
    "                        stats['genes_with_ensg'] += 1\n",
    "                    else:\n",
    "                        stats['genes_without_ensg'] += 1\n",
    "\n",
    "    return pd.DataFrame(annotations), stats\n",
    "\n",
    "# ‚îÄ‚îÄ save variant annotations in UKB/regenie format ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "def save_annotations_file(ann_df, output_path):\n",
    "    with open(output_path, 'w') as f:\n",
    "        for _, r in ann_df.iterrows():\n",
    "            f.write(f\"{r['variant_id']}\\t{r['gene']}\\t{r['consequence']}\\n\")\n",
    "\n",
    "# ‚îÄ‚îÄ group variants by gene to create gene sets file ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "def create_gene_sets(ann_df):\n",
    "    gene_sets = defaultdict(list)\n",
    "    gene_pos = {}\n",
    "\n",
    "    for _, r in ann_df.iterrows():\n",
    "        gene_sets[r['gene']].append(r['variant_id'])\n",
    "        if r['gene'] not in gene_pos:\n",
    "            gene_pos[r['gene']] = {'chr': r['chr'], 'pos': r['pos']}\n",
    "\n",
    "    return gene_sets, gene_pos\n",
    "\n",
    "# ‚îÄ‚îÄ save gene sets file ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "def save_gene_sets_file(gene_sets, gene_pos, output_path):\n",
    "    with open(output_path, 'w') as f:\n",
    "        for gene, variants in gene_sets.items():\n",
    "            chrpos = gene_pos[gene]\n",
    "            if variants:  # Only include genes with variants\n",
    "                f.write(f\"{gene} {chrpos['chr']} {chrpos['pos']} \" +\n",
    "                       f\"{','.join(variants)}\\n\")\n",
    "\n",
    "\n",
    "# ‚îÄ‚îÄ create masks ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "def create_mask_definitions():\n",
    "    return {\n",
    "        'M1': ['LoF'],  # Loss-of-function only\n",
    "        'M2': ['missense'],  # Missense variants only\n",
    "        'M3': ['LoF', 'missense'],  # Combined LoF and missense\n",
    "        'M4': ['LoF', 'missense', 'synonymous'],  # All coding variants\n",
    "    }\n",
    "\n",
    "# ‚îÄ‚îÄ save masks ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "def save_mask_definitions_file(mask_definitions, output_path):\n",
    "\n",
    "    with open(output_path, 'w') as f:\n",
    "        for mask_name, consequences in mask_definitions.items():\n",
    "            f.write(f\"{mask_name} {','.join(consequences)}\\n\")\n",
    "\n",
    "# ‚îÄ‚îÄ main function  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "def create_regenie_files_from_annovar():\n",
    "    print(\"=\" * 80)\n",
    "    print(\"ANNOVAR ENSEMBL TO REGENIE CONVERSION\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"Input file: {ANNOVAR_FILE}\")\n",
    "    print(f\"Output prefix: {OUTPUT_PREFIX}\")\n",
    "    print(f\"Genome build: {GENOME_BUILD}\")\n",
    "    print()\n",
    "\n",
    "    try:\n",
    "        # Validate input file\n",
    "        validate_input_file(ANNOVAR_FILE)\n",
    "\n",
    "        # Read ANNOVAR ensGene output\n",
    "        print(\"üìñ Reading ANNOVAR ensGene file...\")\n",
    "        df = pd.read_csv(ANNOVAR_FILE, sep='\\t', low_memory=False)\n",
    "        print(f\"‚úÖ Found {len(df)} annotated variants\")\n",
    "\n",
    "        # Create variant annotations\n",
    "        print(\"\\nüß¨ Creating variant annotations...\")\n",
    "        ann_df, stats = create_variant_annotations(df)\n",
    "\n",
    "        if len(ann_df) == 0:\n",
    "            raise ValueError(\"No valid annotations created\")\n",
    "\n",
    "        print(f\"‚úÖ Created {len(ann_df)} variant-gene annotation pairs\")\n",
    "        print(f\"‚úÖ {stats['genes_with_ensg']} annotations have ENSG IDs\")\n",
    "        print(f\"‚ö†Ô∏è  {stats['genes_without_ensg']} annotations lack ENSG IDs\")\n",
    "\n",
    "        # Show example annotations\n",
    "        if len(ann_df) > 0:\n",
    "            print(\"\\nüìã Example annotations:\")\n",
    "            for i in range(min(5, len(ann_df))):\n",
    "                row = ann_df.iloc[i]\n",
    "                print(f\"   {row['variant_id']} {row['gene']} {row['consequence']}\")\n",
    "\n",
    "        # Save annotations file\n",
    "        ann_file = f\"{OUTPUT_PREFIX}.annotations.txt\"\n",
    "        save_annotations_file(ann_df, ann_file)\n",
    "        print(f\"üíæ Saved: {ann_file}\")\n",
    "\n",
    "        # Create and save gene sets\n",
    "        print(\"\\nüßÆ Creating gene sets...\")\n",
    "        gene_sets, gene_pos = create_gene_sets(ann_df)\n",
    "\n",
    "        sets_file = f\"{OUTPUT_PREFIX}.sets.txt\"\n",
    "        save_gene_sets_file(gene_sets, gene_pos, sets_file)\n",
    "        print(f\"‚úÖ Created {len(gene_sets)} gene sets\")\n",
    "        print(f\"üíæ Saved: {sets_file}\")\n",
    "\n",
    "        # Create and save mask definitions\n",
    "        print(\"\\nüé≠ Creating mask definitions...\")\n",
    "        mask_definitions = create_mask_definitions()\n",
    "\n",
    "        masks_file = f\"{OUTPUT_PREFIX}.masks\"\n",
    "        save_mask_definitions_file(mask_definitions, masks_file)\n",
    "        print(f\"‚úÖ Created {len(mask_definitions)} mask definitions\")\n",
    "        print(f\"üíæ Saved: {masks_file}\")\n",
    "\n",
    "        # Final summary\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"CONVERSION COMPLETE\")\n",
    "        print(\"=\" * 80)\n",
    "        print(f\"‚úÖ Processed {len(df)} variants\")\n",
    "        print(f\"‚úÖ Created annotations for {len(gene_sets)} genes\")\n",
    "        print(f\"‚úÖ Generated {len(mask_definitions)} mask types\")\n",
    "        print(f\"‚úÖ Gene name format: GENENAME(ENSG00000ID)\")\n",
    "\n",
    "        if len(ann_df) > 0:\n",
    "            example_row = ann_df.iloc[0]\n",
    "            print(f\"   Example: {example_row['variant_id']}\\t{example_row['gene']}\\t{example_row['consequence']}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå ERROR: {e}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "   create_regenie_files_from_annovar()"
   ],
   "id": "efe2d02ab65026e2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ANNOVAR ENSEMBL TO REGENIE CONVERSION\n",
      "================================================================================\n",
      "Input file: C:\\Users\\B00731414\\OneDrive - Ulster University\\6. Code\\ADNI\\4. Gene Burden\\02_Annotations\\outputs\\ADNI2_preQC_annotated_ensembl.hg19_multianno.txt\n",
      "Output prefix: C:\\Users\\B00731414\\OneDrive - Ulster University\\6. Code\\ADNI\\4. Gene Burden\\02_Annotations\\outputs\\regenie\\regenie_ukb\n",
      "Genome build: hg19\n",
      "\n",
      "üìñ Reading ANNOVAR ensGene file...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 295\u001B[39m\n\u001B[32m    292\u001B[39m         sys.exit(\u001B[32m1\u001B[39m)\n\u001B[32m    294\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[34m__name__\u001B[39m == \u001B[33m\"\u001B[39m\u001B[33m__main__\u001B[39m\u001B[33m\"\u001B[39m:\n\u001B[32m--> \u001B[39m\u001B[32m295\u001B[39m     \u001B[43mcreate_regenie_files_from_annovar\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 233\u001B[39m, in \u001B[36mcreate_regenie_files_from_annovar\u001B[39m\u001B[34m()\u001B[39m\n\u001B[32m    231\u001B[39m \u001B[38;5;66;03m# Read ANNOVAR ensGene output\u001B[39;00m\n\u001B[32m    232\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33müìñ Reading ANNOVAR ensGene file...\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m--> \u001B[39m\u001B[32m233\u001B[39m df = \u001B[43mpd\u001B[49m\u001B[43m.\u001B[49m\u001B[43mread_csv\u001B[49m\u001B[43m(\u001B[49m\u001B[43mANNOVAR_FILE\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msep\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[38;5;130;43;01m\\t\u001B[39;49;00m\u001B[33;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlow_memory\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[32m    234\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33m‚úÖ Found \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(df)\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m annotated variants\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m    236\u001B[39m \u001B[38;5;66;03m# Create variant annotations\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\OneDrive - Ulster University\\6. Code\\ADNI\\4. Gene Burden\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001B[39m, in \u001B[36mread_csv\u001B[39m\u001B[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001B[39m\n\u001B[32m   1013\u001B[39m kwds_defaults = _refine_defaults_read(\n\u001B[32m   1014\u001B[39m     dialect,\n\u001B[32m   1015\u001B[39m     delimiter,\n\u001B[32m   (...)\u001B[39m\u001B[32m   1022\u001B[39m     dtype_backend=dtype_backend,\n\u001B[32m   1023\u001B[39m )\n\u001B[32m   1024\u001B[39m kwds.update(kwds_defaults)\n\u001B[32m-> \u001B[39m\u001B[32m1026\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_read\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\OneDrive - Ulster University\\6. Code\\ADNI\\4. Gene Burden\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:626\u001B[39m, in \u001B[36m_read\u001B[39m\u001B[34m(filepath_or_buffer, kwds)\u001B[39m\n\u001B[32m    623\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m parser\n\u001B[32m    625\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m parser:\n\u001B[32m--> \u001B[39m\u001B[32m626\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mparser\u001B[49m\u001B[43m.\u001B[49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnrows\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\OneDrive - Ulster University\\6. Code\\ADNI\\4. Gene Burden\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1923\u001B[39m, in \u001B[36mTextFileReader.read\u001B[39m\u001B[34m(self, nrows)\u001B[39m\n\u001B[32m   1916\u001B[39m nrows = validate_integer(\u001B[33m\"\u001B[39m\u001B[33mnrows\u001B[39m\u001B[33m\"\u001B[39m, nrows)\n\u001B[32m   1917\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m   1918\u001B[39m     \u001B[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001B[39;00m\n\u001B[32m   1919\u001B[39m     (\n\u001B[32m   1920\u001B[39m         index,\n\u001B[32m   1921\u001B[39m         columns,\n\u001B[32m   1922\u001B[39m         col_dict,\n\u001B[32m-> \u001B[39m\u001B[32m1923\u001B[39m     ) = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_engine\u001B[49m\u001B[43m.\u001B[49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# type: ignore[attr-defined]\u001B[39;49;00m\n\u001B[32m   1924\u001B[39m \u001B[43m        \u001B[49m\u001B[43mnrows\u001B[49m\n\u001B[32m   1925\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1926\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n\u001B[32m   1927\u001B[39m     \u001B[38;5;28mself\u001B[39m.close()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\OneDrive - Ulster University\\6. Code\\ADNI\\4. Gene Burden\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:239\u001B[39m, in \u001B[36mCParserWrapper.read\u001B[39m\u001B[34m(self, nrows)\u001B[39m\n\u001B[32m    236\u001B[39m         data = _concatenate_chunks(chunks)\n\u001B[32m    238\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m239\u001B[39m         data = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_reader\u001B[49m\u001B[43m.\u001B[49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnrows\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    240\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m:\n\u001B[32m    241\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._first_chunk:\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-18T23:02:26.309120Z",
     "start_time": "2025-08-18T22:52:41.372932Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 02_annotation\n",
    "# ii. (ALTERNATIVE) convert ANNOVAR ensGene output to regenie inputs:\n",
    "# 1. Variant annotations file (.annotations.txt)\n",
    "# 2. Gene sets file (.sets.txt)\n",
    "# 3. Mask definitions file (.masks)\n",
    "# makes file in format: rs17160698 NOC2L(ENSG00000ID) non_coding\n",
    "\n",
    "\n",
    "##############################################################\n",
    "#               USER-DEFINED INPUTS (EDIT HERE)              #\n",
    "##############################################################\n",
    "\n",
    "# Path to ANNOVAR ensGene multianno.txt output file\n",
    "ANNOVAR_FILE = r\"C:\\Users\\B00731414\\OneDrive - Ulster University\\6. Code\\ADNI\\4. Gene Burden\\02_Annotations\\outputs\\ADNI2_preQC_annotated_ensembl.hg19_multianno.txt\"\n",
    "\n",
    "# Path to the BIM file to get the correct variant IDs (rsIDs)\n",
    "BIM_FILE = r\"C:\\Users\\B00731414\\OneDrive - Ulster University\\6. Code\\ADNI\\4. Gene Burden\\01_Data_Prep_QC\\outputs\\ADNI2_preQC.bim\"\n",
    "\n",
    "# Output file prefix for regenie files\n",
    "OUTPUT_PREFIX = r\"C:\\Users\\B00731414\\OneDrive - Ulster University\\6. Code\\ADNI\\4. Gene Burden\\02_Annotations\\outputs\\regenie\\regenie_ukb\"\n",
    "\n",
    "# Genome build version\n",
    "GENOME_BUILD = \"hg19\"\n",
    "\n",
    "##############################################################\n",
    "#            DO NOT EDIT BELOW THIS LINE                     #\n",
    "##############################################################\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "import re\n",
    "\n",
    "# ‚îÄ‚îÄ Parse annotation to extract gene ENSGID ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "def parse_ensembl_gene_name(gene_string):\n",
    "    if pd.isna(gene_string) or gene_string == '.' or gene_string == '':\n",
    "        return None\n",
    "\n",
    "    gene_string = str(gene_string).strip()\n",
    "    parts = gene_string.split(',')\n",
    "\n",
    "    ensg_id = None\n",
    "    gene_name = None\n",
    "\n",
    "    for part in parts:\n",
    "        part = part.strip()\n",
    "        if part.startswith('ENSG'):\n",
    "            ensg_id = part\n",
    "        elif part and not part.startswith('ENSG'):\n",
    "            gene_name = part\n",
    "\n",
    "    if gene_name and ensg_id:\n",
    "        return f\"{gene_name}({ensg_id})\"\n",
    "    elif gene_name:\n",
    "        return gene_name\n",
    "    elif ensg_id:\n",
    "        return f\"Unknown({ensg_id})\"\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# ‚îÄ‚îÄ Map ANNOVAR functional annotations to UKB regenie categories ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "def map_annovar_consequence_ukb(func_ensgene, exonic_func_ensgene):\n",
    "    func = str(func_ensgene).lower()\n",
    "    exonic_func = str(exonic_func_ensgene).lower()\n",
    "\n",
    "    if ((func == 'exonic' and any(x in exonic_func for x in\n",
    "         ['nonsense', 'frameshift', 'stopgain', 'stoploss'])) or\n",
    "        'splicing' in func):\n",
    "        return 'LoF'\n",
    "\n",
    "    if func == 'exonic' and any(x in exonic_func for x in\n",
    "        ['nonsynonymous', 'missense']):\n",
    "        return 'missense'\n",
    "\n",
    "    if func == 'exonic' and 'synonymous' in exonic_func:\n",
    "        return 'synonymous'\n",
    "\n",
    "    if func == 'exonic':\n",
    "        return 'other_coding'\n",
    "\n",
    "    return 'non_coding'\n",
    "\n",
    "# ‚îÄ‚îÄ Load BIM file and create CHR:POS:REF:ALT ‚Üí rsID mapping ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "def load_bim_file(bim_path):\n",
    "    print(\"üìñ Reading BIM file to create variant ID mapping...\")\n",
    "\n",
    "    if not Path(bim_path).exists():\n",
    "        raise FileNotFoundError(f\"BIM file not found: {bim_path}\")\n",
    "\n",
    "    bim_df = pd.read_csv(bim_path, sep=r'\\s+', header=None,\n",
    "                         names=['CHR', 'rsID', 'cM', 'POS', 'A1', 'A2'])\n",
    "\n",
    "    print(f\"‚úÖ Loaded {len(bim_df)} variants from BIM file\")\n",
    "\n",
    "    variant_to_rsid = {}\n",
    "    for _, row in bim_df.iterrows():\n",
    "        var_id_1 = f\"{row['CHR']}:{row['POS']}:{row['A1']}:{row['A2']}\"\n",
    "        var_id_2 = f\"{row['CHR']}:{row['POS']}:{row['A2']}:{row['A1']}\"\n",
    "        variant_to_rsid[var_id_1] = row['rsID']\n",
    "        variant_to_rsid[var_id_2] = row['rsID']\n",
    "\n",
    "    print(f\"‚úÖ Created mapping for {len(variant_to_rsid)} variant ID combinations\")\n",
    "    return variant_to_rsid\n",
    "\n",
    "# ‚îÄ‚îÄ Validate ANNOVAR input ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "def validate_annovar_file(file_path):\n",
    "    if not Path(file_path).exists():\n",
    "        raise FileNotFoundError(f\"ANNOVAR file not found: {file_path}\")\n",
    "\n",
    "    df_test = pd.read_csv(file_path, sep='\\t', nrows=5, low_memory=False)\n",
    "    required_cols = ['Gene.ensGene', 'Func.ensGene', 'Chr', 'Start', 'Ref', 'Alt']\n",
    "    missing_cols = [col for col in required_cols if col not in df_test.columns]\n",
    "\n",
    "    if missing_cols:\n",
    "        raise ValueError(f\"Missing required columns: {missing_cols}\")\n",
    "    return True\n",
    "\n",
    "# ‚îÄ‚îÄ Create variant annotations with rsID mapping ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "def create_variant_annotations(df, variant_to_rsid):\n",
    "    annotations = []\n",
    "    stats = {\n",
    "        'genes_with_ensg': 0,\n",
    "        'genes_without_ensg': 0,\n",
    "        'variants_mapped': 0,\n",
    "        'variants_unmapped': 0\n",
    "    }\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        chr_pos_ref_alt = f\"{row['Chr']}:{row['Start']}:{row['Ref']}:{row['Alt']}\"\n",
    "\n",
    "        if chr_pos_ref_alt in variant_to_rsid:\n",
    "            rsid = variant_to_rsid[chr_pos_ref_alt]\n",
    "            stats['variants_mapped'] += 1\n",
    "        else:\n",
    "            chr_pos_alt_ref = f\"{row['Chr']}:{row['Start']}:{row['Alt']}:{row['Ref']}\"\n",
    "            if chr_pos_alt_ref in variant_to_rsid:\n",
    "                rsid = variant_to_rsid[chr_pos_alt_ref]\n",
    "                stats['variants_mapped'] += 1\n",
    "            else:\n",
    "                stats['variants_unmapped'] += 1\n",
    "                continue\n",
    "\n",
    "        genes = str(row['Gene.ensGene'])\n",
    "        if genes == '.' or pd.isna(genes):\n",
    "            continue\n",
    "\n",
    "        consequence = map_annovar_consequence_ukb(\n",
    "            row['Func.ensGene'],\n",
    "            row.get('ExonicFunc.ensGene', '.')\n",
    "        )\n",
    "\n",
    "        for gene_entry in genes.split(';'):\n",
    "            gene_entry = gene_entry.strip()\n",
    "            if gene_entry and gene_entry != '.':\n",
    "                formatted_gene = parse_ensembl_gene_name(gene_entry)\n",
    "                if formatted_gene:\n",
    "                    annotations.append({\n",
    "                        'variant_id': rsid,\n",
    "                        'gene': formatted_gene,\n",
    "                        'consequence': consequence,\n",
    "                        'chr': row['Chr'],\n",
    "                        'pos': row['Start']\n",
    "                    })\n",
    "                    if 'ENSG' in formatted_gene:\n",
    "                        stats['genes_with_ensg'] += 1\n",
    "                    else:\n",
    "                        stats['genes_without_ensg'] += 1\n",
    "\n",
    "    return pd.DataFrame(annotations), stats\n",
    "\n",
    "# ‚îÄ‚îÄ Save annotations file ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "def save_annotations_file(ann_df, output_path):\n",
    "    with open(output_path, 'w') as f:\n",
    "        for _, r in ann_df.iterrows():\n",
    "            f.write(f\"{r['variant_id']}\\t{r['gene']}\\t{r['consequence']}\\n\")\n",
    "\n",
    "# ‚îÄ‚îÄ Create gene sets ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "def create_gene_sets(ann_df):\n",
    "    gene_sets = defaultdict(list)\n",
    "    gene_pos = {}\n",
    "    for _, r in ann_df.iterrows():\n",
    "        gene_sets[r['gene']].append(r['variant_id'])\n",
    "        if r['gene'] not in gene_pos:\n",
    "            gene_pos[r['gene']] = {'chr': r['chr'], 'pos': r['pos']}\n",
    "    return gene_sets, gene_pos\n",
    "\n",
    "# ‚îÄ‚îÄ Save gene sets file ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "def save_gene_sets_file(gene_sets, gene_pos, output_path):\n",
    "    with open(output_path, 'w') as f:\n",
    "        for gene, variants in gene_sets.items():\n",
    "            chrpos = gene_pos[gene]\n",
    "            if variants:\n",
    "                f.write(f\"{gene} {chrpos['chr']} {chrpos['pos']} \" +\n",
    "                        f\"{','.join(variants)}\\n\")\n",
    "\n",
    "# ‚îÄ‚îÄ Create mask definitions ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "def create_mask_definitions():\n",
    "    return {\n",
    "        'M1': ['LoF'],\n",
    "        'M2': ['missense'],\n",
    "        'M3': ['LoF', 'missense'],\n",
    "        'M4': ['LoF', 'missense', 'synonymous'],\n",
    "    }\n",
    "\n",
    "# ‚îÄ‚îÄ Save mask definitions ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "def save_mask_definitions_file(mask_definitions, output_path):\n",
    "    with open(output_path, 'w') as f:\n",
    "        for mask_name, consequences in mask_definitions.items():\n",
    "            f.write(f\"{mask_name} {','.join(consequences)}\\n\")\n",
    "\n",
    "# ‚îÄ‚îÄ Main function ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "def create_regenie_files_with_rsid_mapping():\n",
    "    print(\"=\" * 80)\n",
    "    print(\"ANNOVAR ENSEMBL TO REGENIE CONVERSION (rsID mapping)\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"Input ANNOVAR file: {ANNOVAR_FILE}\")\n",
    "    print(f\"Input BIM file: {BIM_FILE}\")\n",
    "    print(f\"Output prefix: {OUTPUT_PREFIX}\")\n",
    "    print(f\"Genome build: {GENOME_BUILD}\")\n",
    "    print()\n",
    "\n",
    "    try:\n",
    "        validate_annovar_file(ANNOVAR_FILE)\n",
    "        variant_to_rsid = load_bim_file(BIM_FILE)\n",
    "\n",
    "        print(\"üìñ Reading ANNOVAR ensGene file...\")\n",
    "        df = pd.read_csv(ANNOVAR_FILE, sep='\\t', low_memory=False)\n",
    "        print(f\"‚úÖ Found {len(df)} annotated variants\")\n",
    "\n",
    "        print(\"\\nüß¨ Creating variant annotations with rsID mapping...\")\n",
    "        ann_df, stats = create_variant_annotations(df, variant_to_rsid)\n",
    "\n",
    "        if len(ann_df) == 0:\n",
    "            raise ValueError(\"No valid annotations created\")\n",
    "\n",
    "        print(f\"‚úÖ Created {len(ann_df)} variant-gene annotation pairs\")\n",
    "        print(f\"‚úÖ {stats['variants_mapped']} variants successfully mapped to rsIDs\")\n",
    "        print(f\"‚ö†Ô∏è  {stats['variants_unmapped']} variants could not be mapped\")\n",
    "        print(f\"‚úÖ {stats['genes_with_ensg']} annotations have ENSG IDs\")\n",
    "        print(f\"‚ö†Ô∏è  {stats['genes_without_ensg']} annotations lack ENSG IDs\")\n",
    "\n",
    "        if len(ann_df) > 0:\n",
    "            print(\"\\nüìã Example annotations:\")\n",
    "            for i in range(min(5, len(ann_df))):\n",
    "                row = ann_df.iloc[i]\n",
    "                print(f\"   {row['variant_id']} {row['gene']} {row['consequence']}\")\n",
    "\n",
    "        ann_file = f\"{OUTPUT_PREFIX}.annotations.txt\"\n",
    "        save_annotations_file(ann_df, ann_file)\n",
    "        print(f\"üíæ Saved: {ann_file}\")\n",
    "\n",
    "        print(\"\\nüßÆ Creating gene sets...\")\n",
    "        gene_sets, gene_pos = create_gene_sets(ann_df)\n",
    "        sets_file = f\"{OUTPUT_PREFIX}.sets.txt\"\n",
    "        save_gene_sets_file(gene_sets, gene_pos, sets_file)\n",
    "        print(f\"‚úÖ Created {len(gene_sets)} gene sets\")\n",
    "        print(f\"üíæ Saved: {sets_file}\")\n",
    "\n",
    "        print(\"\\nüé≠ Creating mask definitions...\")\n",
    "        mask_definitions = create_mask_definitions()\n",
    "        masks_file = f\"{OUTPUT_PREFIX}.masks\"\n",
    "        save_mask_definitions_file(mask_definitions, masks_file)\n",
    "        print(f\"‚úÖ Created {len(mask_definitions)} mask definitions\")\n",
    "        print(f\"üíæ Saved: {masks_file}\")\n",
    "\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"CONVERSION COMPLETE (rsID mapping)\")\n",
    "        print(\"=\" * 80)\n",
    "        print(f\"‚úÖ Processed {len(df)} ANNOVAR variants\")\n",
    "        print(f\"‚úÖ Mapped {stats['variants_mapped']} variants to rsIDs\")\n",
    "        print(f\"‚ö†Ô∏è  {stats['variants_unmapped']} variants unmapped\")\n",
    "        print(f\"‚úÖ Created annotations for {len(gene_sets)} genes\")\n",
    "        print(f\"‚úÖ Generated {len(mask_definitions)} mask types\")\n",
    "\n",
    "        if len(ann_df) > 0:\n",
    "            example_row = ann_df.iloc[0]\n",
    "            print(f\"   Example: {example_row['variant_id']}\\t{example_row['gene']}\\t{example_row['consequence']}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå ERROR: {e}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    create_regenie_files_with_rsid_mapping()\n"
   ],
   "id": "b69a99da9df27096",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ANNOVAR ENSEMBL TO REGENIE CONVERSION - OPTION B (rsID MAPPING)\n",
      "================================================================================\n",
      "Input ANNOVAR file: C:\\Users\\B00731414\\OneDrive - Ulster University\\6. Code\\ADNI\\4. Gene Burden\\02_Annotations\\outputs\\ADNI2_preQC_annotated_ensembl.hg19_multianno.txt\n",
      "Input BIM file: C:\\Users\\B00731414\\OneDrive - Ulster University\\6. Code\\ADNI\\4. Gene Burden\\01_Data_Prep_QC\\outputs\\ADNI2_preQC.bim\n",
      "Output prefix: C:\\Users\\B00731414\\OneDrive - Ulster University\\6. Code\\ADNI\\4. Gene Burden\\02_Annotations\\outputs\\regenie\\regenie_ukb\n",
      "Genome build: hg19\n",
      "\n",
      "üìñ Reading BIM file to create variant ID mapping...\n",
      "‚úÖ Loaded 20804 variants from BIM file\n",
      "‚úÖ Created mapping for 41608 variant ID combinations\n",
      "üìñ Reading ANNOVAR ensGene file...\n",
      "‚úÖ Found 695578 annotated variants\n",
      "\n",
      "üß¨ Creating variant annotations with rsID mapping...\n",
      "‚úÖ Created 20097 variant-gene annotation pairs\n",
      "‚úÖ 20065 variants successfully mapped to rsIDs\n",
      "‚ö†Ô∏è  675513 variants could not be mapped (not in BIM)\n",
      "‚úÖ 6047 annotations have ENSG IDs\n",
      "‚ö†Ô∏è  14050 annotations lack ENSG IDs\n",
      "\n",
      "üìã Example annotations (with rsIDs):\n",
      "   rs17160698 NOC2L non_coding\n",
      "   rs6669227 ACAP3 non_coding\n",
      "   rs11807706 SSU72 non_coding\n",
      "   rs262643 PRKCZ non_coding\n",
      "   rs3122920 PANK4 non_coding\n",
      "üíæ Saved: C:\\Users\\B00731414\\OneDrive - Ulster University\\6. Code\\ADNI\\4. Gene Burden\\02_Annotations\\outputs\\regenie\\regenie_ukb.annotations.txt\n",
      "\n",
      "üßÆ Creating gene sets...\n",
      "‚úÖ Created 10532 gene sets\n",
      "üíæ Saved: C:\\Users\\B00731414\\OneDrive - Ulster University\\6. Code\\ADNI\\4. Gene Burden\\02_Annotations\\outputs\\regenie\\regenie_ukb.sets.txt\n",
      "\n",
      "üé≠ Creating mask definitions...\n",
      "‚úÖ Created 4 mask definitions\n",
      "üíæ Saved: C:\\Users\\B00731414\\OneDrive - Ulster University\\6. Code\\ADNI\\4. Gene Burden\\02_Annotations\\outputs\\regenie\\regenie_ukb.masks\n",
      "\n",
      "================================================================================\n",
      "CONVERSION COMPLETE - OPTION B (rsID MAPPING)\n",
      "================================================================================\n",
      "‚úÖ Processed 695578 ANNOVAR variants\n",
      "‚úÖ Mapped 20065 variants to rsIDs\n",
      "‚ö†Ô∏è  675513 variants unmapped (not in genetic data)\n",
      "‚úÖ Created annotations for 10532 genes\n",
      "‚úÖ Generated 4 mask types\n",
      "‚úÖ Variant ID format: rsID (matches BIM file)\n",
      "   Example: rs17160698\tNOC2L\tnon_coding\n",
      "\n",
      "üéØ REGENIE Step 2 should now work with these files!\n",
      "   - Variant IDs in annotation file match those in BIM file\n",
      "   - All files are properly tab-delimited\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 3. Regenie",
   "id": "b0bc853b50ec674b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 03_regenie\n",
    "# step 1\n",
    "# create null model to control for relatedness, population structure and polygenicity.\n",
    "\n",
    "##############################################################\n",
    "#               USER-DEFINED INPUTS (EDIT HERE)              #\n",
    "##############################################################\n",
    "\n",
    "BED_FILE=\"/mnt/c/Users/B00731414/OneDrive - Ulster University/6. Code/ADNI/4. Gene Burden/01_Data_Prep_QC/outputs/ADNI2_preQC_common\"\n",
    "PHENO_FILE=\"/mnt/c/Users/B00731414/OneDrive - Ulster University/6. Code/ADNI/4. Gene Burden/01_Data_Prep_QC/outputs/ADNI_AD_vs_CN_phenotypes.txt\"\n",
    "PHENO_COL=\"AD_vs_CN\"\n",
    "COVAR_FILE=\"/mnt/c/Users/B00731414/OneDrive - Ulster University/6. Code/ADNI/4. Gene Burden/01_Data_Prep_QC/outputs/ADNI_PCA_merged_covariates.txt\"\n",
    "COVAR_COL_LIST=\"age,sex,education,apoe4_count,PC{1:10}\"\n",
    "OUTPUT_PREFIX=\"/mnt/c/Users/B00731414/OneDrive - Ulster University/6. Code/ADNI/4. Gene Burden/03_Regenie/step 1/S1_ADNI\"\n",
    "\n",
    "##############################################################\n",
    "#            DO NOT EDIT BELOW THIS LINE                     #\n",
    "##############################################################\n",
    "\n",
    "regenie \\\n",
    "  --step 1 \\\n",
    "  --bt \\ # for binary trait\n",
    "  --ref-first \\\n",
    "  --bed \"$BED_FILE\" \\\n",
    "  --phenoFile \"$PHENO_FILE\" \\\n",
    "  --phenoCol $PHENO_COL \\\n",
    "  --covarFile \"$COVAR_FILE\" \\\n",
    "  --covarColList $COVAR_COL_LIST \\\n",
    "  --bsize 200 \\\n",
    "  --gz \\\n",
    "  --out \"$OUTPUT_PREFIX\"\n"
   ],
   "id": "d9f8d77c9e32ffce"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#!/bin/bash\n",
    "\n",
    "#SBATCH --job-name=regenie_step1\n",
    "#SBATCH --output=/users/smitchell/ADNI/ADNI_regenie/logs_and_errors/regenie_step1_%j.out\n",
    "#SBATCH --error=/users/smitchell/ADNI/ADNI_regenie/logs_and_errors/regenie_step1_%j.err\n",
    "#SBATCH --time=02:00:00\n",
    "#SBATCH --partition=k2-hipri\n",
    "#SBATCH --ntasks=1\n",
    "#SBATCH --cpus-per-task=4\n",
    "#SBATCH --mem=64G\n",
    "#SBATCH --mail-type=BEGIN,END,FAIL\n",
    "#SBATCH --mail-user=mitchell-s17@ulster.ac.uk\n",
    "\n",
    "##############################################################\n",
    "#               USER-DEFINED INPUTS (EDIT HERE)              #\n",
    "##############################################################\n",
    "\n",
    "# Input directories\n",
    "INPUT_PLINK_PREFIX=\"/users/smitchell/ADNI/ADNI_regenie/pre_qc/ADNI2_preQC_common\"\n",
    "PHENO_FILE=\"/users/smitchell/ADNI/ADNI_regenie/pre_qc/ADNI_AD_vs_CN_phenotypes.txt\"\n",
    "COVAR_FILE=\"/users/smitchell/ADNI/ADNI_regenie/pre_qc/ADNI_PCA_merged_covariates.txt\"\n",
    "\n",
    "# Output directory for step 1\n",
    "OUT_DIR=\"/users/smitchell/ADNI/ADNI_regenie/regenie_step_1\"\n",
    "\n",
    "##############################################################\n",
    "#            DO NOT EDIT BELOW THIS LINE                     #\n",
    "##############################################################\n",
    "\n",
    "# ‚îÄ‚îÄ activate conda env ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "# Initialize conda (adjust path if needed)\n",
    "eval \"$(conda shell.bash hook)\"\n",
    "\n",
    "# Activate the regenie environment\n",
    "conda activate regenie-env\n",
    "\n",
    "\n",
    "# ‚îÄ‚îÄ load modules ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "module load compilers/gcc/14.1.0\n",
    "module load libs/intel-mkl/2020u4/bin\n",
    "\n",
    "# ‚îÄ‚îÄ Run REGENIE step 1 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "regenie \\\n",
    "  --step 1 \\\n",
    "  --bt \\\n",
    "  --ref-first \\\n",
    "  --bed \"${INPUT_PLINK_PREFIX}\" \\\n",
    "  --phenoFile \"${PHENO_FILE}\" \\\n",
    "  --phenoCol AD_vs_CN \\\n",
    "  --covarFile \"${COVAR_FILE}\" \\\n",
    "  --covarColList age,sex,education,apoe4_count,PC{1:10} \\\n",
    "  --bsize 200 \\\n",
    "  --gz \\\n",
    "  --out \"${OUT_DIR}/S1_ADNI\"\n",
    "\n",
    "# ‚îÄ‚îÄ deactivate conda ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "conda deactivate\n"
   ],
   "id": "2823f150150b6f41"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 03_regenie\n",
    "# step 2\n",
    "# burden testing for rare variants\n",
    "\n",
    "##############################################################\n",
    "#               USER-DEFINED INPUTS (EDIT HERE)              #\n",
    "##############################################################\n",
    "\n",
    "BASE_DIR=\"/mnt/c/Users/B00731414/OneDrive - Ulster University/6. Code/ADNI/4. Gene Burden\"\n",
    "PHENO_FILE=\"$BASE_DIR/01_Data_Prep_QC/outputs/ADNI_AD_vs_CN_phenotypes.txt\"\n",
    "COVAR_FILE=\"$BASE_DIR/01_Data_Prep_QC/outputs/ADNI_PCA_merged_covariates.txt\"\n",
    "RARE_BED=\"$BASE_DIR/01_Data_Prep_QC/outputs/ADNI2_preQC\"\n",
    "\n",
    "# Annotation files\n",
    "ANNO_FILE=\"$BASE_DIR/02_Annotations/outputs/regenie/regenie_ukb.annotations.txt\"\n",
    "SETS_FILE=\"$BASE_DIR/02_Annotations/outputs/regenie/regenie_ukb.sets.txt\"\n",
    "MASK_FILE=\"$BASE_DIR/02_Annotations/outputs/regenie/regenie_ukb.masks\"\n",
    "\n",
    "# Output directories\n",
    "STEP1_OUT=\"$BASE_DIR/03_Regenie/step 1\"\n",
    "STEP2_OUT=\"$BASE_DIR/03_Regenie/step 2\"\n",
    "\n",
    "##############################################################\n",
    "#            DO NOT EDIT BELOW THIS LINE                     #\n",
    "##############################################################\n",
    "\n",
    "regenie \\\n",
    "  --step 2 \\\n",
    "  --bt \\\n",
    "  --bed \"$RARE_BED\" \\\n",
    "  --ref-first \\\n",
    "  --phenoFile \"$PHENO_FILE\" \\\n",
    "  --phenoCol AD_vs_CN \\\n",
    "  --covarFile \"$COVAR_FILE\" \\\n",
    "  --covarColList age,sex,education,apoe4_count,PC{1:10} \\\n",
    "  --pred \"$STEP1_OUT/S1_ADNI_pred_base.list\" \\\n",
    "  --anno-file \"$ANNO_FILE\" \\\n",
    "  --set-list \"$SETS_FILE\" \\\n",
    "  --mask-def \"$MASK_FILE\" \\\n",
    "  --aaf-bins 0.01,0.001 \\\n",
    "  --build-mask max \\\n",
    "  --write-mask \\\n",
    "  --vc-tests skato,acato \\\n",
    "  --bsize 200 \\\n",
    "  --out \"$STEP2_OUT/S2_ADNI_burden\""
   ],
   "id": "f2cfddeddee79831"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#!/bin/bash\n",
    "#SBATCH --job-name=regenie_step2\n",
    "#SBATCH --output=/users/smitchell/ADNI/ADNI_regenie/logs_and_errors/regenie_step2_%j.out\n",
    "#SBATCH --error=/users/smitchell/ADNI/ADNI_regenie/logs_and_errors/regenie_step2_%j.err\n",
    "#SBATCH --time=2:00:00\n",
    "#SBATCH --partition=k2-hipri\n",
    "#SBATCH --ntasks=1\n",
    "#SBATCH --cpus-per-task=8\n",
    "#SBATCH --mem=128G\n",
    "#SBATCH --mail-type=BEGIN,END,FAIL\n",
    "#SBATCH --mail-user=mitchell-s17@ulster.ac.uk\n",
    "\n",
    "##############################################################\n",
    "#               USER-DEFINED INPUTS (EDIT HERE)              #\n",
    "##############################################################\n",
    "\n",
    "BASE_DIR=\"/users/smitchell/ADNI/ADNI_regenie\"\n",
    "\n",
    "PHENO_FILE=\"${BASE_DIR}/pre_qc/ADNI_AD_vs_CN_phenotypes.txt\"\n",
    "COVAR_FILE=\"${BASE_DIR}/pre_qc/ADNI_PCA_merged_covariates.txt\"\n",
    "RARE_BED=\"${BASE_DIR}/pre_qc/ADNI2_preQC\"\n",
    "\n",
    "# Annotation files\n",
    "ANNO_FILE=\"${BASE_DIR}/annotations/regenie_ukb.annotations.txt\"\n",
    "SETS_FILE=\"${BASE_DIR}/annotations/regenie_ukb.sets.txt\"\n",
    "MASK_FILE=\"${BASE_DIR}/annotations/regenie_ukb.masks\"\n",
    "\n",
    "# Output directory for step 2\n",
    "OUT_DIR=\"${BASE_DIR}/regenie_step_2\"\n",
    "mkdir -p \"${OUT_DIR}\"\n",
    "\n",
    "##############################################################\n",
    "#            DO NOT EDIT BELOW THIS LINE                     #\n",
    "##############################################################\n",
    "\n",
    "# ‚îÄ‚îÄ activate conda env ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "eval \"$(conda shell.bash hook)\"\n",
    "conda activate regenie-env\n",
    "\n",
    "# ‚îÄ‚îÄ load modules ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "module load compilers/gcc/14.1.0\n",
    "module load libs/eigen/3.4.0/gcc-14.1.0\n",
    "module load libs/intel-mkl/2020u4/bin\n",
    "\n",
    "# ‚îÄ‚îÄ run regenie step 2 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "regenie \\\n",
    "  --step 2 \\\n",
    "  --bt \\\n",
    "  --bed \"${RARE_BED}\" \\\n",
    "  --ref-first \\\n",
    "  --phenoFile \"${PHENO_FILE}\" \\\n",
    "  --phenoCol AD_vs_CN \\\n",
    "  --covarFile \"${COVAR_FILE}\" \\\n",
    "  --covarColList age,sex,education,apoe4_count,PC{1:10} \\\n",
    "  --pred \"${BASE_DIR}/regenie_step_1/S1_ADNI_pred.list\" \\\n",
    "  --anno-file \"${ANNO_FILE}\" \\\n",
    "  --set-list \"${SETS_FILE}\" \\\n",
    "  --mask-def \"${MASK_FILE}\" \\\n",
    "  --aaf-bins 0.01,0.001 \\\n",
    "  --build-mask max \\\n",
    "  --write-mask \\\n",
    "  --vc-tests skato,acato \\\n",
    "  --bsize 200 \\\n",
    "  --out \"${OUT_DIR}/S2_ADNI_burden\"\n",
    "\n",
    "# ‚îÄ‚îÄ deactivate conda ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "conda deactivate\n"
   ],
   "id": "9d48d304d0d5a391"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T20:37:36.668310Z",
     "start_time": "2025-08-21T20:37:36.528518Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 04_LOVO_Gene_Selection\n",
    "# i. Select top genes from REGENIE burden test results (LOVO gene list)\n",
    "# Python script - IMPROVED VERSION\n",
    "\n",
    "##############################################################\n",
    "#               USER-DEFINED INPUTS (EDIT HERE)              #\n",
    "##############################################################\n",
    "\n",
    "# Path to REGENIE output\n",
    "REGENIE_FILE = r\"C:\\Users\\B00731414\\OneDrive - Ulster University\\6. Code\\ADNI\\4. Gene Burden\\03_Regenie\\step 2\\S2_ADNI_burden_AD_vs_CN.regenie\"\n",
    "\n",
    "# Test configuration\n",
    "TEST_NAME = \"ADD-SKATO\"        # e.g. ADD-SKATO, ADD\n",
    "TOP_N = 10                     # Number of top gene‚Äìmask entries to select\n",
    "AAF_BIN_LABEL = \"all\"          # Label for AAF bin (as in ID field)\n",
    "OUTPUT_FILE = \"lovo_genes.txt\"\n",
    "\n",
    "# Scoring method:\n",
    "# \"logp\"  = Rank by LOG10P (recommended for burden tests)\n",
    "# \"chisq\" = Rank by CHISQ statistic\n",
    "# \"beta\"  = Rank by absolute BETA\n",
    "SCORE_METHOD = \"logp\"\n",
    "\n",
    "# Duplicate handling strategy:\n",
    "# \"best_mask\"     ‚Üí Keep most restrictive mask (M1 > M2 > M3 > M4)\n",
    "# \"keep_all\"      ‚Üí Keep all mask combinations\n",
    "# \"highest_score\" ‚Üí Keep highest scoring entry per gene\n",
    "DUPLICATE_STRATEGY = \"keep_all\"\n",
    "\n",
    "# significance filtering\n",
    "SIGNIFICANCE_THRESHOLD = None  # Set to p-value threshold (e.g., 0.05) or None to disable\n",
    "\n",
    "##############################################################\n",
    "#               DO NOT EDIT BELOW THIS LINE                  #\n",
    "##############################################################\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# ‚îÄ‚îÄ Compute score ranking ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "def compute_score(df, method):\n",
    "    df_scored = df.copy()\n",
    "    if method == \"logp\":\n",
    "        df_scored = df_scored[df_scored[\"LOG10P\"] > 0].copy()\n",
    "        df_scored[\"score\"] = df_scored[\"LOG10P\"]\n",
    "    elif method == \"chisq\":\n",
    "        df_scored = df_scored[df_scored[\"CHISQ\"] > 0].copy()\n",
    "        df_scored[\"score\"] = df_scored[\"CHISQ\"]\n",
    "    elif method == \"beta\":\n",
    "        df_scored = df_scored[df_scored[\"BETA\"].notna() & (df_scored[\"BETA\"] != 0)].copy()\n",
    "        if len(df_scored) == 0:\n",
    "            print(\"‚ö†Ô∏è  WARNING: No valid BETA values found!\")\n",
    "            return df_scored\n",
    "        df_scored[\"score\"] = df_scored[\"BETA\"].abs()\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown scoring method: {method}\")\n",
    "    return df_scored\n",
    "\n",
    "# ‚îÄ‚îÄ Extract gene/mask info from ID col ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "def extract_gene_mask_info(df, aaf_label):\n",
    "    id_parts = df[\"ID\"].str.split(\".\", expand=True)\n",
    "    if id_parts.shape[1] >= 3:\n",
    "        df[\"GENE\"] = id_parts[0]\n",
    "        df[\"MASK\"] = id_parts[1]\n",
    "        df[\"AAF_BIN\"] = aaf_label\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è  WARNING: ID format may not match expected GENE.MASK.AAF pattern\")\n",
    "        df[\"GENE\"] = df[\"ID\"]\n",
    "        df[\"MASK\"] = \"unknown\"\n",
    "        df[\"AAF_BIN\"] = aaf_label\n",
    "    return df\n",
    "\n",
    "# ‚îÄ‚îÄ Handle duplicates ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "def filter_duplicates(df, strategy=\"best_mask\"):\n",
    "    if strategy == \"keep_all\":\n",
    "        return df\n",
    "    elif strategy == \"highest_score\":\n",
    "        return df.loc[df.groupby(\"GENE\")[\"score\"].idxmax()].copy()\n",
    "    elif strategy == \"best_mask\":\n",
    "        mask_priority = {\"M1\": 1, \"M2\": 2, \"M3\": 3, \"M4\": 4}\n",
    "        df[\"mask_priority\"] = df[\"MASK\"].map(mask_priority).fillna(99)\n",
    "        best = df.loc[df.groupby(\"GENE\")[\"mask_priority\"].idxmin()].copy()\n",
    "        return best.drop(\"mask_priority\", axis=1)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown duplicate strategy: {strategy}\")\n",
    "\n",
    "# ‚îÄ‚îÄ Apply significance filtering ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "def apply_significance_filter(df, threshold):\n",
    "    if threshold is None:\n",
    "        return df\n",
    "\n",
    "    # Convert LOG10P back to p-value for filtering\n",
    "    if \"LOG10P\" in df.columns:\n",
    "        df_filtered = df[df[\"LOG10P\"] >= -np.log10(threshold)].copy()\n",
    "        print(f\"   Applied p < {threshold} filter: {len(df_filtered)} entries remain\")\n",
    "        return df_filtered\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è  WARNING: Cannot apply significance filter without LOG10P column\")\n",
    "        return df\n",
    "\n",
    "# ‚îÄ‚îÄ Load regenie results ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "def main():\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"LOVO GENE SELECTION FROM REGENIE BURDEN TEST RESULTS\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    # ‚îÄ‚îÄ validate parameters ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    print(\"\\nüîß Validating parameters...\")\n",
    "    if TOP_N <= 0:\n",
    "        print(f\"‚ùå ERROR: TOP_N must be positive, got {TOP_N}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    regenie_path = Path(REGENIE_FILE)\n",
    "    if not regenie_path.exists():\n",
    "        print(f\"‚ùå ERROR: Input file not found: {REGENIE_FILE}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    if SCORE_METHOD not in [\"logp\", \"chisq\", \"beta\"]:\n",
    "        print(f\"‚ùå ERROR: Invalid SCORE_METHOD: {SCORE_METHOD}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    if DUPLICATE_STRATEGY not in [\"best_mask\", \"keep_all\", \"highest_score\"]:\n",
    "        print(f\"‚ùå ERROR: Invalid DUPLICATE_STRATEGY: {DUPLICATE_STRATEGY}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    print(\"‚úÖ All parameters validated\")\n",
    "\n",
    "    # ‚îÄ‚îÄ load results ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    print(f\"\\nüìñ Loading REGENIE results from: {REGENIE_FILE}\")\n",
    "    try:\n",
    "        df = pd.read_csv(REGENIE_FILE, sep=r\"\\s+\", comment=\"#\", header=0)\n",
    "        print(f\"‚úÖ Loaded {len(df)} rows √ó {len(df.columns)} columns\")\n",
    "        print(f\"   Available tests: {', '.join(df['TEST'].unique())}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå ERROR loading file: {e}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    # ‚îÄ‚îÄ filter to test ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    print(f\"\\nüîé Filtering to test: {TEST_NAME}\")\n",
    "    df_test = df[df[\"TEST\"] == TEST_NAME].copy()\n",
    "    if df_test.empty:\n",
    "        print(f\"‚ùå ERROR: No results found for '{TEST_NAME}'\")\n",
    "        sys.exit(1)\n",
    "    print(f\"‚úÖ Found {len(df_test)} entries for {TEST_NAME}\")\n",
    "\n",
    "    # ‚îÄ‚îÄ extract gene and mask info ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    print(f\"\\nüß¨ Extracting gene and mask information...\")\n",
    "    df_test = extract_gene_mask_info(df_test, AAF_BIN_LABEL)\n",
    "    print(f\"‚úÖ Found {df_test['GENE'].nunique()} unique genes\")\n",
    "    print(\"   Mask distribution:\")\n",
    "    for mask, count in df_test['MASK'].value_counts().items():\n",
    "        print(f\"     {mask}: {count} entries\")\n",
    "\n",
    "    # ‚îÄ‚îÄ compute scores ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    print(f\"\\nüìä Computing scores (method: {SCORE_METHOD})\")\n",
    "    df_scored = compute_score(df_test, SCORE_METHOD)\n",
    "    if df_scored.empty:\n",
    "        print(f\"‚ùå ERROR: No valid scores with method '{SCORE_METHOD}'\")\n",
    "        sys.exit(1)\n",
    "    print(f\"‚úÖ {len(df_scored)} entries with valid scores\")\n",
    "    print(f\"   Score range: {df_scored['score'].min():.4f} ‚Üí {df_scored['score'].max():.4f}\")\n",
    "\n",
    "    # ‚îÄ‚îÄ apply significance filtering ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    if SIGNIFICANCE_THRESHOLD is not None:\n",
    "        print(f\"\\nüéØ Applying significance filtering (p < {SIGNIFICANCE_THRESHOLD})...\")\n",
    "        df_scored = apply_significance_filter(df_scored, SIGNIFICANCE_THRESHOLD)\n",
    "        if df_scored.empty:\n",
    "            print(f\"‚ùå ERROR: No significant results at p < {SIGNIFICANCE_THRESHOLD}\")\n",
    "            sys.exit(1)\n",
    "\n",
    "    # ‚îÄ‚îÄ handle duplicates ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    print(f\"\\nüîÑ Handling duplicate genes (strategy: {DUPLICATE_STRATEGY})...\")\n",
    "    initial_count = len(df_scored)\n",
    "    unique_genes_initial = df_scored['GENE'].nunique()\n",
    "\n",
    "    df_scored = filter_duplicates(df_scored, strategy=DUPLICATE_STRATEGY)\n",
    "\n",
    "    final_count = len(df_scored)\n",
    "    unique_genes_final = df_scored['GENE'].nunique()\n",
    "\n",
    "    print(f\"‚úÖ Deduplication complete:\")\n",
    "    print(f\"   Before: {initial_count} entries, {unique_genes_initial} unique genes\")\n",
    "    print(f\"   After:  {final_count} entries, {unique_genes_final} unique genes\")\n",
    "\n",
    "    # ‚îÄ‚îÄ select top entries ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    print(f\"\\nüèÜ Selecting top {TOP_N} entries\")\n",
    "    df_top = df_scored.sort_values(\"score\", ascending=False).head(TOP_N)\n",
    "\n",
    "    print(\"\\nTop gene‚Äìmask combinations:\")\n",
    "    print(\"-\" * 80)\n",
    "    for i, (_, row) in enumerate(df_top.iterrows(), 1):\n",
    "        score_label = {\"logp\": \"LOG10P\", \"chisq\": \"CHISQ\", \"beta\": \"|BETA|\"}[SCORE_METHOD]\n",
    "        print(f\"{i:2d}. {row['GENE']:<12} ({row['MASK']}) - {score_label}={row['score']:.4f}\")\n",
    "\n",
    "    # ‚îÄ‚îÄ write outputs ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    print(f\"\\nüíæ Writing LOVO gene list ‚Üí {OUTPUT_FILE}\")\n",
    "    with open(OUTPUT_FILE, \"w\") as fout:\n",
    "        # Write header\n",
    "        fout.write(\"GENE,MASK,AAF_BIN\\n\")\n",
    "        for _, row in df_top.iterrows():\n",
    "            fout.write(f\"{row['GENE']},{row['MASK']},{row['AAF_BIN']}\\n\")\n",
    "    print(f\"‚úÖ Saved {len(df_top)} entries to {OUTPUT_FILE}\")\n",
    "\n",
    "    # ‚îÄ‚îÄ summary ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"SUMMARY\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"üìÇ Input file: {REGENIE_FILE}\")\n",
    "    print(f\"üß™ Test analysed: {TEST_NAME}\")\n",
    "    print(f\"üìä Scoring method: {SCORE_METHOD}\")\n",
    "    print(f\"üîÑ Duplicate strategy: {DUPLICATE_STRATEGY}\")\n",
    "    print(f\"üéØ Significance filter: {SIGNIFICANCE_THRESHOLD if SIGNIFICANCE_THRESHOLD else 'None'}\")\n",
    "    print(f\"üìà Total entries analysed: {len(df_scored)}\")\n",
    "    print(f\"üèÜ Top entries selected: {TOP_N}\")\n",
    "    print(f\"üíæ Output file: {OUTPUT_FILE}\")\n",
    "\n",
    "    # ‚îÄ‚îÄ detailed results ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    base_cols = [\"GENE\", \"MASK\", \"AAF_BIN\"]\n",
    "    optional_cols = [c for c in [\"BETA\", \"LOG10P\", \"CHISQ\"] if c in df_top.columns]\n",
    "    display_cols = base_cols + optional_cols\n",
    "    print(\"\\nüìã Detailed results:\")\n",
    "    print(df_top[display_cols].to_string(index=False, float_format=\"%.4f\"))\n",
    "\n",
    "    print(\"\\nLOVO gene list format (GENE,MASK,AAF_BIN):\")\n",
    "    for _, row in df_top.iterrows():\n",
    "        print(f\"{row['GENE']},{row['MASK']},{row['AAF_BIN']}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "id": "fd5ef16739dfd24c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "LOVO GENE SELECTION FROM REGENIE BURDEN TEST RESULTS\n",
      "================================================================================\n",
      "\n",
      "üîß Validating parameters...\n",
      "‚úÖ All parameters validated\n",
      "\n",
      "üìñ Loading REGENIE results from: C:\\Users\\B00731414\\OneDrive - Ulster University\\6. Code\\ADNI\\4. Gene Burden\\03_Regenie\\step 2\\S2_ADNI_burden_AD_vs_CN.regenie\n",
      "‚úÖ Loaded 1084 rows √ó 13 columns\n",
      "   Available tests: ADD-ACATO, ADD-ACATV, ADD-SKAT, ADD-SKATO, ADD\n",
      "\n",
      "üîé Filtering to test: ADD-SKATO\n",
      "‚úÖ Found 216 entries for ADD-SKATO\n",
      "\n",
      "üß¨ Extracting gene and mask information...\n",
      "‚úÖ Found 116 unique genes\n",
      "   Mask distribution:\n",
      "     M4: 112 entries\n",
      "     M3: 52 entries\n",
      "     M2: 49 entries\n",
      "     M1: 3 entries\n",
      "\n",
      "üìä Computing scores (method: logp)\n",
      "‚úÖ 216 entries with valid scores\n",
      "   Score range: 0.0004 ‚Üí 1.1118\n",
      "\n",
      "üîÑ Handling duplicate genes (strategy: keep_all)...\n",
      "‚úÖ Deduplication complete:\n",
      "   Before: 216 entries, 116 unique genes\n",
      "   After:  216 entries, 116 unique genes\n",
      "\n",
      "üèÜ Selecting top 10 entries\n",
      "\n",
      "Top gene‚Äìmask combinations:\n",
      "--------------------------------------------------------------------------------\n",
      " 1. ITGA8        (M3) - LOG10P=1.1118\n",
      " 2. ITGA8        (M4) - LOG10P=1.1118\n",
      " 3. ITGA8        (M2) - LOG10P=1.1118\n",
      " 4. GTDC1        (M4) - LOG10P=0.6991\n",
      " 5. GIPR         (M4) - LOG10P=0.6910\n",
      " 6. RNF6         (M4) - LOG10P=0.6781\n",
      " 7. SUGP2        (M4) - LOG10P=0.6415\n",
      " 8. SUGP2        (M3) - LOG10P=0.6415\n",
      " 9. SUGP2        (M2) - LOG10P=0.6415\n",
      "10. ADAMTS16     (M4) - LOG10P=0.6147\n",
      "\n",
      "üíæ Writing LOVO gene list ‚Üí lovo_genes.txt\n",
      "‚úÖ Saved 10 entries to lovo_genes.txt\n",
      "\n",
      "================================================================================\n",
      "SUMMARY\n",
      "================================================================================\n",
      "üìÇ Input file: C:\\Users\\B00731414\\OneDrive - Ulster University\\6. Code\\ADNI\\4. Gene Burden\\03_Regenie\\step 2\\S2_ADNI_burden_AD_vs_CN.regenie\n",
      "üß™ Test analysed: ADD-SKATO\n",
      "üìä Scoring method: logp\n",
      "üîÑ Duplicate strategy: keep_all\n",
      "üéØ Significance filter: None\n",
      "üìà Total entries analysed: 216\n",
      "üèÜ Top entries selected: 10\n",
      "üíæ Output file: lovo_genes.txt\n",
      "\n",
      "üìã Detailed results:\n",
      "    GENE MASK AAF_BIN  BETA  LOG10P  CHISQ\n",
      "   ITGA8   M3     all   NaN  1.1118 3.1206\n",
      "   ITGA8   M4     all   NaN  1.1118 3.1206\n",
      "   ITGA8   M2     all   NaN  1.1118 3.1206\n",
      "   GTDC1   M4     all   NaN  0.6991 1.6427\n",
      "    GIPR   M4     all   NaN  0.6910 1.6155\n",
      "    RNF6   M4     all   NaN  0.6781 1.5725\n",
      "   SUGP2   M4     all   NaN  0.6415 1.4513\n",
      "   SUGP2   M3     all   NaN  0.6415 1.4513\n",
      "   SUGP2   M2     all   NaN  0.6415 1.4513\n",
      "ADAMTS16   M4     all   NaN  0.6147 1.3639\n",
      "\n",
      "LOVO gene list format (GENE,MASK,AAF_BIN):\n",
      "ITGA8,M3,all\n",
      "ITGA8,M4,all\n",
      "ITGA8,M2,all\n",
      "GTDC1,M4,all\n",
      "GIPR,M4,all\n",
      "RNF6,M4,all\n",
      "SUGP2,M4,all\n",
      "SUGP2,M3,all\n",
      "SUGP2,M2,all\n",
      "ADAMTS16,M4,all\n"
     ]
    }
   ],
   "execution_count": 5
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
