{
 "cells": [
  {
   "metadata": {},
   "cell_type": "raw",
   "source": [
    "# ADNI Gene Burden Analysis with REGENIE\n",
    "\n",
    "Notebook for rare variant burden testing in Alzheimer‚Äôs Disease using ADNI data, following UK Biobank/DNAnexus gene burden analysis WES protocols.\n",
    "\n",
    "**Key Steps**\n",
    "\n",
    "0. Environment setup (Conda, REGENIE, PLINK, ANNOVAR)\n",
    "1. Data QC & PCA\n",
    "2. Functional annotation (Ensembl via ANNOVAR ‚Üí REGENIE formats: `.annotations.txt`, `.sets.txt`, `.masks`)\n",
    "3. REGENIE two-step analysis:\n",
    "   - Step 1: Null model fitting (common variants, MAF > 1%, 10 PCs)\n",
    "   - Step 2: Gene-based burden tests (rare variants, MAF 0.005‚Äì0.01) across masks:\n",
    "     - M1: Loss-of-function\n",
    "     - M2: Missense\n",
    "     - M3: LoF + missense\n",
    "     - M4: All coding\n",
    "4. LOVO gene selection (top 10 genes, SKAT-O)\n",
    "\n",
    "**Dataset**: ADNI1\n",
    "**Genome Build**: GRCh36/hg18\n",
    "**Software**: REGENIE v4.1, PLINK v1.9, ANNOVAR, Python\n",
    "**References**:\n",
    "- UK Biobank RAP ‚ÄúBurden testing with WES‚Äù tutorial  https://dnanexus.gitbook.io/uk-biobank-rap/science-corner/burden-testing-with-wes\n",
    "- REGENIE documentation https://rgcgithub.github.io/regenie/options/\n"
   ],
   "id": "1259b0fa3b6e7f23"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 0. Environment setup (kelvin2)",
   "id": "98c43f6898dd7f42"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 00_environment\n",
    "# i. create conda environment in NI-HPC kelvin2\n",
    "\n",
    "conda env create -f regenie-env.yml\n",
    "\n",
    "conda activate regenie-env"
   ],
   "id": "ad3fab68ef4f2230",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 1. Data prep & qc",
   "id": "a0adc64fc8c65c26"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 01_data_prep_qc\n",
    "# x. Liftover\n",
    "\n",
    "# try without liftover\n"
   ],
   "id": "6fe6f045b87a3343",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%%bash\n",
    "\n",
    "# 01_data_prep_qc\n",
    "# i. PLINK QC for Rare Variants\n",
    "\n",
    "##############################################################\n",
    "# USER-DEFINED INPUTS (EDIT HERE) #\n",
    "##############################################################\n",
    "\n",
    "BFILE=\"/mnt/c/Users/B00731414/OneDrive - Ulster University/6. Code/ADNI/4. Gene Burden/01_data_prep_qc_ADNI1/inputs/ADNI_cluster_01_forward_757LONI\"\n",
    "OUTPUT=\"/mnt/c/Users/B00731414/OneDrive - Ulster University/6. Code/ADNI/4. Gene Burden/01_data_prep_qc_ADNI1/outputs/ADNI1_preQC\"\n",
    "\n",
    "\n",
    "##############################################################\n",
    "# DO NOT EDIT BELOW THIS LINE #\n",
    "##############################################################\n",
    "\n",
    "\n",
    "# ‚îÄ‚îÄ QC rare variants ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "plink --bfile \"$BFILE\" \\\n",
    "      --maf 0.005 \\\n",
    "      --max-maf 0.01 \\\n",
    "      --geno 0.05 \\\n",
    "      --mind 0.05 \\\n",
    "      --hwe 1e-6 \\\n",
    "      --mac 1 \\\n",
    "      --not-chr 0 \\\n",
    "      --output-chr MT \\\n",
    "      --make-bed \\\n",
    "      --out \"$OUTPUT\"\n",
    "STATUS=$?\n",
    "\n",
    "if [ $STATUS -ne 0 ]; then\n",
    "  echo \"‚ùå ERROR: PLINK QC failed with exit code $STATUS\"\n",
    "  exit $STATUS\n",
    "fi\n",
    "\n",
    "echo \"‚úÖ Files saved: ${OUTPUT}.[bed|bim|fam]\"\n",
    "echo \"üèÅ QC (rare) complete.\""
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%%bash\n",
    "\n",
    "# 01_data_prep_qc\n",
    "# ii. PLINK QC for Common Variants (to create null model for regenie step 1)\n",
    "\n",
    "##############################################################\n",
    "# USER-DEFINED INPUTS (EDIT HERE) #\n",
    "##############################################################\n",
    "\n",
    "BFILE=\"/mnt/c/Users/B00731414/OneDrive - Ulster University/6. Code/ADNI/4. Gene Burden/01_data_prep_qc_ADNI1/inputs/ADNI_cluster_01_forward_757LONI\"\n",
    "\n",
    "OUTPUT=\"/mnt/c/Users/B00731414/OneDrive - Ulster University/6. Code/ADNI/4. Gene Burden/01_data_prep_qc_ADNI1/outputs/ADNI1_preQC_common\"\n",
    "\n",
    "##############################################################\n",
    "# DO NOT EDIT BELOW THIS LINE #\n",
    "##############################################################\n",
    "\n",
    "# ‚îÄ‚îÄ QC common variants ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "plink --bfile \"$BFILE\" \\\n",
    "      --maf 0.01 \\\n",
    "      --geno 0.05 \\\n",
    "      --mind 0.05 \\\n",
    "      --hwe 1e-6 \\\n",
    "      --mac 1 \\\n",
    "      --not-chr 0 \\\n",
    "      --output-chr MT \\\n",
    "      --make-bed \\\n",
    "      --out \"$OUTPUT\"\n",
    "STATUS=$?\n",
    "\n",
    "if [ $STATUS -ne 0 ]; then\n",
    "  echo \"‚ùå ERROR: PLINK QC failed with exit code $STATUS\"\n",
    "  exit $STATUS\n",
    "fi\n",
    "\n",
    "echo \"‚úÖ Files saved: ${OUTPUT}.[bed|bim|fam]\"\n",
    "echo \"üèÅ QC (common) complete.\""
   ],
   "id": "9ac1df6bacbdad23",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%%bash\n",
    "\n",
    "# 01_data_prep_qc\n",
    "# iii. PLINK LD pruning common variants set\n",
    "\n",
    "##############################################################\n",
    "# USER-DEFINED INPUTS (EDIT HERE) #\n",
    "##############################################################\n",
    "\n",
    "BFILE=\"/mnt/c/Users/B00731414/OneDrive - Ulster University/6. Code/ADNI/4. Gene Burden/01_Data_Prep_QC_ADNI1/outputs/ADNI1_preQC_common\"\n",
    "\n",
    "OUTPUT=\"/mnt/c/Users/B00731414/OneDrive - Ulster University/6. Code/ADNI/4. Gene Burden/01_Data_Prep_QC_ADNI1/outputs/ADNI1_pruned\"\n",
    "\n",
    "##############################################################\n",
    "# DO NOT EDIT BELOW THIS LINE #\n",
    "##############################################################\n",
    "\n",
    "plink \\\n",
    "  --bfile \"$BFILE\" \\\n",
    "  --indep-pairwise 200 50 0.3 \\\n",
    "  --out \"$OUTPUT\"\n",
    "STATUS=$?\n",
    "\n",
    "if [ $STATUS -ne 0 ]; then\n",
    "  echo \"‚ùå ERROR: PLINK QC failed with exit code $STATUS\"\n",
    "  exit $STATUS\n",
    "fi\n",
    "\n",
    "echo \"‚úÖ Files saved: ${OUTPUT}\"\n",
    "echo \"üèÅ LD pruning complete."
   ],
   "id": "6c16fc293296172a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%%bash\n",
    "\n",
    "# 01_data_prep_qc\n",
    "# iv. PLINK PCA generation on common variants set\n",
    "\n",
    "##############################################################\n",
    "# USER-DEFINED INPUTS (EDIT HERE) #\n",
    "##############################################################\n",
    "\n",
    "BFILE=\"/mnt/c/Users/B00731414/OneDrive - Ulster University/6. Code/ADNI/4. Gene Burden/01_Data_Prep_QC_ADNI1/outputs/ADNI1_preQC_common\"\n",
    "\n",
    "PRUNED=\"/mnt/c/Users/B00731414/OneDrive - Ulster University/6. Code/ADNI/4. Gene Burden/01_Data_Prep_QC_ADNI1/outputs/ADNI1_pruned.prune.in\"\n",
    "\n",
    "OUTPUT=\"/mnt/c/Users/B00731414/OneDrive - Ulster University/6. Code/ADNI/4. Gene Burden/01_Data_Prep_QC_ADNI1/outputs/ADNI1_PCA\"\n",
    "\n",
    "##############################################################\n",
    "# DO NOT EDIT BELOW THIS LINE #\n",
    "##############################################################\n",
    "\n",
    "plink \\\n",
    "  --bfile \"$BFILE\" \\\n",
    "  --extract \"$PRUNED\" \\\n",
    "  --pca 10 header \\\n",
    "  --out \"$OUTPUT\"\n",
    "STATUS=$?\n",
    "\n",
    "if [ $STATUS -ne 0 ]; then\n",
    "  echo \"‚ùå ERROR: PLINK QC failed with exit code $STATUS\"\n",
    "  exit $STATUS\n",
    "fi\n",
    "\n",
    "echo \"‚úÖ Files saved: ${OUTPUT}\"\n",
    "echo \"üèÅ PCA complete.\""
   ],
   "id": "a459d39a1389da24",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 01_Data_Prep_QC\n",
    "# v. Generate Phenotype and Covariate Files\n",
    "# Python script\n",
    "\n",
    "##############################################################\n",
    "# USER-DEFINED INPUTS (EDIT HERE) #\n",
    "##############################################################\n",
    "\n",
    "# Paths to input files\n",
    "ADNI_MERGE_PATH = r\"C:\\Users\\B00731414\\OneDrive - Ulster University\\6. Code\\ADNI\\4. Gene Burden\\01_data_prep_qc_ADNI1\\inputs\\ADNIMERGE_15May2025.csv\"\n",
    "\n",
    "PLINK_FAM_PATH  = r\"C:\\Users\\B00731414\\OneDrive - Ulster University\\6. Code\\ADNI\\4. Gene Burden\\01_data_prep_qc_ADNI1\\outputs\\ADNI1_preQC.fam\"\n",
    "\n",
    "# Path to output directory\n",
    "OUTPUT_DIR = Path(r\"C:\\Users\\B00731414\\OneDrive - Ulster University\\6. Code\\ADNI\\4. Gene Burden\\01_data_prep_qc_ADNI1\\outputs\")\n",
    "\n",
    "##############################################################\n",
    "# DO NOT EDIT BELOW THIS LINE #\n",
    "##############################################################\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "def main():\n",
    "    print(\"üì• Loading ADNI phenotype and PLINK sample data...\")\n",
    "    # Load ADNI phenotype data\n",
    "    adni_data = pd.read_csv(ADNI_MERGE_PATH, low_memory=False)\n",
    "    # Load PLINK .fam file\n",
    "    plink_fam = pd.read_csv(\n",
    "        PLINK_FAM_PATH, sep=r'\\s+', header=None,\n",
    "        names=['FID', 'IID', 'PAT', 'MAT', 'SEX', 'PHENOTYPE']\n",
    "    )\n",
    "\n",
    "# ‚îÄ‚îÄ Filter to baseline AD vs CN ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "    ad_cn_data = adni_data[\n",
    "        (adni_data['VISCODE'] == 'bl') &\n",
    "        (adni_data['DX_bl'].isin(['AD', 'CN']))\n",
    "    ].copy()\n",
    "    print(f\"üîç Baseline AD vs CN: {len(ad_cn_data)} samples (before matching)\")\n",
    "\n",
    "# ‚îÄ‚îÄ Match PTID to IID and create FID mapping ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "    ad_cn_data['IID'] = ad_cn_data['PTID'].astype(str)\n",
    "    ad_cn_data = ad_cn_data[ad_cn_data['IID'].isin(plink_fam['IID'].astype(str))]\n",
    "    iid_to_fid = dict(zip(plink_fam['IID'].astype(str), plink_fam['FID']))\n",
    "    ad_cn_data['FID'] = ad_cn_data['IID'].map(iid_to_fid)\n",
    "\n",
    "    if ad_cn_data['FID'].isnull().any():\n",
    "        missing = ad_cn_data[ad_cn_data['FID'].isnull()]['IID'].tolist()\n",
    "        print(\"‚ö†Ô∏è WARNING: Some samples could not be mapped to FIDs\")\n",
    "        print(f\"Missing FID for: {missing}\")\n",
    "\n",
    "    print(f\"‚úÖ After genetic match: {len(ad_cn_data)} samples => \"\n",
    "          f\"{(ad_cn_data['DX_bl']=='AD').sum()} AD, {(ad_cn_data['DX_bl']=='CN').sum()} CN\")\n",
    "\n",
    "# ‚îÄ‚îÄ Create phenotype & covars ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "    ad_cn_data['AD_vs_CN'] = ad_cn_data['DX_bl'].map({'AD':1, 'CN':0})\n",
    "    ad_cn_data['sex']       = ad_cn_data['PTGENDER'].map({'Male':1, 'Female':0})\n",
    "    ad_cn_data['age']       = ad_cn_data['AGE']\n",
    "    ad_cn_data['education'] = ad_cn_data['PTEDUCAT']\n",
    "    ad_cn_data['apoe4_count']=ad_cn_data['APOE4']\n",
    "\n",
    "    phenotype_cols = ['FID','IID','AD_vs_CN','age','sex','education','apoe4_count','PTID','DX_bl']\n",
    "    pheno_df = ad_cn_data[phenotype_cols].dropna(\n",
    "        subset=['AD_vs_CN','age','sex','education','apoe4_count']\n",
    "    )\n",
    "    print(f\"üîç Final sample size: {len(pheno_df)} \"\n",
    "          f\"({(pheno_df['AD_vs_CN']==1).sum()} AD, {(pheno_df['AD_vs_CN']==0).sum()} CN)\")\n",
    "\n",
    "# ‚îÄ‚îÄ Check FID alignment with FAM file ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "    print(\"\\nüîß Verifying FID alignment with FAM file...\")\n",
    "    fam_sample  = plink_fam[plink_fam['IID'].isin(pheno_df['IID'])][['FID','IID']].head()\n",
    "    pheno_sample= pheno_df[['FID','IID']].head()\n",
    "    print(\"FAM file FID/IID mapping (sample):\"); print(fam_sample)\n",
    "    print(\"\\nPhenotype file FID/IID mapping (sample):\"); print(pheno_sample)\n",
    "\n",
    "    merged = pheno_df.merge(\n",
    "        plink_fam[['FID','IID']], on='IID', suffixes=('_pheno','_fam')\n",
    "    )\n",
    "    if (merged['FID_pheno']==merged['FID_fam']).all():\n",
    "        print(\"‚úÖ FID alignment check: PASS\")\n",
    "    else:\n",
    "        mismatches = merged[merged['FID_pheno']!=merged['FID_fam']]\n",
    "        print(\"‚ùå FID alignment check: FAIL\")\n",
    "        print(f\"Number of mismatches: {len(mismatches)}\")\n",
    "\n",
    "# ‚îÄ‚îÄ Save outputs ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    pheno_df[['FID','IID','AD_vs_CN']].to_csv(\n",
    "        OUTPUT_DIR/\"ADNI_AD_vs_CN_phenotypes.txt\", sep='\\t',\n",
    "        index=False, na_rep='NA'\n",
    "    )\n",
    "    pheno_df[['FID','IID','age','sex','education','apoe4_count']].to_csv(\n",
    "        OUTPUT_DIR/\"ADNI_AD_vs_CN_covariates.txt\", sep='\\t',\n",
    "        index=False, na_rep='NA'\n",
    "    )\n",
    "    pheno_df.to_csv(\n",
    "        OUTPUT_DIR/\"ADNI_AD_vs_CN_summary.txt\", sep='\\t',\n",
    "        index=False, na_rep='NA'\n",
    "    )\n",
    "    summary_stats = pheno_df.groupby('DX_bl').agg({\n",
    "        'age':['count','mean','std'],\n",
    "        'sex':'mean',\n",
    "        'education':['mean','std'],\n",
    "        'apoe4_count':['mean','std']\n",
    "    }).round(2)\n",
    "    summary_stats.to_csv(\n",
    "        OUTPUT_DIR/\"ADNI_AD_vs_CN_summary_stats.txt\", sep='\\t'\n",
    "    )\n",
    "\n",
    "    print(f\"\\n‚úÖ Files saved to: {OUTPUT_DIR}\")\n",
    "    print(f\"\\nüèÅ Pheno & covar creation complete.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ],
   "id": "4146c6a5b511e3ba",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 01_Data_Prep_QC\n",
    "# vi. Merge covars with PCA data\n",
    "# Python script\n",
    "\n",
    "\n",
    "##############################################################\n",
    "# USER-DEFINED INPUTS (EDIT HERE) #\n",
    "##############################################################\n",
    "\n",
    "covar_file = r\"C:\\Users\\B00731414\\OneDrive - Ulster University\\6. Code\\ADNI\\4. Gene Burden\\01_data_prep_qc_ADNI1\\outputs\\ADNI_AD_vs_CN_covariates.txt\"\n",
    "\n",
    "pca_file = r\"C:\\Users\\B00731414\\OneDrive - Ulster University\\6. Code\\ADNI\\4. Gene Burden\\01_data_prep_qc_ADNI1\\outputs\\ADNI1_PCA.eigenvec\"\n",
    "\n",
    "output_file = r\"C:\\Users\\B00731414\\OneDrive - Ulster University\\6. Code\\ADNI\\4. Gene Burden\\01_data_prep_qc_ADNI1\\outputs\\ADNI1_PCA_merged_covariates.txt\"\n",
    "\n",
    "# Number of PCs to include\n",
    "num_pcs = 10\n",
    "\n",
    "##############################################################\n",
    "# DO NOT EDIT BELOW THIS LINE #\n",
    "##############################################################\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import List, Optional\n",
    "\n",
    "# ‚îÄ‚îÄ Check input files ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "def validate_input_files(covar_path: str, pca_path: str) -> None:\n",
    "    print(\"üîç Checking input files...\")\n",
    "\n",
    "    if not os.path.exists(covar_path):\n",
    "        raise FileNotFoundError(f\"‚ùå Covariates file not found: {covar_path}\")\n",
    "\n",
    "    if not os.path.exists(pca_path):\n",
    "        raise FileNotFoundError(f\"‚ùå PCA file not found: {pca_path}\")\n",
    "\n",
    "    print(f\"‚úÖ Covariates file found: {Path(covar_path).name}\")\n",
    "    print(f\"‚úÖ PCA file found: {Path(pca_path).name}\")\n",
    "\n",
    "# ‚îÄ‚îÄ Load PCA scores  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "def load_pca_data(pca_path: str, num_pcs: int) -> pd.DataFrame:\n",
    "    print(f\"üìñ Loading PCA data with {num_pcs} components...\")\n",
    "\n",
    "    try:\n",
    "        # Define column names for PCA file\n",
    "        pca_columns = [\"FID\", \"IID\"] + [f\"PC{i}\" for i in range(1, num_pcs + 1)]\n",
    "\n",
    "        pca = pd.read_csv(\n",
    "            pca_path,\n",
    "            sep=r'\\s+',\n",
    "            header=0,\n",
    "            names=pca_columns,\n",
    "            dtype={\"FID\": str, \"IID\": str}\n",
    "        )\n",
    "\n",
    "        print(f\"‚úÖ Loaded {len(pca)} samples with {num_pcs} PCs\")\n",
    "        return pca\n",
    "\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"‚ùå Error loading PCA data: {e}\")\n",
    "\n",
    "# ‚îÄ‚îÄ Load covar data w/ str IDs ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "def load_covariate_data(covar_path: str) -> pd.DataFrame:\n",
    "    print(\"üìñ Loading covariate data...\")\n",
    "\n",
    "    try:\n",
    "        cov = pd.read_csv(covar_path, sep='\\t', dtype=str)\n",
    "\n",
    "        # Validate required columns\n",
    "        if 'FID' not in cov.columns or 'IID' not in cov.columns:\n",
    "            raise ValueError(\"Covariate file must contain 'FID' and 'IID' columns\")\n",
    "\n",
    "        print(f\"‚úÖ Loaded {len(cov)} samples with {len(cov.columns)} covariates\")\n",
    "        print(f\"   Covariate columns: {', '.join(cov.columns.tolist())}\")\n",
    "        return cov\n",
    "\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"‚ùå Error loading covariate data: {e}\")\n",
    "\n",
    "# ‚îÄ‚îÄ Merge covar and PCA ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "def merge_data(cov: pd.DataFrame, pca: pd.DataFrame, num_pcs: int) -> pd.DataFrame:\n",
    "    print(\"üîó Merging covariate and PCA data...\")\n",
    "\n",
    "    # Check for sample overlap\n",
    "    common_samples = set(cov['IID']) & set(pca['IID'])\n",
    "    cov_only = set(cov['IID']) - set(pca['IID'])\n",
    "    pca_only = set(pca['IID']) - set(cov['IID'])\n",
    "\n",
    "    print(f\"   Common samples: {len(common_samples)}\")\n",
    "    if cov_only:\n",
    "        print(f\"   ‚ö†Ô∏è  Samples in covariates only: {len(cov_only)}\")\n",
    "    if pca_only:\n",
    "        print(f\"   ‚ö†Ô∏è  Samples in PCA only: {len(pca_only)}\")\n",
    "\n",
    "    # Merge on IID, keeping covariate FID and dropping PCA FID\n",
    "    try:\n",
    "        df = pd.merge(cov, pca.drop(columns=\"FID\"), on=\"IID\", how=\"inner\")\n",
    "\n",
    "        # Reorder columns: covariate columns first, then PCs\n",
    "        cov_cols = cov.columns.tolist()\n",
    "        pc_cols = [f\"PC{i}\" for i in range(1, num_pcs + 1)]\n",
    "        df = df[cov_cols + pc_cols]\n",
    "\n",
    "        print(f\"‚úÖ Successfully merged data: {len(df)} samples\")\n",
    "        return df\n",
    "\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"‚ùå Error merging data: {e}\")\n",
    "\n",
    "# ‚îÄ‚îÄ Save merged data ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "def save_merged_data(df: pd.DataFrame, output_path: str) -> None:\n",
    "    print(\"üíæ Saving merged covariate-PCA file...\")\n",
    "\n",
    "    try:\n",
    "        # Create output directory if it doesn't exist\n",
    "        output_dir = Path(output_path).parent\n",
    "        output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        # Save with tab delimiter\n",
    "        df.to_csv(output_path, sep='\\t', index=False)\n",
    "\n",
    "        print(f\"‚úÖ Merged file saved: {Path(output_path).name}\")\n",
    "        print(f\"   Location: {output_path}\")\n",
    "        print(f\"   Dimensions: {df.shape[0]} rows √ó {df.shape[1]} columns\")\n",
    "\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"‚ùå Error saving merged data: {e}\")\n",
    "\n",
    "# ‚îÄ‚îÄ Check data ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "def validate_output(df: pd.DataFrame, num_pcs: int) -> None:\n",
    "\n",
    "    print(\"üîç Checking merged data...\")\n",
    "\n",
    "    # Check for required columns\n",
    "    required_cols = ['FID', 'IID'] + [f\"PC{i}\" for i in range(1, num_pcs + 1)]\n",
    "    missing_cols = [col for col in required_cols if col not in df.columns]\n",
    "\n",
    "    if missing_cols:\n",
    "        print(f\"‚ö†Ô∏è  Warning: Missing expected columns: {missing_cols}\")\n",
    "\n",
    "    # Check for missing values in key columns\n",
    "    na_counts = df[['FID', 'IID']].isna().sum()\n",
    "    if na_counts.any():\n",
    "        print(f\"‚ö†Ô∏è  Warning: Missing values in ID columns: {na_counts.to_dict()}\")\n",
    "\n",
    "    # Display sample of merged data\n",
    "    print(\"\\nüìã Sample of merged data:\")\n",
    "    print(df.head(3).to_string(index=False))\n",
    "\n",
    "    print(\"‚úÖ Data check complete\")\n",
    "\n",
    "# ‚îÄ‚îÄ Main function ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "def main():\n",
    "    print(\"=\" * 60)\n",
    "    print(\"COVARIATE-PCA DATA MERGER\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    try:\n",
    "        # Validate input files\n",
    "        validate_input_files(covar_file, pca_file)\n",
    "\n",
    "        # Load data\n",
    "        pca_data = load_pca_data(pca_file, num_pcs)\n",
    "        covar_data = load_covariate_data(covar_file)\n",
    "\n",
    "        # Merge data\n",
    "        merged_data = merge_data(covar_data, pca_data, num_pcs)\n",
    "\n",
    "        # Save merged data\n",
    "        save_merged_data(merged_data, output_file)\n",
    "\n",
    "        # Validate output\n",
    "        validate_output(merged_data, num_pcs)\n",
    "\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"üèÅ MERGE COMPLETE\")\n",
    "        print(\"=\" * 60)\n",
    "        print(f\"‚úÖ Successfully created merged covariate-PCA file\")\n",
    "        print(f\"‚úÖ Ready for REGENIE analysis\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå ERROR: {e}\")\n",
    "        print(\"Please check your input files and try again.\")\n",
    "        exit(1)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "id": "b50b2df6ca549e3a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%%bash\n",
    "\n",
    "# 01_Data_Prep_QC\n",
    "# vii. Convert to vcf\n",
    "\n",
    "##############################################################\n",
    "# USER-DEFINED INPUTS (EDIT HERE) #\n",
    "##############################################################\n",
    "\n",
    "INPUT=\"/mnt/c/Users/B00731414/OneDrive - Ulster University/6. Code/ADNI/4. Gene Burden/01_data_prep_qc_ADNI1/outputs/ADNI1_preQC\"\n",
    "\n",
    "OUTPUT=\"/mnt/c/Users/B00731414/OneDrive - Ulster University/6. Code/ADNI/4. Gene Burden/02_annotations_ADNI1/inputs/vcf/ADNI1_preQC_converted\"\n",
    "\n",
    "##############################################################\n",
    "# DO NOT EDIT BELOW THIS LINE #\n",
    "##############################################################\n",
    "\n",
    "plink \\\n",
    "    --bfile \"${INPUT}\" \\\n",
    "    --recode vcf \\\n",
    "    --out \"${OUTPUT}\"\n",
    "STATUS=$?\n",
    "\n",
    "if [ $STATUS -ne 0 ]; then\n",
    "  echo \"‚ùå ERROR: vcf recode failed with exit code $STATUS\"\n",
    "  exit $STATUS\n",
    "fi\n",
    "\n",
    "echo \"‚úÖ Files saved: ${OUTPUT}\"\n",
    "echo \"üèÅ VCF conversion complete\"\n"
   ],
   "id": "7dd2ca178be9a181",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2. Annotation",
   "id": "db812af91481d018"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%%bash\n",
    "\n",
    "# 02_annotation\n",
    "# i. Ensembl Gene Annotation with ANNOVAR\n",
    "\n",
    "##############################################################\n",
    "# USER-DEFINED INPUTS (EDIT HERE) #\n",
    "##############################################################\n",
    "\n",
    "BASE_DIR=\"/mnt/c/Users/B00731414/OneDrive - Ulster University/6. Code/ADNI/4. Gene Burden/02_Annotations_ADNI1\"\n",
    "\n",
    "INPUT_VCF=\"./inputs/vcf/ADNI1_preQC_converted.vcf\"\n",
    "\n",
    "BUILD=\"hg18\"\n",
    "\n",
    "OUTPUT_DIR=\"./outputs\"\n",
    "\n",
    "ANNOVAR_DB_DIR=\"./inputs/annovar_db\"\n",
    "\n",
    "ANNOVAR_SCRIPTS_DIR=\"./inputs/annovar_db/annovar\"\n",
    "ANNOVAR_PATH=\"${ANNOVAR_SCRIPTS_DIR}/table_annovar.pl\"\n",
    "ANNOTATE_VAR_PATH=\"${ANNOVAR_SCRIPTS_DIR}/annotate_variation.pl\"\n",
    "\n",
    "# Extract project name from input VCF for consistent naming\n",
    "PROJECT_NAME=$(basename \"$INPUT_VCF\" | sed 's/_preQC_converted\\.vcf$//')\n",
    "\n",
    "##############################################################\n",
    "# DO NOT EDIT BELOW THIS LINE #\n",
    "##############################################################\n",
    "\n",
    "set -euo pipefail\n",
    "\n",
    "# ‚îÄ‚îÄ Change to base directory ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "cd \"$BASE_DIR\" || {\n",
    "    echo \"‚ùå ERROR: Failed to change directory to $BASE_DIR\"\n",
    "    exit 1\n",
    "}\n",
    "\n",
    "echo \"üîß Checking ANNOVAR setup...\"\n",
    "echo \"üìã Build version: $BUILD\"\n",
    "echo \"üìÅ Project: $PROJECT_NAME\"\n",
    "\n",
    "# ‚îÄ‚îÄ Verify required scripts exist ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "if [ ! -f \"$ANNOTATE_VAR_PATH\" ]; then\n",
    "    echo \"‚ùå ERROR: annotate_variation.pl not found at $ANNOTATE_VAR_PATH\"\n",
    "    echo \"Please ensure ANNOVAR scripts are in the correct location\"\n",
    "    exit 1\n",
    "fi\n",
    "\n",
    "if [ ! -f \"$ANNOVAR_PATH\" ]; then\n",
    "    echo \"‚ùå ERROR: table_annovar.pl not found at $ANNOVAR_PATH\"\n",
    "    exit 1\n",
    "fi\n",
    "\n",
    "# ‚îÄ‚îÄ Check and download ensGene database if needed ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "ENSEMBL_DB_FILE=\"${ANNOVAR_DB_DIR}/${BUILD}_ensGene.txt\"\n",
    "\n",
    "if [ ! -f \"$ENSEMBL_DB_FILE\" ]; then\n",
    "    echo \"‚ùå ERROR: ${BUILD}_ensGene.txt database not found\"\n",
    "    echo \"üîÑ Attempting to download ensGene database for $BUILD...\"\n",
    "\n",
    "    # Download ensGene database using script paths\n",
    "    perl \"$ANNOTATE_VAR_PATH\" \\\n",
    "        -buildver \"$BUILD\" \\\n",
    "        -downdb -webfrom annovar ensGene \\\n",
    "        \"$ANNOVAR_DB_DIR/\"\n",
    "\n",
    "    if [ ! -f \"$ENSEMBL_DB_FILE\" ]; then\n",
    "        echo \"‚ùå ERROR: Failed to download ensGene database for $BUILD\"\n",
    "        echo \"üí° Available builds may be limited. Check ANNOVAR documentation.\"\n",
    "        exit 1\n",
    "    fi\n",
    "    echo \"‚úÖ ensGene database for $BUILD downloaded successfully\"\n",
    "else\n",
    "    echo \"‚úÖ ensGene database for $BUILD found\"\n",
    "fi\n",
    "\n",
    "# ‚îÄ‚îÄ Make scripts executable ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "chmod +x \"$ANNOVAR_SCRIPTS_DIR\"/*.pl\n",
    "\n",
    "# ‚îÄ‚îÄ Create output directory ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "mkdir -p \"$OUTPUT_DIR\"\n",
    "\n",
    "echo \"üîÑ Setting up Ensembl gene annotations...\"\n",
    "echo \"‚è≥ Annotating VCF: $INPUT_VCF with Ensembl genes (Build: $BUILD)...\"\n",
    "\n",
    "# ‚îÄ‚îÄ Run annotation ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "OUTPUT_PREFIX=\"${OUTPUT_DIR}/${PROJECT_NAME}_annotated_ensembl\"\n",
    "\n",
    "perl \"$ANNOVAR_PATH\" \\\n",
    "    \"$INPUT_VCF\" \\\n",
    "    \"$ANNOVAR_DB_DIR/\" \\\n",
    "    -buildver \"$BUILD\" \\\n",
    "    -out \"$OUTPUT_PREFIX\" \\\n",
    "    -protocol ensGene \\\n",
    "    -operation g \\\n",
    "    -remove \\\n",
    "    -vcfinput \\\n",
    "    -nastring .\n",
    "\n",
    "# ‚îÄ‚îÄ Verify annotation success ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "if [ $? -eq 0 ]; then\n",
    "    echo \"üèÅ Annotation finished successfully!\"\n",
    "    echo \"üìÑ Output files:\"\n",
    "    echo \"   - ${OUTPUT_PREFIX}.${BUILD}_multianno.txt\"\n",
    "    echo \"   - ${OUTPUT_PREFIX}.${BUILD}_multianno.vcf\"\n",
    "\n",
    "    # List actual output files created\n",
    "    echo \"\"\n",
    "    echo \"üìÅ Created files:\"\n",
    "    ls -la \"${OUTPUT_PREFIX}\".${BUILD}_multianno.*\n",
    "else\n",
    "    echo \"‚ùå ERROR: Annotation failed\"\n",
    "    exit 1\n",
    "fi\n"
   ],
   "id": "dab13721e5864f63",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 02_annotation\n",
    "# ii. convert ANNOVAR ensGene output to regenie inputs:\n",
    "# 1. Variant annotations file (.annotations.txt)\n",
    "# 2. Gene sets file (.sets.txt)\n",
    "# 3. Mask definitions file (.masks)\n",
    "# makes file in format  1:69134:A:G\tOR4F5(ENSG00000186092) missense(0/5)\n",
    "# python script\n",
    "\n",
    "##############################################################\n",
    "#               USER-DEFINED INPUTS (EDIT HERE)              #\n",
    "##############################################################\n",
    "\n",
    "# Path to ANNOVAR ensGene multianno.txt output file\n",
    "ANNOVAR_FILE = r\"C:\\Users\\B00731414\\OneDrive - Ulster University\\6. Code\\ADNI\\4. Gene Burden\\02_Annotations_ADNI1\\outputs\\ADNI1_annotated_ensembl.hg18_multianno.txt\"\n",
    "\n",
    "# Output file prefix for regenie files\n",
    "OUTPUT_PREFIX = r\"C:\\Users\\B00731414\\OneDrive - Ulster University\\6. Code\\ADNI\\4. Gene Burden\\02_Annotations_ADNI1\\outputs\\regenie\\regenie_ukb\"\n",
    "\n",
    "# Genome build version\n",
    "GENOME_BUILD = \"hg18\"\n",
    "\n",
    "##############################################################\n",
    "#            DO NOT EDIT BELOW THIS LINE                     #\n",
    "##############################################################\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "import re\n",
    "\n",
    "# ‚îÄ‚îÄ Parse annotation to extract gene ENSGID ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "def parse_ensembl_gene_name(gene_string):\n",
    "\n",
    "    if pd.isna(gene_string) or gene_string == '.' or gene_string == '':\n",
    "        return None\n",
    "\n",
    "    gene_string = str(gene_string).strip()\n",
    "\n",
    "    # Split by comma to handle \"ENSG00000ID,GENENAME\" format\n",
    "    parts = gene_string.split(',')\n",
    "\n",
    "    ensg_id = None\n",
    "    gene_name = None\n",
    "\n",
    "    # Extract ENSG ID and gene name from parts\n",
    "    for part in parts:\n",
    "        part = part.strip()\n",
    "        if part.startswith('ENSG'):\n",
    "            ensg_id = part\n",
    "        elif part and not part.startswith('ENSG'):\n",
    "            gene_name = part\n",
    "\n",
    "    # Format like UKB\n",
    "    if gene_name and ensg_id:\n",
    "        return f\"{gene_name}({ensg_id})\"\n",
    "    elif gene_name:\n",
    "        return gene_name  # Return gene name even without ENSG\n",
    "    elif ensg_id:\n",
    "        return f\"Unknown({ensg_id})\"  # Fallback if only ENSG available\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# ‚îÄ‚îÄ Map ANNOVAR functional annotations to UKB regenie categories ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "def map_annovar_consequence_ukb(func_ensgene, exonic_func_ensgene):\n",
    "\n",
    "    func = str(func_ensgene).lower()\n",
    "    exonic_func = str(exonic_func_ensgene).lower()\n",
    "\n",
    "    # Loss-of-function variants (highest priority)\n",
    "    if ((func == 'exonic' and any(x in exonic_func for x in\n",
    "         ['nonsense', 'frameshift', 'stopgain', 'stoploss'])) or\n",
    "        'splicing' in func):\n",
    "        return 'LoF'\n",
    "\n",
    "    # Missense variants\n",
    "    if func == 'exonic' and any(x in exonic_func for x in\n",
    "        ['nonsynonymous', 'missense']):\n",
    "        return 'missense'\n",
    "\n",
    "    # Synonymous variants\n",
    "    if func == 'exonic' and 'synonymous' in exonic_func:\n",
    "        return 'synonymous'\n",
    "\n",
    "    # Other coding variants\n",
    "    if func == 'exonic':\n",
    "        return 'other_coding'\n",
    "\n",
    "    # Non-coding variants (default)\n",
    "    return 'non_coding'\n",
    "\n",
    "# ‚îÄ‚îÄ check inputs exist ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "def validate_input_file(file_path):\n",
    "\n",
    "    if not Path(file_path).exists():\n",
    "        raise FileNotFoundError(f\"Input file not found: {file_path}\")\n",
    "\n",
    "    # Test read first few lines to check format\n",
    "    try:\n",
    "        df_test = pd.read_csv(file_path, sep='\\t', nrows=5, low_memory=False)\n",
    "        required_cols = ['Gene.ensGene', 'Func.ensGene', 'Chr', 'Start', 'Ref', 'Alt']\n",
    "        missing_cols = [col for col in required_cols if col not in df_test.columns]\n",
    "\n",
    "        if missing_cols:\n",
    "            raise ValueError(f\"Missing required columns: {missing_cols}\")\n",
    "\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Error reading input file: {e}\")\n",
    "\n",
    "# ‚îÄ‚îÄ create variant-gene pairs ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "def create_variant_annotations(df):\n",
    "\n",
    "    annotations = []\n",
    "    stats = {'genes_with_ensg': 0, 'genes_without_ensg': 0}\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        # Create variant ID in regenie format: CHR:POS:REF:ALT\n",
    "        var_id = f\"{row['Chr']}:{row['Start']}:{row['Ref']}:{row['Alt']}\"\n",
    "\n",
    "        # Get gene names from ensGene (may be semicolon-separated)\n",
    "        genes = str(row['Gene.ensGene'])\n",
    "        if genes == '.' or pd.isna(genes):\n",
    "            continue\n",
    "\n",
    "        # Get functional consequence\n",
    "        consequence = map_annovar_consequence_ukb(\n",
    "            row['Func.ensGene'],\n",
    "            row.get('ExonicFunc.ensGene', '.')\n",
    "        )\n",
    "\n",
    "        # Handle multiple genes (separated by semicolons)\n",
    "        for gene_entry in genes.split(';'):\n",
    "            gene_entry = gene_entry.strip()\n",
    "            if gene_entry and gene_entry != '.':\n",
    "                # Parse and format gene name properly\n",
    "                formatted_gene = parse_ensembl_gene_name(gene_entry)\n",
    "\n",
    "                if formatted_gene:\n",
    "                    annotations.append({\n",
    "                        'variant_id': var_id,\n",
    "                        'gene': formatted_gene,\n",
    "                        'consequence': consequence,\n",
    "                        'chr': row['Chr'],\n",
    "                        'pos': row['Start']\n",
    "                    })\n",
    "\n",
    "                    # Track ENSG coverage\n",
    "                    if 'ENSG' in formatted_gene:\n",
    "                        stats['genes_with_ensg'] += 1\n",
    "                    else:\n",
    "                        stats['genes_without_ensg'] += 1\n",
    "\n",
    "    return pd.DataFrame(annotations), stats\n",
    "\n",
    "# ‚îÄ‚îÄ save variant annotations in UKB/regenie format ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "def save_annotations_file(ann_df, output_path):\n",
    "    with open(output_path, 'w') as f:\n",
    "        for _, r in ann_df.iterrows():\n",
    "            f.write(f\"{r['variant_id']}\\t{r['gene']}\\t{r['consequence']}\\n\")\n",
    "\n",
    "# ‚îÄ‚îÄ group variants by gene to create gene sets file ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "def create_gene_sets(ann_df):\n",
    "    gene_sets = defaultdict(list)\n",
    "    gene_pos = {}\n",
    "\n",
    "    for _, r in ann_df.iterrows():\n",
    "        gene_sets[r['gene']].append(r['variant_id'])\n",
    "        if r['gene'] not in gene_pos:\n",
    "            gene_pos[r['gene']] = {'chr': r['chr'], 'pos': r['pos']}\n",
    "\n",
    "    return gene_sets, gene_pos\n",
    "\n",
    "# ‚îÄ‚îÄ save gene sets file ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "def save_gene_sets_file(gene_sets, gene_pos, output_path):\n",
    "    with open(output_path, 'w') as f:\n",
    "        for gene, variants in gene_sets.items():\n",
    "            chrpos = gene_pos[gene]\n",
    "            if variants:  # Only include genes with variants\n",
    "                f.write(f\"{gene} {chrpos['chr']} {chrpos['pos']} \" +\n",
    "                       f\"{','.join(variants)}\\n\")\n",
    "\n",
    "\n",
    "# ‚îÄ‚îÄ create masks ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "def create_mask_definitions():\n",
    "    return {\n",
    "        'M1': ['LoF'],  # Loss-of-function only\n",
    "        'M2': ['missense'],  # Missense variants only\n",
    "        'M3': ['LoF', 'missense'],  # Combined LoF and missense\n",
    "        'M4': ['LoF', 'missense', 'synonymous'],  # All coding variants\n",
    "    }\n",
    "\n",
    "# ‚îÄ‚îÄ save masks ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "def save_mask_definitions_file(mask_definitions, output_path):\n",
    "\n",
    "    with open(output_path, 'w') as f:\n",
    "        for mask_name, consequences in mask_definitions.items():\n",
    "            f.write(f\"{mask_name} {','.join(consequences)}\\n\")\n",
    "\n",
    "# ‚îÄ‚îÄ main function  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "def create_regenie_files_from_annovar():\n",
    "    print(\"=\" * 80)\n",
    "    print(\"ANNOVAR ENSEMBL TO REGENIE CONVERSION\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"Input file: {ANNOVAR_FILE}\")\n",
    "    print(f\"Output prefix: {OUTPUT_PREFIX}\")\n",
    "    print(f\"Genome build: {GENOME_BUILD}\")\n",
    "    print()\n",
    "\n",
    "    try:\n",
    "        # Validate input file\n",
    "        validate_input_file(ANNOVAR_FILE)\n",
    "\n",
    "        # Read ANNOVAR ensGene output\n",
    "        print(\"üìñ Reading ANNOVAR ensGene file...\")\n",
    "        df = pd.read_csv(ANNOVAR_FILE, sep='\\t', low_memory=False)\n",
    "        print(f\"‚úÖ Found {len(df)} annotated variants\")\n",
    "\n",
    "        # Create variant annotations\n",
    "        print(\"\\nüß¨ Creating variant annotations...\")\n",
    "        ann_df, stats = create_variant_annotations(df)\n",
    "\n",
    "        if len(ann_df) == 0:\n",
    "            raise ValueError(\"No valid annotations created\")\n",
    "\n",
    "        print(f\"‚úÖ Created {len(ann_df)} variant-gene annotation pairs\")\n",
    "        print(f\"‚úÖ {stats['genes_with_ensg']} annotations have ENSG IDs\")\n",
    "        print(f\"‚ö†Ô∏è  {stats['genes_without_ensg']} annotations lack ENSG IDs\")\n",
    "\n",
    "        # Show example annotations\n",
    "        if len(ann_df) > 0:\n",
    "            print(\"\\nüìã Example annotations:\")\n",
    "            for i in range(min(5, len(ann_df))):\n",
    "                row = ann_df.iloc[i]\n",
    "                print(f\"   {row['variant_id']} {row['gene']} {row['consequence']}\")\n",
    "\n",
    "        # Save annotations file\n",
    "        ann_file = f\"{OUTPUT_PREFIX}.annotations.txt\"\n",
    "        save_annotations_file(ann_df, ann_file)\n",
    "        print(f\"üíæ Saved: {ann_file}\")\n",
    "\n",
    "        # Create and save gene sets\n",
    "        print(\"\\nüßÆ Creating gene sets...\")\n",
    "        gene_sets, gene_pos = create_gene_sets(ann_df)\n",
    "\n",
    "        sets_file = f\"{OUTPUT_PREFIX}.sets.txt\"\n",
    "        save_gene_sets_file(gene_sets, gene_pos, sets_file)\n",
    "        print(f\"‚úÖ Created {len(gene_sets)} gene sets\")\n",
    "        print(f\"üíæ Saved: {sets_file}\")\n",
    "\n",
    "        # Create and save mask definitions\n",
    "        print(\"\\nüé≠ Creating mask definitions...\")\n",
    "        mask_definitions = create_mask_definitions()\n",
    "\n",
    "        masks_file = f\"{OUTPUT_PREFIX}.masks\"\n",
    "        save_mask_definitions_file(mask_definitions, masks_file)\n",
    "        print(f\"‚úÖ Created {len(mask_definitions)} mask definitions\")\n",
    "        print(f\"üíæ Saved: {masks_file}\")\n",
    "\n",
    "        # Final summary\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"CONVERSION COMPLETE\")\n",
    "        print(\"=\" * 80)\n",
    "        print(f\"‚úÖ Processed {len(df)} variants\")\n",
    "        print(f\"‚úÖ Created annotations for {len(gene_sets)} genes\")\n",
    "        print(f\"‚úÖ Generated {len(mask_definitions)} mask types\")\n",
    "        print(f\"‚úÖ Gene name format: GENENAME(ENSG00000ID)\")\n",
    "\n",
    "        if len(ann_df) > 0:\n",
    "            example_row = ann_df.iloc[0]\n",
    "            print(f\"   Example: {example_row['variant_id']}\\t{example_row['gene']}\\t{example_row['consequence']}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå ERROR: {e}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "   create_regenie_files_from_annovar()"
   ],
   "id": "efe2d02ab65026e2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 02_annotation\n",
    "# ii. (ALTERNATIVE) convert ANNOVAR ensGene output to regenie inputs:\n",
    "# 1. Variant annotations file (.annotations.txt)\n",
    "# 2. Gene sets file (.sets.txt)\n",
    "# 3. Mask definitions file (.masks)\n",
    "# makes file in format: rs17160698 NOC2L(ENSG00000ID) non_coding\n",
    "# python script\n",
    "\n",
    "\n",
    "##############################################################\n",
    "#               USER-DEFINED INPUTS (EDIT HERE)              #\n",
    "##############################################################\n",
    "\n",
    "# Path to ANNOVAR ensGene multianno.txt output file\n",
    "ANNOVAR_FILE = r\"C:\\Users\\B00731414\\OneDrive - Ulster University\\6. Code\\ADNI\\4. Gene Burden\\02_Annotations_ADNI1\\outputs\\ADNI1_annotated_ensembl.hg18_multianno.txt\"\n",
    "\n",
    "# Path to the BIM file to get the correct variant IDs (rsIDs)\n",
    "BIM_FILE = r\"C:\\Users\\B00731414\\OneDrive - Ulster University\\6. Code\\ADNI\\4. Gene Burden\\01_data_prep_qc_ADNI1\\outputs\\ADNI1_preQC.bim\"\n",
    "\n",
    "# Output file prefix for regenie files\n",
    "OUTPUT_PREFIX = r\"C:\\Users\\B00731414\\OneDrive - Ulster University\\6. Code\\ADNI\\4. Gene Burden\\02_Annotations_ADNI1\\outputs\\regenie\\regenie_ukb\"\n",
    "\n",
    "# Genome build version\n",
    "GENOME_BUILD = \"hg18\"\n",
    "\n",
    "##############################################################\n",
    "#            DO NOT EDIT BELOW THIS LINE                     #\n",
    "##############################################################\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "import re\n",
    "\n",
    "# ‚îÄ‚îÄ Parse annotation to extract gene ENSGID ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "def parse_ensembl_gene_name(gene_string):\n",
    "    if pd.isna(gene_string) or gene_string == '.' or gene_string == '':\n",
    "        return None\n",
    "\n",
    "    gene_string = str(gene_string).strip()\n",
    "    parts = gene_string.split(',')\n",
    "\n",
    "    ensg_id = None\n",
    "    gene_name = None\n",
    "\n",
    "    for part in parts:\n",
    "        part = part.strip()\n",
    "        if part.startswith('ENSG'):\n",
    "            ensg_id = part\n",
    "        elif part and not part.startswith('ENSG'):\n",
    "            gene_name = part\n",
    "\n",
    "    if gene_name and ensg_id:\n",
    "        return f\"{gene_name}({ensg_id})\"\n",
    "    elif gene_name:\n",
    "        return gene_name\n",
    "    elif ensg_id:\n",
    "        return f\"Unknown({ensg_id})\"\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# ‚îÄ‚îÄ Map ANNOVAR functional annotations to UKB regenie categories ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "def map_annovar_consequence_ukb(func_ensgene, exonic_func_ensgene):\n",
    "    func = str(func_ensgene).lower()\n",
    "    exonic_func = str(exonic_func_ensgene).lower()\n",
    "\n",
    "    if ((func == 'exonic' and any(x in exonic_func for x in\n",
    "         ['nonsense', 'frameshift', 'stopgain', 'stoploss'])) or\n",
    "        'splicing' in func):\n",
    "        return 'LoF'\n",
    "\n",
    "    if func == 'exonic' and any(x in exonic_func for x in\n",
    "        ['nonsynonymous', 'missense']):\n",
    "        return 'missense'\n",
    "\n",
    "    if func == 'exonic' and 'synonymous' in exonic_func:\n",
    "        return 'synonymous'\n",
    "\n",
    "    if func == 'exonic':\n",
    "        return 'other_coding'\n",
    "\n",
    "    return 'non_coding'\n",
    "\n",
    "# ‚îÄ‚îÄ Load BIM file and create CHR:POS:REF:ALT ‚Üí rsID mapping ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "def load_bim_file(bim_path):\n",
    "    print(\"üìñ Reading BIM file to create variant ID mapping...\")\n",
    "\n",
    "    if not Path(bim_path).exists():\n",
    "        raise FileNotFoundError(f\"BIM file not found: {bim_path}\")\n",
    "\n",
    "    bim_df = pd.read_csv(bim_path, sep=r'\\s+', header=None,\n",
    "                         names=['CHR', 'rsID', 'cM', 'POS', 'A1', 'A2'])\n",
    "\n",
    "    print(f\"‚úÖ Loaded {len(bim_df)} variants from BIM file\")\n",
    "\n",
    "    variant_to_rsid = {}\n",
    "    for _, row in bim_df.iterrows():\n",
    "        var_id_1 = f\"{row['CHR']}:{row['POS']}:{row['A1']}:{row['A2']}\"\n",
    "        var_id_2 = f\"{row['CHR']}:{row['POS']}:{row['A2']}:{row['A1']}\"\n",
    "        variant_to_rsid[var_id_1] = row['rsID']\n",
    "        variant_to_rsid[var_id_2] = row['rsID']\n",
    "\n",
    "    print(f\"‚úÖ Created mapping for {len(variant_to_rsid)} variant ID combinations\")\n",
    "    return variant_to_rsid\n",
    "\n",
    "# ‚îÄ‚îÄ Validate ANNOVAR input ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "def validate_annovar_file(file_path):\n",
    "    if not Path(file_path).exists():\n",
    "        raise FileNotFoundError(f\"ANNOVAR file not found: {file_path}\")\n",
    "\n",
    "    df_test = pd.read_csv(file_path, sep='\\t', nrows=5, low_memory=False)\n",
    "    required_cols = ['Gene.ensGene', 'Func.ensGene', 'Chr', 'Start', 'Ref', 'Alt']\n",
    "    missing_cols = [col for col in required_cols if col not in df_test.columns]\n",
    "\n",
    "    if missing_cols:\n",
    "        raise ValueError(f\"Missing required columns: {missing_cols}\")\n",
    "    return True\n",
    "\n",
    "# ‚îÄ‚îÄ Create variant annotations with rsID mapping ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "def create_variant_annotations(df, variant_to_rsid):\n",
    "    annotations = []\n",
    "    stats = {\n",
    "        'genes_with_ensg': 0,\n",
    "        'genes_without_ensg': 0,\n",
    "        'variants_mapped': 0,\n",
    "        'variants_unmapped': 0\n",
    "    }\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        chr_pos_ref_alt = f\"{row['Chr']}:{row['Start']}:{row['Ref']}:{row['Alt']}\"\n",
    "\n",
    "        if chr_pos_ref_alt in variant_to_rsid:\n",
    "            rsid = variant_to_rsid[chr_pos_ref_alt]\n",
    "            stats['variants_mapped'] += 1\n",
    "        else:\n",
    "            chr_pos_alt_ref = f\"{row['Chr']}:{row['Start']}:{row['Alt']}:{row['Ref']}\"\n",
    "            if chr_pos_alt_ref in variant_to_rsid:\n",
    "                rsid = variant_to_rsid[chr_pos_alt_ref]\n",
    "                stats['variants_mapped'] += 1\n",
    "            else:\n",
    "                stats['variants_unmapped'] += 1\n",
    "                continue\n",
    "\n",
    "        genes = str(row['Gene.ensGene'])\n",
    "        if genes == '.' or pd.isna(genes):\n",
    "            continue\n",
    "\n",
    "        consequence = map_annovar_consequence_ukb(\n",
    "            row['Func.ensGene'],\n",
    "            row.get('ExonicFunc.ensGene', '.')\n",
    "        )\n",
    "\n",
    "        for gene_entry in genes.split(';'):\n",
    "            gene_entry = gene_entry.strip()\n",
    "            if gene_entry and gene_entry != '.':\n",
    "                formatted_gene = parse_ensembl_gene_name(gene_entry)\n",
    "                if formatted_gene:\n",
    "                    annotations.append({\n",
    "                        'variant_id': rsid,\n",
    "                        'gene': formatted_gene,\n",
    "                        'consequence': consequence,\n",
    "                        'chr': row['Chr'],\n",
    "                        'pos': row['Start']\n",
    "                    })\n",
    "                    if 'ENSG' in formatted_gene:\n",
    "                        stats['genes_with_ensg'] += 1\n",
    "                    else:\n",
    "                        stats['genes_without_ensg'] += 1\n",
    "\n",
    "    return pd.DataFrame(annotations), stats\n",
    "\n",
    "# ‚îÄ‚îÄ Save annotations file ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "def save_annotations_file(ann_df, output_path):\n",
    "    with open(output_path, 'w') as f:\n",
    "        for _, r in ann_df.iterrows():\n",
    "            f.write(f\"{r['variant_id']}\\t{r['gene']}\\t{r['consequence']}\\n\")\n",
    "\n",
    "# ‚îÄ‚îÄ Create gene sets ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "def create_gene_sets(ann_df):\n",
    "    gene_sets = defaultdict(list)\n",
    "    gene_pos = {}\n",
    "    for _, r in ann_df.iterrows():\n",
    "        gene_sets[r['gene']].append(r['variant_id'])\n",
    "        if r['gene'] not in gene_pos:\n",
    "            gene_pos[r['gene']] = {'chr': r['chr'], 'pos': r['pos']}\n",
    "    return gene_sets, gene_pos\n",
    "\n",
    "# ‚îÄ‚îÄ Save gene sets file ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "def save_gene_sets_file(gene_sets, gene_pos, output_path):\n",
    "    with open(output_path, 'w') as f:\n",
    "        for gene, variants in gene_sets.items():\n",
    "            chrpos = gene_pos[gene]\n",
    "            if variants:\n",
    "                f.write(f\"{gene} {chrpos['chr']} {chrpos['pos']} \" +\n",
    "                        f\"{','.join(variants)}\\n\")\n",
    "\n",
    "# ‚îÄ‚îÄ Create mask definitions ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "def create_mask_definitions():\n",
    "    return {\n",
    "        'M1': ['LoF'],\n",
    "        'M2': ['missense'],\n",
    "        'M3': ['LoF', 'missense'],\n",
    "        'M4': ['LoF', 'missense', 'synonymous'],\n",
    "    }\n",
    "\n",
    "# ‚îÄ‚îÄ Save mask definitions ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "def save_mask_definitions_file(mask_definitions, output_path):\n",
    "    with open(output_path, 'w') as f:\n",
    "        for mask_name, consequences in mask_definitions.items():\n",
    "            f.write(f\"{mask_name} {','.join(consequences)}\\n\")\n",
    "\n",
    "# ‚îÄ‚îÄ Main function ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "def create_regenie_files_with_rsid_mapping():\n",
    "    print(\"=\" * 80)\n",
    "    print(\"ANNOVAR ENSEMBL TO REGENIE CONVERSION (rsID mapping)\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"Input ANNOVAR file: {ANNOVAR_FILE}\")\n",
    "    print(f\"Input BIM file: {BIM_FILE}\")\n",
    "    print(f\"Output prefix: {OUTPUT_PREFIX}\")\n",
    "    print(f\"Genome build: {GENOME_BUILD}\")\n",
    "    print()\n",
    "\n",
    "    try:\n",
    "        validate_annovar_file(ANNOVAR_FILE)\n",
    "        variant_to_rsid = load_bim_file(BIM_FILE)\n",
    "\n",
    "        print(\"üìñ Reading ANNOVAR ensGene file...\")\n",
    "        df = pd.read_csv(ANNOVAR_FILE, sep='\\t', low_memory=False)\n",
    "        print(f\"‚úÖ Found {len(df)} annotated variants\")\n",
    "\n",
    "        print(\"\\nüß¨ Creating variant annotations with rsID mapping...\")\n",
    "        ann_df, stats = create_variant_annotations(df, variant_to_rsid)\n",
    "\n",
    "        if len(ann_df) == 0:\n",
    "            raise ValueError(\"No valid annotations created\")\n",
    "\n",
    "        print(f\"‚úÖ Created {len(ann_df)} variant-gene annotation pairs\")\n",
    "        print(f\"‚úÖ {stats['variants_mapped']} variants successfully mapped to rsIDs\")\n",
    "        print(f\"‚ö†Ô∏è  {stats['variants_unmapped']} variants could not be mapped\")\n",
    "        print(f\"‚úÖ {stats['genes_with_ensg']} annotations have ENSG IDs\")\n",
    "        print(f\"‚ö†Ô∏è  {stats['genes_without_ensg']} annotations lack ENSG IDs\")\n",
    "\n",
    "        if len(ann_df) > 0:\n",
    "            print(\"\\nüìã Example annotations:\")\n",
    "            for i in range(min(5, len(ann_df))):\n",
    "                row = ann_df.iloc[i]\n",
    "                print(f\"   {row['variant_id']} {row['gene']} {row['consequence']}\")\n",
    "\n",
    "        ann_file = f\"{OUTPUT_PREFIX}.annotations.txt\"\n",
    "        save_annotations_file(ann_df, ann_file)\n",
    "        print(f\"üíæ Saved: {ann_file}\")\n",
    "\n",
    "        print(\"\\nüßÆ Creating gene sets...\")\n",
    "        gene_sets, gene_pos = create_gene_sets(ann_df)\n",
    "        sets_file = f\"{OUTPUT_PREFIX}.sets.txt\"\n",
    "        save_gene_sets_file(gene_sets, gene_pos, sets_file)\n",
    "        print(f\"‚úÖ Created {len(gene_sets)} gene sets\")\n",
    "        print(f\"üíæ Saved: {sets_file}\")\n",
    "\n",
    "        print(\"\\nüé≠ Creating mask definitions...\")\n",
    "        mask_definitions = create_mask_definitions()\n",
    "        masks_file = f\"{OUTPUT_PREFIX}.masks\"\n",
    "        save_mask_definitions_file(mask_definitions, masks_file)\n",
    "        print(f\"‚úÖ Created {len(mask_definitions)} mask definitions\")\n",
    "        print(f\"üíæ Saved: {masks_file}\")\n",
    "\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"CONVERSION COMPLETE (rsID mapping)\")\n",
    "        print(\"=\" * 80)\n",
    "        print(f\"‚úÖ Processed {len(df)} ANNOVAR variants\")\n",
    "        print(f\"‚úÖ Mapped {stats['variants_mapped']} variants to rsIDs\")\n",
    "        print(f\"‚ö†Ô∏è  {stats['variants_unmapped']} variants unmapped\")\n",
    "        print(f\"‚úÖ Created annotations for {len(gene_sets)} genes\")\n",
    "        print(f\"‚úÖ Generated {len(mask_definitions)} mask types\")\n",
    "\n",
    "        if len(ann_df) > 0:\n",
    "            example_row = ann_df.iloc[0]\n",
    "            print(f\"   Example: {example_row['variant_id']}\\t{example_row['gene']}\\t{example_row['consequence']}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå ERROR: {e}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    create_regenie_files_with_rsid_mapping()\n"
   ],
   "id": "b69a99da9df27096",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 3. Regenie",
   "id": "b0bc853b50ec674b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%%bash\n",
    "\n",
    "# 03_regenie\n",
    "# step 1\n",
    "# create null model to control for relatedness, population structure and polygenicity.\n",
    "\n",
    "##############################################################\n",
    "#               USER-DEFINED INPUTS (EDIT HERE)              #\n",
    "##############################################################\n",
    "\n",
    "BED_FILE=\"/mnt/c/Users/B00731414/OneDrive - Ulster University/6. Code/ADNI/4. Gene Burden/01_Data_Prep_QC/outputs/ADNI2_preQC_common\"\n",
    "PHENO_FILE=\"/mnt/c/Users/B00731414/OneDrive - Ulster University/6. Code/ADNI/4. Gene Burden/01_Data_Prep_QC/outputs/ADNI_AD_vs_CN_phenotypes.txt\"\n",
    "PHENO_COL=\"AD_vs_CN\"\n",
    "COVAR_FILE=\"/mnt/c/Users/B00731414/OneDrive - Ulster University/6. Code/ADNI/4. Gene Burden/01_Data_Prep_QC/outputs/ADNI_PCA_merged_covariates.txt\"\n",
    "COVAR_COL_LIST=\"age,sex,education,apoe4_count,PC{1:10}\"\n",
    "OUTPUT_PREFIX=\"/mnt/c/Users/B00731414/OneDrive - Ulster University/6. Code/ADNI/4. Gene Burden/03_Regenie/step 1/S1_ADNI\"\n",
    "\n",
    "##############################################################\n",
    "#            DO NOT EDIT BELOW THIS LINE                     #\n",
    "##############################################################\n",
    "\n",
    "regenie \\\n",
    "  --step 1 \\\n",
    "  --bt \\ # for binary trait\n",
    "  --ref-first \\\n",
    "  --bed \"$BED_FILE\" \\\n",
    "  --phenoFile \"$PHENO_FILE\" \\\n",
    "  --phenoCol $PHENO_COL \\\n",
    "  --covarFile \"$COVAR_FILE\" \\\n",
    "  --covarColList $COVAR_COL_LIST \\\n",
    "  --bsize 200 \\\n",
    "  --gz \\\n",
    "  --out \"$OUTPUT_PREFIX\"\n"
   ],
   "id": "d9f8d77c9e32ffce",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#!/bin/bash\n",
    "\n",
    "#SBATCH --job-name=regenie_step1\n",
    "#SBATCH --output=/users/smitchell/ADNI/ADNI1_regenie/logs_and_errors/regenie_step1_%j.out\n",
    "#SBATCH --error=/users/smitchell/ADNI/ADNI1_regenie/logs_and_errors/regenie_step1_%j.err\n",
    "#SBATCH --time=02:00:00\n",
    "#SBATCH --partition=k2-hipri\n",
    "#SBATCH --ntasks=1\n",
    "#SBATCH --cpus-per-task=4\n",
    "#SBATCH --mem=64G\n",
    "#SBATCH --mail-type=BEGIN,END,FAIL\n",
    "#SBATCH --mail-user=mitchell-s17@ulster.ac.uk\n",
    "\n",
    "##############################################################\n",
    "#               USER-DEFINED INPUTS (EDIT HERE)              #\n",
    "##############################################################\n",
    "\n",
    "# Input directories\n",
    "INPUT_PLINK_PREFIX=\"/users/smitchell/ADNI/ADNI1_regenie/pre_qc/ADNI1_preQC_common\"\n",
    "PHENO_FILE=\"/users/smitchell/ADNI/ADNI1_regenie/pre_qc/ADNI_AD_vs_CN_phenotypes.txt\"\n",
    "COVAR_FILE=\"/users/smitchell/ADNI/ADNI1_regenie/pre_qc/ADNI1_PCA_merged_covariates.txt\"\n",
    "\n",
    "# Output directory for step 1\n",
    "OUT_DIR=\"/users/smitchell/ADNI/ADNI_regenie/regenie_step_1\"\n",
    "\n",
    "##############################################################\n",
    "#            DO NOT EDIT BELOW THIS LINE                     #\n",
    "##############################################################\n",
    "\n",
    "# ‚îÄ‚îÄ activate conda env ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "# Initialise conda (adjust path if needed)\n",
    "eval \"$(conda shell.bash hook)\"\n",
    "\n",
    "# Activate the regenie environment\n",
    "conda activate regenie-env\n",
    "\n",
    "\n",
    "# ‚îÄ‚îÄ load modules ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "module load compilers/gcc/14.1.0\n",
    "module load libs/intel-mkl/2020u4/bin\n",
    "\n",
    "# ‚îÄ‚îÄ Run REGENIE step 1 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "regenie \\\n",
    "  --step 1 \\\n",
    "  --bt \\\n",
    "  --ref-first \\\n",
    "  --bed \"${INPUT_PLINK_PREFIX}\" \\\n",
    "  --phenoFile \"${PHENO_FILE}\" \\\n",
    "  --phenoCol AD_vs_CN \\\n",
    "  --covarFile \"${COVAR_FILE}\" \\\n",
    "  --covarColList age,sex,education,apoe4_count,PC{1:10} \\\n",
    "  --bsize 200 \\\n",
    "  --gz \\\n",
    "  --out \"${OUT_DIR}/S1_ADNI\"\n",
    "\n",
    "# ‚îÄ‚îÄ deactivate conda ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "conda deactivate\n"
   ],
   "id": "2823f150150b6f41",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%%bash\n",
    "\n",
    "# 03_regenie\n",
    "# step 2\n",
    "# burden testing for rare variants\n",
    "\n",
    "##############################################################\n",
    "#               USER-DEFINED INPUTS (EDIT HERE)              #\n",
    "##############################################################\n",
    "\n",
    "BASE_DIR=\"/mnt/c/Users/B00731414/OneDrive - Ulster University/6. Code/ADNI/4. Gene Burden\"\n",
    "PHENO_FILE=\"$BASE_DIR/01_Data_Prep_QC/outputs/ADNI_AD_vs_CN_phenotypes.txt\"\n",
    "COVAR_FILE=\"$BASE_DIR/01_Data_Prep_QC/outputs/ADNI_PCA_merged_covariates.txt\"\n",
    "RARE_BED=\"$BASE_DIR/01_Data_Prep_QC/outputs/ADNI2_preQC\"\n",
    "\n",
    "# Annotation files\n",
    "ANNO_FILE=\"$BASE_DIR/02_Annotations/outputs/regenie/regenie_ukb.annotations.txt\"\n",
    "SETS_FILE=\"$BASE_DIR/02_Annotations/outputs/regenie/regenie_ukb.sets.txt\"\n",
    "MASK_FILE=\"$BASE_DIR/02_Annotations/outputs/regenie/regenie_ukb.masks\"\n",
    "\n",
    "# Output directories\n",
    "STEP1_OUT=\"$BASE_DIR/03_Regenie/step 1\"\n",
    "STEP2_OUT=\"$BASE_DIR/03_Regenie/step 2\"\n",
    "\n",
    "##############################################################\n",
    "#            DO NOT EDIT BELOW THIS LINE                     #\n",
    "##############################################################\n",
    "\n",
    "regenie \\\n",
    "  --step 2 \\\n",
    "  --bt \\\n",
    "  --bed \"$RARE_BED\" \\\n",
    "  --ref-first \\\n",
    "  --phenoFile \"$PHENO_FILE\" \\\n",
    "  --phenoCol AD_vs_CN \\\n",
    "  --covarFile \"$COVAR_FILE\" \\\n",
    "  --covarColList age,sex,education,apoe4_count,PC{1:10} \\\n",
    "  --pred \"$STEP1_OUT/S1_ADNI_pred_base.list\" \\\n",
    "  --anno-file \"$ANNO_FILE\" \\\n",
    "  --set-list \"$SETS_FILE\" \\\n",
    "  --mask-def \"$MASK_FILE\" \\\n",
    "  --aaf-bins 0.01,0.001 \\\n",
    "  --build-mask max \\\n",
    "  --write-mask \\\n",
    "  --vc-tests skato,acato \\\n",
    "  --bsize 200 \\\n",
    "  --out \"$STEP2_OUT/S2_ADNI_burden\""
   ],
   "id": "f2cfddeddee79831",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#!/bin/bash\n",
    "#SBATCH --job-name=regenie_step2\n",
    "#SBATCH --output=/users/smitchell/ADNI/ADNI1_regenie/logs_and_errors/regenie_step2_%j.out\n",
    "#SBATCH --error=/users/smitchell/ADNI/ADNI1_regenie/logs_and_errors/regenie_step2_%j.err\n",
    "#SBATCH --time=2:00:00\n",
    "#SBATCH --partition=k2-hipri\n",
    "#SBATCH --ntasks=1\n",
    "#SBATCH --cpus-per-task=8\n",
    "#SBATCH --mem=128G\n",
    "#SBATCH --mail-type=BEGIN,END,FAIL\n",
    "#SBATCH --mail-user=mitchell-s17@ulster.ac.uk\n",
    "\n",
    "##############################################################\n",
    "#               USER-DEFINED INPUTS (EDIT HERE)              #\n",
    "##############################################################\n",
    "\n",
    "BASE_DIR=\"/users/smitchell/ADNI/ADNI1_regenie\"\n",
    "\n",
    "PHENO_FILE=\"${BASE_DIR}/pre_qc/ADNI_AD_vs_CN_phenotypes.txt\"\n",
    "COVAR_FILE=\"${BASE_DIR}/pre_qc/ADNI1_PCA_merged_covariates.txt\"\n",
    "RARE_BED=\"${BASE_DIR}/pre_qc/ADNI1_preQC\"\n",
    "\n",
    "# Annotation files\n",
    "ANNO_FILE=\"${BASE_DIR}/annotations/regenie_ukb.annotations.txt\"\n",
    "SETS_FILE=\"${BASE_DIR}/annotations/regenie_ukb.sets.txt\"\n",
    "MASK_FILE=\"${BASE_DIR}/annotations/regenie_ukb.masks\"\n",
    "\n",
    "# Output directory for step 2\n",
    "OUT_DIR=\"${BASE_DIR}/regenie_step_2\"\n",
    "mkdir -p \"${OUT_DIR}\"\n",
    "\n",
    "##############################################################\n",
    "#            DO NOT EDIT BELOW THIS LINE                     #\n",
    "##############################################################\n",
    "\n",
    "# ‚îÄ‚îÄ activate conda env ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "eval \"$(conda shell.bash hook)\"\n",
    "conda activate regenie-env\n",
    "\n",
    "# ‚îÄ‚îÄ load modules ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "module load compilers/gcc/14.1.0\n",
    "module load libs/eigen/3.4.0/gcc-14.1.0\n",
    "module load libs/intel-mkl/2020u4/bin\n",
    "\n",
    "# ‚îÄ‚îÄ run regenie step 2 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "regenie \\\n",
    "  --step 2 \\\n",
    "  --bt \\\n",
    "  --bed \"${RARE_BED}\" \\\n",
    "  --ref-first \\\n",
    "  --phenoFile \"${PHENO_FILE}\" \\\n",
    "  --phenoCol AD_vs_CN \\\n",
    "  --covarFile \"${COVAR_FILE}\" \\\n",
    "  --covarColList age,sex,education,apoe4_count,PC{1:10} \\\n",
    "  --pred \"${BASE_DIR}/regenie_step_1/S1_ADNI_pred.list\" \\\n",
    "  --anno-file \"${ANNO_FILE}\" \\\n",
    "  --set-list \"${SETS_FILE}\" \\\n",
    "  --mask-def \"${MASK_FILE}\" \\\n",
    "  --aaf-bins 0.01,0.001 \\\n",
    "  --build-mask max \\\n",
    "  --write-mask \\\n",
    "  --vc-tests skato,acato \\\n",
    "  --bsize 200 \\\n",
    "  --out \"${OUT_DIR}/S2_ADNI_burden\"\n",
    "\n",
    "# ‚îÄ‚îÄ deactivate conda ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "conda deactivate\n",
    "\n"
   ],
   "id": "9d48d304d0d5a391",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 04_LOVO_Gene_Selection\n",
    "# i. Select top genes from REGENIE burden test results (LOVO gene list)\n",
    "# Python script\n",
    "\n",
    "##############################################################\n",
    "#               USER-DEFINED INPUTS (EDIT HERE)              #\n",
    "##############################################################\n",
    "\n",
    "# Path to REGENIE output\n",
    "REGENIE_FILE = r\"C:\\Users\\B00731414\\OneDrive - Ulster University\\6. Code\\ADNI\\4. Gene Burden\\03_Regenie_ADNI1\\S2_ADNI_burden_AD_vs_CN.regenie\"\n",
    "\n",
    "# Test configuration\n",
    "TEST_NAME = \"ADD-SKATO\"        # e.g. ADD-SKATO, ADD\n",
    "TOP_N = 10                     # Number of top gene‚Äìmask entries to select\n",
    "AAF_BIN_LABEL = \"all\"          # Label for AAF bin (as in ID field)\n",
    "OUTPUT_FILE = \"lovo_genes.txt\"\n",
    "\n",
    "# Scoring method:\n",
    "# \"logp\"  = Rank by LOG10P (recommended for burden tests)\n",
    "# \"chisq\" = Rank by CHISQ statistic\n",
    "# \"beta\"  = Rank by absolute BETA\n",
    "SCORE_METHOD = \"logp\"\n",
    "\n",
    "# Duplicate handling strategy:\n",
    "# \"best_mask\"     ‚Üí Keep most restrictive mask (M1 > M2 > M3 > M4)\n",
    "# \"keep_all\"      ‚Üí Keep all mask combinations\n",
    "# \"highest_score\" ‚Üí Keep highest scoring entry per gene\n",
    "DUPLICATE_STRATEGY = \"keep_all\"\n",
    "\n",
    "# significance filtering\n",
    "SIGNIFICANCE_THRESHOLD = None  # Set to p-value threshold (e.g., 0.05) or None to disable\n",
    "\n",
    "##############################################################\n",
    "#               DO NOT EDIT BELOW THIS LINE                  #\n",
    "##############################################################\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# ‚îÄ‚îÄ Compute score ranking ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "def compute_score(df, method):\n",
    "    df_scored = df.copy()\n",
    "    if method == \"logp\":\n",
    "        df_scored = df_scored[df_scored[\"LOG10P\"] > 0].copy()\n",
    "        df_scored[\"score\"] = df_scored[\"LOG10P\"]\n",
    "    elif method == \"chisq\":\n",
    "        df_scored = df_scored[df_scored[\"CHISQ\"] > 0].copy()\n",
    "        df_scored[\"score\"] = df_scored[\"CHISQ\"]\n",
    "    elif method == \"beta\":\n",
    "        df_scored = df_scored[df_scored[\"BETA\"].notna() & (df_scored[\"BETA\"] != 0)].copy()\n",
    "        if len(df_scored) == 0:\n",
    "            print(\"‚ö†Ô∏è  WARNING: No valid BETA values found!\")\n",
    "            return df_scored\n",
    "        df_scored[\"score\"] = df_scored[\"BETA\"].abs()\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown scoring method: {method}\")\n",
    "    return df_scored\n",
    "\n",
    "# ‚îÄ‚îÄ Extract gene/mask info from ID col ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "def extract_gene_mask_info(df, aaf_label):\n",
    "    id_parts = df[\"ID\"].str.split(\".\", expand=True)\n",
    "    if id_parts.shape[1] >= 3:\n",
    "        df[\"GENE\"] = id_parts[0]\n",
    "        df[\"MASK\"] = id_parts[1]\n",
    "        df[\"AAF_BIN\"] = aaf_label\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è  WARNING: ID format may not match expected GENE.MASK.AAF pattern\")\n",
    "        df[\"GENE\"] = df[\"ID\"]\n",
    "        df[\"MASK\"] = \"unknown\"\n",
    "        df[\"AAF_BIN\"] = aaf_label\n",
    "    return df\n",
    "\n",
    "# ‚îÄ‚îÄ Handle duplicates ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "def filter_duplicates(df, strategy=\"best_mask\"):\n",
    "    if strategy == \"keep_all\":\n",
    "        return df\n",
    "    elif strategy == \"highest_score\":\n",
    "        return df.loc[df.groupby(\"GENE\")[\"score\"].idxmax()].copy()\n",
    "    elif strategy == \"best_mask\":\n",
    "        mask_priority = {\"M1\": 1, \"M2\": 2, \"M3\": 3, \"M4\": 4}\n",
    "        df[\"mask_priority\"] = df[\"MASK\"].map(mask_priority).fillna(99)\n",
    "        best = df.loc[df.groupby(\"GENE\")[\"mask_priority\"].idxmin()].copy()\n",
    "        return best.drop(\"mask_priority\", axis=1)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown duplicate strategy: {strategy}\")\n",
    "\n",
    "# ‚îÄ‚îÄ Apply significance filtering ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "def apply_significance_filter(df, threshold):\n",
    "    if threshold is None:\n",
    "        return df\n",
    "\n",
    "    # Convert LOG10P back to p-value for filtering\n",
    "    if \"LOG10P\" in df.columns:\n",
    "        df_filtered = df[df[\"LOG10P\"] >= -np.log10(threshold)].copy()\n",
    "        print(f\"   Applied p < {threshold} filter: {len(df_filtered)} entries remain\")\n",
    "        return df_filtered\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è  WARNING: Cannot apply significance filter without LOG10P column\")\n",
    "        return df\n",
    "\n",
    "# ‚îÄ‚îÄ Load regenie results ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "def main():\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"LOVO GENE SELECTION FROM REGENIE BURDEN TEST RESULTS\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    # ‚îÄ‚îÄ validate parameters ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    print(\"\\nüîß Validating parameters...\")\n",
    "    if TOP_N <= 0:\n",
    "        print(f\"‚ùå ERROR: TOP_N must be positive, got {TOP_N}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    regenie_path = Path(REGENIE_FILE)\n",
    "    if not regenie_path.exists():\n",
    "        print(f\"‚ùå ERROR: Input file not found: {REGENIE_FILE}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    if SCORE_METHOD not in [\"logp\", \"chisq\", \"beta\"]:\n",
    "        print(f\"‚ùå ERROR: Invalid SCORE_METHOD: {SCORE_METHOD}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    if DUPLICATE_STRATEGY not in [\"best_mask\", \"keep_all\", \"highest_score\"]:\n",
    "        print(f\"‚ùå ERROR: Invalid DUPLICATE_STRATEGY: {DUPLICATE_STRATEGY}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    print(\"‚úÖ All parameters validated\")\n",
    "\n",
    "    # ‚îÄ‚îÄ load results ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    print(f\"\\nüìñ Loading REGENIE results from: {REGENIE_FILE}\")\n",
    "    try:\n",
    "        df = pd.read_csv(REGENIE_FILE, sep=r\"\\s+\", comment=\"#\", header=0)\n",
    "        print(f\"‚úÖ Loaded {len(df)} rows √ó {len(df.columns)} columns\")\n",
    "        print(f\"   Available tests: {', '.join(df['TEST'].unique())}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå ERROR loading file: {e}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    # ‚îÄ‚îÄ filter to test ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    print(f\"\\nüîé Filtering to test: {TEST_NAME}\")\n",
    "    df_test = df[df[\"TEST\"] == TEST_NAME].copy()\n",
    "    if df_test.empty:\n",
    "        print(f\"‚ùå ERROR: No results found for '{TEST_NAME}'\")\n",
    "        sys.exit(1)\n",
    "    print(f\"‚úÖ Found {len(df_test)} entries for {TEST_NAME}\")\n",
    "\n",
    "    # ‚îÄ‚îÄ extract gene and mask info ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    print(f\"\\nüß¨ Extracting gene and mask information...\")\n",
    "    df_test = extract_gene_mask_info(df_test, AAF_BIN_LABEL)\n",
    "    print(f\"‚úÖ Found {df_test['GENE'].nunique()} unique genes\")\n",
    "    print(\"   Mask distribution:\")\n",
    "    for mask, count in df_test['MASK'].value_counts().items():\n",
    "        print(f\"     {mask}: {count} entries\")\n",
    "\n",
    "    # ‚îÄ‚îÄ compute scores ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    print(f\"\\nüìä Computing scores (method: {SCORE_METHOD})\")\n",
    "    df_scored = compute_score(df_test, SCORE_METHOD)\n",
    "    if df_scored.empty:\n",
    "        print(f\"‚ùå ERROR: No valid scores with method '{SCORE_METHOD}'\")\n",
    "        sys.exit(1)\n",
    "    print(f\"‚úÖ {len(df_scored)} entries with valid scores\")\n",
    "    print(f\"   Score range: {df_scored['score'].min():.4f} ‚Üí {df_scored['score'].max():.4f}\")\n",
    "\n",
    "    # ‚îÄ‚îÄ apply significance filtering ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    if SIGNIFICANCE_THRESHOLD is not None:\n",
    "        print(f\"\\nüéØ Applying significance filtering (p < {SIGNIFICANCE_THRESHOLD})...\")\n",
    "        df_scored = apply_significance_filter(df_scored, SIGNIFICANCE_THRESHOLD)\n",
    "        if df_scored.empty:\n",
    "            print(f\"‚ùå ERROR: No significant results at p < {SIGNIFICANCE_THRESHOLD}\")\n",
    "            sys.exit(1)\n",
    "\n",
    "    # ‚îÄ‚îÄ handle duplicates ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    print(f\"\\nüîÑ Handling duplicate genes (strategy: {DUPLICATE_STRATEGY})...\")\n",
    "    initial_count = len(df_scored)\n",
    "    unique_genes_initial = df_scored['GENE'].nunique()\n",
    "\n",
    "    df_scored = filter_duplicates(df_scored, strategy=DUPLICATE_STRATEGY)\n",
    "\n",
    "    final_count = len(df_scored)\n",
    "    unique_genes_final = df_scored['GENE'].nunique()\n",
    "\n",
    "    print(f\"‚úÖ Deduplication complete:\")\n",
    "    print(f\"   Before: {initial_count} entries, {unique_genes_initial} unique genes\")\n",
    "    print(f\"   After:  {final_count} entries, {unique_genes_final} unique genes\")\n",
    "\n",
    "    # ‚îÄ‚îÄ select top entries ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    print(f\"\\nüèÜ Selecting top {TOP_N} entries\")\n",
    "    df_top = df_scored.sort_values(\"score\", ascending=False).head(TOP_N)\n",
    "\n",
    "    print(\"\\nTop gene‚Äìmask combinations:\")\n",
    "    print(\"-\" * 80)\n",
    "    for i, (_, row) in enumerate(df_top.iterrows(), 1):\n",
    "        score_label = {\"logp\": \"LOG10P\", \"chisq\": \"CHISQ\", \"beta\": \"|BETA|\"}[SCORE_METHOD]\n",
    "        print(f\"{i:2d}. {row['GENE']:<12} ({row['MASK']}) - {score_label}={row['score']:.4f}\")\n",
    "\n",
    "    # ‚îÄ‚îÄ write outputs ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    print(f\"\\nüíæ Writing LOVO gene list ‚Üí {OUTPUT_FILE}\")\n",
    "    with open(OUTPUT_FILE, \"w\") as fout:\n",
    "        # Write header\n",
    "        fout.write(\"GENE,MASK,AAF_BIN\\n\")\n",
    "        for _, row in df_top.iterrows():\n",
    "            fout.write(f\"{row['GENE']},{row['MASK']},{row['AAF_BIN']}\\n\")\n",
    "    print(f\"‚úÖ Saved {len(df_top)} entries to {OUTPUT_FILE}\")\n",
    "\n",
    "    # ‚îÄ‚îÄ summary ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"SUMMARY\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"üìÇ Input file: {REGENIE_FILE}\")\n",
    "    print(f\"üß™ Test analysed: {TEST_NAME}\")\n",
    "    print(f\"üìä Scoring method: {SCORE_METHOD}\")\n",
    "    print(f\"üîÑ Duplicate strategy: {DUPLICATE_STRATEGY}\")\n",
    "    print(f\"üéØ Significance filter: {SIGNIFICANCE_THRESHOLD if SIGNIFICANCE_THRESHOLD else 'None'}\")\n",
    "    print(f\"üìà Total entries analysed: {len(df_scored)}\")\n",
    "    print(f\"üèÜ Top entries selected: {TOP_N}\")\n",
    "    print(f\"üíæ Output file: {OUTPUT_FILE}\")\n",
    "\n",
    "    # ‚îÄ‚îÄ detailed results ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    base_cols = [\"GENE\", \"MASK\", \"AAF_BIN\"]\n",
    "    optional_cols = [c for c in [\"BETA\", \"LOG10P\", \"CHISQ\"] if c in df_top.columns]\n",
    "    display_cols = base_cols + optional_cols\n",
    "    print(\"\\nüìã Detailed results:\")\n",
    "    print(df_top[display_cols].to_string(index=False, float_format=\"%.4f\"))\n",
    "\n",
    "    print(\"\\nLOVO gene list format (GENE,MASK,AAF_BIN):\")\n",
    "    for _, row in df_top.iterrows():\n",
    "        print(f\"{row['GENE']},{row['MASK']},{row['AAF_BIN']}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "id": "fd5ef16739dfd24c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# version with boniferri correction\n",
    "# multiple testing correction as testing thousands of genes simultaneously, so can expect false positives\n",
    "\n",
    "\n",
    "# 04_LOVO_Gene_Selection\n",
    "# i. Select top genes from REGENIE burden test results (LOVO gene list)\n",
    "# Python script - IMPROVED VERSION WITH BONFERRONI CORRECTION\n",
    "\n",
    "##############################################################\n",
    "#               USER-DEFINED INPUTS (EDIT HERE)              #\n",
    "##############################################################\n",
    "\n",
    "# Path to REGENIE output\n",
    "REGENIE_FILE = r\"C:\\Users\\B00731414\\OneDrive - Ulster University\\6. Code\\ADNI\\4. Gene Burden\\03_Regenie_ADNI1\\S2_ADNI_burden_AD_vs_CN.regenie\"\n",
    "\n",
    "# Test configuration\n",
    "TEST_NAME = \"ADD-SKATO\"        # e.g. ADD-SKATO, ADD\n",
    "TOP_N = 10                     # Number of top gene‚Äìmask entries to select\n",
    "AAF_BIN_LABEL = \"all\"          # Label for AAF bin (as in ID field)\n",
    "OUTPUT_FILE = \"lovo_genes.txt\"\n",
    "\n",
    "# Scoring method:\n",
    "# \"logp\"  = Rank by LOG10P (recommended for burden tests)\n",
    "# \"chisq\" = Rank by CHISQ statistic\n",
    "# \"beta\"  = Rank by absolute BETA\n",
    "SCORE_METHOD = \"logp\"\n",
    "\n",
    "# duplicate handling strategy:\n",
    "# \"best_mask\"     ‚Üí Keep most restrictive mask (M1 > M2 > M3 > M4)\n",
    "# \"keep_all\"      ‚Üí Keep all mask combinations\n",
    "# \"highest_score\" ‚Üí Keep highest scoring entry per gene\n",
    "DUPLICATE_STRATEGY = \"keep_all\"\n",
    "\n",
    "# multiple testing correction\n",
    "APPLY_BONFERRONI = True        # Apply Bonferroni correction for multiple testing\n",
    "BONFERRONI_ALPHA = 0.05        # Family-wise error rate for Bonferroni correction\n",
    "\n",
    "# Raw significance filtering (applied before Bonferroni if enabled)\n",
    "RAW_SIGNIFICANCE_THRESHOLD = None  # Set to raw p-value threshold (e.g., 0.05) or None to disable\n",
    "\n",
    "##############################################################\n",
    "#               DO NOT EDIT BELOW THIS LINE                  #\n",
    "##############################################################\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# ‚îÄ‚îÄ Compute score ranking ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "def compute_score(df, method):\n",
    "    df_scored = df.copy()\n",
    "    if method == \"logp\":\n",
    "        df_scored = df_scored[df_scored[\"LOG10P\"] > 0].copy()\n",
    "        df_scored[\"score\"] = df_scored[\"LOG10P\"]\n",
    "    elif method == \"chisq\":\n",
    "        df_scored = df_scored[df_scored[\"CHISQ\"] > 0].copy()\n",
    "        df_scored[\"score\"] = df_scored[\"CHISQ\"]\n",
    "    elif method == \"beta\":\n",
    "        df_scored = df_scored[df_scored[\"BETA\"].notna() & (df_scored[\"BETA\"] != 0)].copy()\n",
    "        if len(df_scored) == 0:\n",
    "            print(\"‚ö†Ô∏è  WARNING: No valid BETA values found!\")\n",
    "            return df_scored\n",
    "        df_scored[\"score\"] = df_scored[\"BETA\"].abs()\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown scoring method: {method}\")\n",
    "    return df_scored\n",
    "\n",
    "# ‚îÄ‚îÄ Extract gene/mask info from ID col ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "def extract_gene_mask_info(df, aaf_label):\n",
    "    id_parts = df[\"ID\"].str.split(\".\", expand=True)\n",
    "    if id_parts.shape[1] >= 3:\n",
    "        df[\"GENE\"] = id_parts[0]\n",
    "        df[\"MASK\"] = id_parts[1]\n",
    "        df[\"AAF_BIN\"] = aaf_label\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è  WARNING: ID format may not match expected GENE.MASK.AAF pattern\")\n",
    "        df[\"GENE\"] = df[\"ID\"]\n",
    "        df[\"MASK\"] = \"unknown\"\n",
    "        df[\"AAF_BIN\"] = aaf_label\n",
    "    return df\n",
    "\n",
    "# ‚îÄ‚îÄ Handle duplicates ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "def filter_duplicates(df, strategy=\"best_mask\"):\n",
    "    if strategy == \"keep_all\":\n",
    "        return df\n",
    "    elif strategy == \"highest_score\":\n",
    "        return df.loc[df.groupby(\"GENE\")[\"score\"].idxmax()].copy()\n",
    "    elif strategy == \"best_mask\":\n",
    "        mask_priority = {\"M1\": 1, \"M2\": 2, \"M3\": 3, \"M4\": 4}\n",
    "        df[\"mask_priority\"] = df[\"MASK\"].map(mask_priority).fillna(99)\n",
    "        best = df.loc[df.groupby(\"GENE\")[\"mask_priority\"].idxmin()].copy()\n",
    "        return best.drop(\"mask_priority\", axis=1)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown duplicate strategy: {strategy}\")\n",
    "\n",
    "# ‚îÄ‚îÄ Apply raw significance filtering ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "def apply_raw_significance_filter(df, threshold):\n",
    "    if threshold is None:\n",
    "        return df\n",
    "\n",
    "    # Convert LOG10P back to p-value for filtering\n",
    "    if \"LOG10P\" in df.columns:\n",
    "        df_filtered = df[df[\"LOG10P\"] >= -np.log10(threshold)].copy()\n",
    "        print(f\"   Applied raw p < {threshold} filter: {len(df_filtered)} entries remain\")\n",
    "        return df_filtered\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è  WARNING: Cannot apply significance filter without LOG10P column\")\n",
    "        return df\n",
    "\n",
    "# ‚îÄ‚îÄ Apply Bonferroni correction ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "def apply_bonferroni_correction(df, alpha=0.05):\n",
    "    if \"LOG10P\" not in df.columns:\n",
    "        print(\"‚ö†Ô∏è  WARNING: Cannot apply Bonferroni correction without LOG10P column\")\n",
    "        return df\n",
    "\n",
    "    # Calculate raw p-values from LOG10P\n",
    "    df[\"raw_pvalue\"] = 10**(-df[\"LOG10P\"])\n",
    "\n",
    "    # Number of tests for Bonferroni correction\n",
    "    n_tests = len(df)\n",
    "    bonferroni_threshold = alpha / n_tests\n",
    "\n",
    "    # Apply Bonferroni correction\n",
    "    df[\"bonferroni_corrected_pvalue\"] = df[\"raw_pvalue\"] * n_tests\n",
    "    df[\"bonferroni_corrected_pvalue\"] = df[\"bonferroni_corrected_pvalue\"].clip(upper=1.0)  # Cap at 1.0\n",
    "    df[\"bonferroni_corrected_log10p\"] = -np.log10(df[\"bonferroni_corrected_pvalue\"])\n",
    "\n",
    "    # Filter for Bonferroni significance\n",
    "    df_significant = df[df[\"bonferroni_corrected_pvalue\"] <= alpha].copy()\n",
    "\n",
    "    print(f\"   Bonferroni correction applied:\")\n",
    "    print(f\"   ‚Ä¢ Number of tests: {n_tests}\")\n",
    "    print(f\"   ‚Ä¢ Raw threshold: p < {bonferroni_threshold:.2e}\")\n",
    "    print(f\"   ‚Ä¢ Family-wise alpha: {alpha}\")\n",
    "    print(f\"   ‚Ä¢ Bonferroni significant: {len(df_significant)} entries\")\n",
    "\n",
    "    return df_significant, bonferroni_threshold\n",
    "\n",
    "# ‚îÄ‚îÄ Load regenie results ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "def main():\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"LOVO GENE SELECTION FROM REGENIE BURDEN TEST RESULTS\")\n",
    "    print(\"WITH BONFERRONI MULTIPLE TESTING CORRECTION\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    # ‚îÄ‚îÄ validate parameters ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    print(\"\\nüîß Validating parameters...\")\n",
    "    if TOP_N <= 0:\n",
    "        print(f\"‚ùå ERROR: TOP_N must be positive, got {TOP_N}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    regenie_path = Path(REGENIE_FILE)\n",
    "    if not regenie_path.exists():\n",
    "        print(f\"‚ùå ERROR: Input file not found: {REGENIE_FILE}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    if SCORE_METHOD not in [\"logp\", \"chisq\", \"beta\"]:\n",
    "        print(f\"‚ùå ERROR: Invalid SCORE_METHOD: {SCORE_METHOD}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    if DUPLICATE_STRATEGY not in [\"best_mask\", \"keep_all\", \"highest_score\"]:\n",
    "        print(f\"‚ùå ERROR: Invalid DUPLICATE_STRATEGY: {DUPLICATE_STRATEGY}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    if APPLY_BONFERRONI and not (0 < BONFERRONI_ALPHA < 1):\n",
    "        print(f\"‚ùå ERROR: BONFERRONI_ALPHA must be between 0 and 1, got {BONFERRONI_ALPHA}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    print(\"‚úÖ All parameters validated\")\n",
    "\n",
    "    # ‚îÄ‚îÄ load results ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    print(f\"\\nüìñ Loading REGENIE results from: {REGENIE_FILE}\")\n",
    "    try:\n",
    "        df = pd.read_csv(REGENIE_FILE, sep=r\"\\s+\", comment=\"#\", header=0)\n",
    "        print(f\"‚úÖ Loaded {len(df)} rows √ó {len(df.columns)} columns\")\n",
    "        print(f\"   Available tests: {', '.join(df['TEST'].unique())}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå ERROR loading file: {e}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    # ‚îÄ‚îÄ filter to test ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    print(f\"\\nüîé Filtering to test: {TEST_NAME}\")\n",
    "    df_test = df[df[\"TEST\"] == TEST_NAME].copy()\n",
    "    if df_test.empty:\n",
    "        print(f\"‚ùå ERROR: No results found for '{TEST_NAME}'\")\n",
    "        sys.exit(1)\n",
    "    print(f\"‚úÖ Found {len(df_test)} entries for {TEST_NAME}\")\n",
    "\n",
    "    # ‚îÄ‚îÄ extract gene and mask info ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    print(f\"\\nüß¨ Extracting gene and mask information...\")\n",
    "    df_test = extract_gene_mask_info(df_test, AAF_BIN_LABEL)\n",
    "    print(f\"‚úÖ Found {df_test['GENE'].nunique()} unique genes\")\n",
    "    print(\"   Mask distribution:\")\n",
    "    for mask, count in df_test['MASK'].value_counts().items():\n",
    "        print(f\"     {mask}: {count} entries\")\n",
    "\n",
    "    # ‚îÄ‚îÄ compute scores ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    print(f\"\\nüìä Computing scores (method: {SCORE_METHOD})\")\n",
    "    df_scored = compute_score(df_test, SCORE_METHOD)\n",
    "    if df_scored.empty:\n",
    "        print(f\"‚ùå ERROR: No valid scores with method '{SCORE_METHOD}'\")\n",
    "        sys.exit(1)\n",
    "    print(f\"‚úÖ {len(df_scored)} entries with valid scores\")\n",
    "    print(f\"   Score range: {df_scored['score'].min():.4f} ‚Üí {df_scored['score'].max():.4f}\")\n",
    "\n",
    "    # ‚îÄ‚îÄ apply raw significance filtering ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    if RAW_SIGNIFICANCE_THRESHOLD is not None:\n",
    "        print(f\"\\nüéØ Applying raw significance filtering (p < {RAW_SIGNIFICANCE_THRESHOLD})...\")\n",
    "        df_scored = apply_raw_significance_filter(df_scored, RAW_SIGNIFICANCE_THRESHOLD)\n",
    "        if df_scored.empty:\n",
    "            print(f\"‚ùå ERROR: No significant results at raw p < {RAW_SIGNIFICANCE_THRESHOLD}\")\n",
    "            sys.exit(1)\n",
    "\n",
    "    # ‚îÄ‚îÄ apply bonferroni correction ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    bonferroni_threshold = None\n",
    "    if APPLY_BONFERRONI:\n",
    "        print(f\"\\nüî¨ Applying Bonferroni correction (Œ± = {BONFERRONI_ALPHA})...\")\n",
    "        df_bonferroni, bonferroni_threshold = apply_bonferroni_correction(df_scored, BONFERRONI_ALPHA)\n",
    "\n",
    "        if df_bonferroni.empty:\n",
    "            print(f\"‚ö†Ô∏è  WARNING: No genes pass Bonferroni correction at Œ± = {BONFERRONI_ALPHA}\")\n",
    "            print(f\"   Proceeding with top {TOP_N} genes from original dataset for exploratory analysis\")\n",
    "            # Keep original data but add Bonferroni columns for reference\n",
    "            df_scored[\"raw_pvalue\"] = 10**(-df_scored[\"LOG10P\"])\n",
    "            df_scored[\"bonferroni_corrected_pvalue\"] = df_scored[\"raw_pvalue\"] * len(df_scored)\n",
    "            df_scored[\"bonferroni_corrected_pvalue\"] = df_scored[\"bonferroni_corrected_pvalue\"].clip(upper=1.0)\n",
    "            df_scored[\"bonferroni_corrected_log10p\"] = -np.log10(df_scored[\"bonferroni_corrected_pvalue\"])\n",
    "            df_working = df_scored\n",
    "        else:\n",
    "            print(f\"‚úÖ {len(df_bonferroni)} genes pass Bonferroni correction\")\n",
    "            df_working = df_bonferroni\n",
    "    else:\n",
    "        print(\"\\nüî¨ Skipping Bonferroni correction (APPLY_BONFERRONI = False)\")\n",
    "        df_working = df_scored\n",
    "\n",
    "    # ‚îÄ‚îÄ handle duplicates ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    print(f\"\\nüîÑ Handling duplicate genes (strategy: {DUPLICATE_STRATEGY})...\")\n",
    "    initial_count = len(df_working)\n",
    "    unique_genes_initial = df_working['GENE'].nunique()\n",
    "\n",
    "    df_working = filter_duplicates(df_working, strategy=DUPLICATE_STRATEGY)\n",
    "\n",
    "    final_count = len(df_working)\n",
    "    unique_genes_final = df_working['GENE'].nunique()\n",
    "\n",
    "    print(f\"‚úÖ Deduplication complete:\")\n",
    "    print(f\"   Before: {initial_count} entries, {unique_genes_initial} unique genes\")\n",
    "    print(f\"   After:  {final_count} entries, {unique_genes_final} unique genes\")\n",
    "\n",
    "    # ‚îÄ‚îÄ select top entries ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    print(f\"\\nüèÜ Selecting top {TOP_N} entries\")\n",
    "    df_top = df_working.sort_values(\"score\", ascending=False).head(TOP_N)\n",
    "\n",
    "    print(\"\\nTop gene‚Äìmask combinations:\")\n",
    "    print(\"-\" * 100)\n",
    "    score_label = {\"logp\": \"LOG10P\", \"chisq\": \"CHISQ\", \"beta\": \"|BETA|\"}[SCORE_METHOD]\n",
    "\n",
    "    for i, (_, row) in enumerate(df_top.iterrows(), 1):\n",
    "        bonf_info = \"\"\n",
    "        if APPLY_BONFERRONI and \"bonferroni_corrected_pvalue\" in row:\n",
    "            bonf_p = row[\"bonferroni_corrected_pvalue\"]\n",
    "            significance = \"***\" if bonf_p <= BONFERRONI_ALPHA else \"\"\n",
    "            bonf_info = f\" | Bonf.p={bonf_p:.2e}{significance}\"\n",
    "\n",
    "        print(f\"{i:2d}. {row['GENE']:<12} ({row['MASK']}) - {score_label}={row['score']:.4f}{bonf_info}\")\n",
    "\n",
    "    # ‚îÄ‚îÄ write outputs ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    print(f\"\\nüíæ Writing LOVO gene list ‚Üí {OUTPUT_FILE}\")\n",
    "    with open(OUTPUT_FILE, \"w\") as fout:\n",
    "        # Write header\n",
    "        fout.write(\"GENE,MASK,AAF_BIN\\n\")\n",
    "        for _, row in df_top.iterrows():\n",
    "            fout.write(f\"{row['GENE']},{row['MASK']},{row['AAF_BIN']}\\n\")\n",
    "    print(f\"‚úÖ Saved {len(df_top)} entries to {OUTPUT_FILE}\")\n",
    "\n",
    "    # Write detailed results file\n",
    "    detailed_output = OUTPUT_FILE.replace(\".txt\", \"_detailed.csv\")\n",
    "    output_cols = [\"GENE\", \"MASK\", \"AAF_BIN\", \"BETA\", \"LOG10P\", \"CHISQ\", \"score\"]\n",
    "    if APPLY_BONFERRONI and \"bonferroni_corrected_pvalue\" in df_top.columns:\n",
    "        output_cols.extend([\"raw_pvalue\", \"bonferroni_corrected_pvalue\", \"bonferroni_corrected_log10p\"])\n",
    "\n",
    "    available_cols = [col for col in output_cols if col in df_top.columns]\n",
    "    df_top[available_cols].to_csv(detailed_output, index=False)\n",
    "    print(f\"‚úÖ Detailed results saved to {detailed_output}\")\n",
    "\n",
    "    # ‚îÄ‚îÄ summary ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"SUMMARY\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"üìÇ Input file: {REGENIE_FILE}\")\n",
    "    print(f\"üß™ Test analysed: {TEST_NAME}\")\n",
    "    print(f\"üìä Scoring method: {SCORE_METHOD}\")\n",
    "    print(f\"üîÑ Duplicate strategy: {DUPLICATE_STRATEGY}\")\n",
    "    print(f\"üéØ Raw significance filter: {RAW_SIGNIFICANCE_THRESHOLD if RAW_SIGNIFICANCE_THRESHOLD else 'None'}\")\n",
    "    print(f\"üî¨ Bonferroni correction: {'Yes' if APPLY_BONFERRONI else 'No'}\")\n",
    "    if APPLY_BONFERRONI:\n",
    "        print(f\"   ‚Ä¢ Family-wise Œ±: {BONFERRONI_ALPHA}\")\n",
    "        if bonferroni_threshold:\n",
    "            print(f\"   ‚Ä¢ Raw p-value threshold: {bonferroni_threshold:.2e}\")\n",
    "    print(f\"üìà Total entries analysed: {len(df_working)}\")\n",
    "    print(f\"üèÜ Top entries selected: {TOP_N}\")\n",
    "    print(f\"üíæ Output file: {OUTPUT_FILE}\")\n",
    "    print(f\"üìã Detailed results: {detailed_output}\")\n",
    "\n",
    "    # ‚îÄ‚îÄ detailed results ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    display_cols = [\"GENE\", \"MASK\", \"AAF_BIN\", \"BETA\", \"LOG10P\", \"CHISQ\"]\n",
    "    if APPLY_BONFERRONI and \"bonferroni_corrected_pvalue\" in df_top.columns:\n",
    "        display_cols.append(\"bonferroni_corrected_pvalue\")\n",
    "\n",
    "    available_display_cols = [col for col in display_cols if col in df_top.columns]\n",
    "    print(\"\\nüìã Detailed results:\")\n",
    "    print(df_top[available_display_cols].to_string(index=False, float_format=\"%.4f\"))\n",
    "\n",
    "    print(\"\\nLOVO gene list format (GENE,MASK,AAF_BIN):\")\n",
    "    for _, row in df_top.iterrows():\n",
    "        print(f\"{row['GENE']},{row['MASK']},{row['AAF_BIN']}\")\n",
    "\n",
    "    # ‚îÄ‚îÄ bonferroni warning ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    if APPLY_BONFERRONI:\n",
    "        significant_genes = len(df_working[df_working[\"bonferroni_corrected_pvalue\"] <= BONFERRONI_ALPHA]) if \"bonferroni_corrected_pvalue\" in df_working.columns else 0\n",
    "\n",
    "        print(f\"\\nüî¨ BONFERRONI CORRECTION SUMMARY:\")\n",
    "        print(f\"   ‚Ä¢ Total tests performed: {len(df_scored)}\")\n",
    "        print(f\"   ‚Ä¢ Genes passing correction: {significant_genes}\")\n",
    "\n",
    "        if significant_genes == 0:\n",
    "            print(\"   ‚ö†Ô∏è  No genes pass multiple testing correction\")\n",
    "        elif significant_genes < TOP_N:\n",
    "            print(f\"   ‚ö†Ô∏è  Only {significant_genes} genes pass correction (< TOP_N)\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "id": "1a4fc96a443ea3cb",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
